Work Breakdown Structure (WBS)
A Work Breakdown Structure (WBS), in project management and systems engineering, is a deliverable-oriented decomposition of a project into smaller components.

A Work Breakdown Structure element may be a product, data, service, or any combination thereof. A WBS also provides the necessary framework for detailed cost estimating and control along with providing guidance for schedule development and control.

WBS is a hierarchical and incremental decomposition of the project into phases, deliverables and work packages. It is a tree structure, which shows a subdivision of effort required to achieve an objective; for example a program, project, and contract. In a project or contract, the WBS is developed by starting with the end objective and successively subdividing it into manageable components in terms of size, duration, and responsibility (e.g., systems, subsystems, components, tasks, subtasks, and work packages) which include all steps necessary to achieve the objective.

The work breakdown structure provides a common framework for the natural development of the overall planning and control of a contract and is the basis for dividing work into definable increments from which the statement of work can be developed and technical, schedule, cost, and labor hour reporting can be established.

A work breakdown structure permits summing of subordinate costs for tasks, materials, etc., into their successively higher level “parent” tasks, materials, etc. For each element of the work breakdown structure, a description of the task to be performed is generated. This technique (sometimes called a system breakdown structure) is used to define and organize the total scope of a project.

The WBS is organised around the primary products of the project (or planned outcomes) instead of the work needed to produce the products (planned actions). Since the planned outcomes are the desired ends of the project, they form a relatively stable set of categories in which the costs of the planned actions needed to achieve them can be collected. A well-designed WBS makes it easy to assign each project activity to one and only one terminal element of the WBS. In addition to its function in cost accounting, the WBS also helps map requirements from one level of system specification to another, for example a requirements cross reference matrix mapping functional requirements to high level or low level design documents.

The development of the WBS normally occurs at the start of a project and precedes detailed project and task planning.

The concept of work breakdown structure developed with the Program Evaluation and Review Technique ([PERT]) by the [United States Department of Defense] (DoD). PERT was introduced by the U.S. Navy in 1957 to support the development of its Polaris missile program. While the term "work breakdown structure" was not used, this first implementation of PERT did organize the tasks into product-oriented categories.

By June 1962, DoD, NASA and the aerospace industry published a document for the PERT/COST system which described the WBS approach. This guide was endorsed by the Secretary of Defense for adoption by all services. In 1968, the DoD issued "Work Breakdown Structures for Defense Materiel Items" (MIL-STD-881), a military standard requiring the use of work breakdown structures across the DoD.
===

PERT - Project Evaluation and Review Technique
The Program (or Project) Evaluation and Review Technique, commonly abbreviated PERT, is a statistical tool, used in project management, which was designed to analyse and represent the tasks involved in completing a given project. First developed by the United States Navy in the 1950s, it is commonly used in conjunction with the [critical path method] (CPM).

PERT is a method to analyze the involved tasks in completing a given project, especially the time needed to complete each task, and to identify the minimum time needed to complete the total project.

PERT was developed primarily to simplify the planning and scheduling of large and complex projects. It was developed for the U.S. Navy Special Projects Office in 1957 to support the U.S. Navy's Polaris nuclear submarine project. It was able to incorporate uncertainty by making it possible to schedule a project while not knowing precisely the details and durations of all the activities. It is more of an event-oriented technique rather than start and completion oriented, and is used more in projects where time is the major factor rather than cost. It is applied to very large-scale, one-time, complex, non-routine infrastructure and Research and Development projects. An example of this was for the 1968 Winter Olympics in Grenoble which applied PERT from 1965 until the opening of the 1968 Games.

This project model was the first of its kind, a revival for scientific management, founded by Frederick Taylor (Taylorism) and later refined by Henry Ford (Fordism). DuPont's critical path method was invented at roughly the same time as PERT.

Program evaluation and review technique
     
The Navy's Special Projects Office, charged with developing the Polaris-Submarine weapon system and the Fleet Ballistic Missile capability, has developed a statistical technique for measuring and forecasting progress in research and development programs. This program evaluation and review technique (code-named PERT) is applied as a decision-making tool designed to save time in achieving end-objectives, and is of particular interest to those engaged in research and development programs for which time is a critical factor.
     The new technique takes recognition of three factors that influence successful achievement of research and development program objectives: time, resources, and technical performance specifications. PERT employs time as the variable that reflects planned resource-applications and performance specifications. With units of time as a common denominator, PERT quantifies knowledge about the uncertainties involved in developmental programs requiring effort at the edge of, or beyond, current knowledge of the subject – effort for which little or no previous experience exists.
     Through an electronic computer, the PERT technique processes data representing the major, finite accomplishments (events) essential to achieve end-objectives; the inter-dependence of those events; and estimates of time and range of time necessary to complete each activity between two successive events. Such time expectations include estimates of "most likely time", "optimistic time", and "pessimistic time" for each activity. The technique is a management control tool that sizes up the outlook for meeting objectives on time; highlights danger signals requiring management decisions; reveals and defines both methodicalness and slack in the flow plan or the network of sequential activities that must be performed to meet objectives; compares current expectations with scheduled completion dates and computes the probability for meeting scheduled dates; and simulates the effects of options for decision – before decision.
     The concept of PERT was developed by an operations research team staffed with representatives from the Operations Research Department of Booz, Allen and Hamilton; the Evaluation Office of the Lockheed Missile Systems Division; and the Program Evaluation Branch, Special Projects Office, of the Department of the Navy.
— Willard Fazar (Head, Program Evaluation Branch, Special Projects Office, U. S. Navy), The American Statistician, April 1959.
===

Critical Path Method (CPM)
The Critical Path Method (CPM) is an algorithm for scheduling a set of project activities.

CPM is a project modeling technique developed in the late 1950s by Morgan R. Walker of DuPont and James E. Kelley, Jr. of Remington Rand. Kelley and Walker related their memories of the development of CPM in 1989. Kelley attributed the term "critical path" to the developers of the Program Evaluation and Review Technique which was developed at about the same time by Booz Allen Hamilton and the U.S. Navy. The precursors of what came to be known as Critical Path were developed and put into practice by DuPont between 1940 and 1943 and contributed to the success of the Manhattan Project.

CPM is commonly used with all forms of projects, including construction, aerospace and defense, software development, research projects, product development, engineering, and plant maintenance, among others. Any project with interdependent activities can apply this method of mathematical analysis. Although the original CPM program and approach is no longer used, the term is generally applied to any approach used to analyse a project network logic diagram.

Basic technique
The essential technique for using CPM is to construct a model of the project that includes the following:

- A list of all activities required to complete the project (typically categorized within a work breakdown structure),
- The time (duration) that each activity will take to complete,
- The dependencies between the activities and,
- Logical end points such as milestones or deliverable items.
Using these values, CPM calculates the longest path of planned activities to logical end points or to the end of the project, and the earliest and latest that each activity can start and finish without making the project longer. This process determines which activities are "critical" (i.e., on the longest path) and which have "total float" (i.e., can be delayed without making the project longer). In project management, a critical path is the sequence of project network activities which add up to the longest overall duration, regardless if that longest duration has float or not. This determines the shortest time possible to complete the project. There can be 'total float' (unused time) within the critical path. For example, if a project is testing a solar panel and task 'B' requires 'sunrise', there could be a scheduling constraint on the testing activity so that it would not start until the scheduled time for sunrise. This might insert dead time (total float) into the schedule on the activities on that path prior to the sunrise due to needing to wait for this event. This path, with the constraint-generated total float would actually make the path longer, with total float being part of the shortest possible duration for the overall project. In other words, individual tasks on the critical path prior to the constraint might be able to be delayed without elongating the critical path; this is the 'total float' of that task. However, the time added to the project duration by the constraint is actually critical path drag, the amount by which the project's duration is extended by each critical path activity and constraint.

A project can have several, parallel, near critical paths; and some or all of the tasks could have 'free float' and/or 'total float'. An additional parallel path through the network with the total durations shorter than the critical path is called a sub-critical or non-critical path. Activities on sub-critical paths have no drag, as they are not extending the project's duration.

CPM analysis tools allow a user to select a logical end point in a project and quickly identify its longest series of dependent activities (its longest path). These tools can display the critical path (and near critical path activities if desired) as a cascading waterfall that flows from the project's start (or current status date) to the selected logical end point.
===

Value Breakdown Structure (VBS)
A Value Breakdown Structure (VBS) is a project management technique introduced by Stephen Devaux as part of the [Total Project Control] (TPC) approach to project and program value analysis.

A Work Breakdown Structure (WBS) in project management and systems engineering is a deliverable oriented decomposition of a project into smaller components into a tree structure that represents how the work of the project will create the components of the final product. Resources and cost are typically inserted into the activities in a WBS, and summed to create a budget both for summary levels (often called “work packages”) and for the whole project or program. Similarly, the expected value-added of each activity and/or component of the project (or projects within a program) are inserted into the VBS.

In most projects (and programs), there are some components and activities (and projects) that are mandatory and others that are optional. Mandatory activities are required, and have the full value of the project investment, as the project cannot be completed without them. In contrast, optional activities have only the value that they are adding to the project, i.e., their value is equal to the delta between the project / program value if they are included and the value if they are omitted.

===

Total Project Control (TPC)
Total Project Control (TPC) is a project management method that emphasises continuous tracking and optimization of [ROI]. It was developed by Stephen Devaux. It builds upon earlier techniques such as earned value management, [critical path method], and [program evaluation and review technique], but uses these to track and index projected project profitability as well as the more traditional cost and schedule. In this way it aims to manage projects as profit and investment centers, rather than cost centers.

Introduced with TPC are a variety of project management metrics and techniques, among them critical path drag, the [Value Breakdown Structure] (VBS), Devaux's Index of Project Performance (DIPP), Doubled Resource Estimated Duration (DRED), and Cost of Leveling with Unresolved Bottlenecks (CLUB).
===

Return On Investment (ROI)
Return on investment (ROI) is the benefit to the investor resulting from an investment of some resource. A high ROI means the investment gains compare favourably to investment cost. As a performance measure, ROI is used to evaluate the efficiency of an investment or to compare the efficiency of a number of different investments. In purely economic terms, it is one way of considering profits in relation to capital invested.
===
Wideband Delphi
The Wideband Delphi estimation method is a consensus-based technique for estimating effort. It derives from the [Delphi method] which was developed in the 1950-1960s at the RAND Corporation as a forecasting tool. It has since been adapted across many industries to estimate many kinds of tasks, ranging from statistical data collection results to sales and marketing forecasts.

Barry Boehm and John A. Farquhar originated the Wideband variant of the Delphi method in the 1970s. They called it "wideband" because, compared to the existing delphi method, the new method involved greater interaction and more communication between those participating. The method was popularised by Boehm's book Software Engineering Economics (1981). Boehm's original steps from this book were:

1 Coordinator presents each expert with a specification and an estimation form.
2 Coordinator calls a group meeting in which the experts discuss estimation issues with the coordinator and each other.
3 Experts fill out forms anonymously.
4 Coordinator prepares and distributes a summary of the estimates
5 Coordinator calls a group meeting, specifically focusing on having the experts discuss points where their estimates vary widely
6 Experts fill out forms, again anonymously, and steps 4 to 6 are iterated for as many rounds as appropriate.
===

Delphi Method
The Delphi method is a structured communication technique, originally developed as a systematic, interactive forecasting method which relies on a panel of experts. The experts answer questionnaires in two or more rounds. After each round, a facilitator or change agent provides an anonymous summary of the experts’ forecasts from the previous round as well as the reasons they provided for their judgments. Thus, experts are encouraged to revise their earlier answers in light of the replies of other members of their panel. It is believed that during this process the range of the answers will decrease and the group will converge towards the "correct" answer. Finally, the process is stopped after a pre-defined stop criterion (e.g. number of rounds, achievement of consensus, stability of results) and the mean or median scores of the final rounds determine the results.

The Delphi Method is not to be confused with a related technique for manufacturing consent in which an organising party combines the input in a non-transparent way, giving the organising party complete but non-obvious control over the outcome. A name often used for this deceptive use of the Delphi Method is the "Delphi Technique".

Delphi is based on the principle that forecasts (or decisions) from a structured group of individuals are more accurate than those from unstructured groups. The technique can also be adapted for use in face-to-face meetings, and is then called mini-Delphi or Estimate-Talk-Estimate (ETE). Delphi has been widely used for business forecasting and has certain advantages over another structured forecasting approach, prediction markets.
===

Test Management Approach (TMap)
Test management approach (TMap) is a software testing approach. TMap is an approach that combines insights on how to test and what to manage, as well as techniques for the individual test consultant.

The first method was created in 1995 and written by Martin Pol, Ruud Teunissen en Erik van Veenendaal. At the end of 2006 a new version was published called TMap Next written by other authors (Tim Koomen, Michiel Vroon, Leo van der Aalst & Bart Broekman). The main reason for this new version was the aim to create a more process focused description of the test process and put more emphasis on the business objectives as a guidance for the testing process.

TMap was created by the Dutch division of Sogeti which is part of Capgemini.
==

Risk Management
Risk management is the identification, assessment, and prioritisation of risks (defined in ISO 31000 as the effect of uncertainty on objectives) followed by coordinated and economical application of resources to minimize, monitor, and control the probability and/or impact of unfortunate events or to maximize the realization of opportunities. Risk management’s objective is to assure uncertainty does not deviate the endeavor from the business goals.

Risks can come from different ways e.g. uncertainty in financial markets, threats from project failures (at any phase in design, development, production, or sustainment life-cycles), legal liabilities, credit risk, accidents, natural causes and disasters as well as deliberate attack from an adversary, or events of uncertain or unpredictable root-cause. There are two types of events i.e. negative events can be classified as risks while positive events are classified as opportunities. Several risk management standards have been developed including the Project Management Institute, the National Institute of Standards and Technology, actuarial societies, and ISO standards. Methods, definitions and goals vary widely according to whether the risk management method is in the context of project management, security, engineering, industrial processes, financial portfolios, actuarial assessments, or public health and safety.

Risk sources are more often identified and located not only in infrastructural or technological assets and tangible variables, but in Human Factor variables, Mental States and Decision Making. The interaction between Human Factors and tangible aspects of risk, highlights the need to focus closely into Human Factor as one of the main drivers for Risk Management, a "Change Driver" that comes first of all from the need to know how humans perform in challenging environments and in face of risks (Trevisani, 2007). As the author describes, «it is an extremely hard task to be able to apply an objective and systematic self-observation, and to make a clear and decisive step from the level of the mere "sensation" that something is going wrong, to the clear understanding of how, when and where to act. The truth of a problem or risk is often obfuscated by wrong or incomplete analyses, fake targets, perceptual illusions, unclear focusing, altered mental states, and lack of good communication and confrontation of risk management solutions with reliable partners. This makes the Human Factor aspect of Risk Management sometimes heavier than its tangible and technological counterpart.

The strategies to manage threats (uncertainties with negative consequences) typically include transferring the threat to another party, avoiding the threat, reducing the negative effect or probability of the threat, or even accepting some or all of the potential or actual consequences of a particular threat, and the opposites for opportunities (uncertain future states with benefits).

===

Quality Management System (QMS)
A Quality Management System (QMS) is a collection of business processes focused on achieving quality policy and quality objectives to meet customer requirements. It is expressed as the organisational structure, policies, procedures, processes and resources needed to implement quality management. Early systems emphasised predictable outcomes of an industrial product production line, using simple statistics and random sampling. By the 20th century, labour inputs were typically the most costly inputs in most industrialized societies, so focus shifted to team cooperation and dynamics, especially the early signalling of problems via a continuous improvement cycle. In the 21st century, QMS has tended to converge with sustainability and transparency initiatives, as both investor and customer satisfaction and perceived quality is increasingly tied to these factors. Of all QMS regimes, the ISO 9000 family of standards is probably the most widely implemented worldwide - the ISO 19011 audit regime applies to both, and deals with quality and sustainability and their integration.
===

Product Breakdown Structure (PBS)
A Product Breakdown Structure (PBS) is a tool for analysing, documenting and communicating the outcomes of a project, and forms part of the product based planning technique.

The PBS provides an exhaustive, hierarchical tree structure of deliverables (physical, functional or conceptual) that make up the project, arranged in whole-part relationship.

This diagrammatic representation of project outputs provides a clear and unambiguous statement of what the project is to deliver.

The PBS is identical in format to the [Work Breakdown Structure] (WBS), but is a separate entity and is used at a different step in the planning process. The PBS precedes the WBS and focuses on cataloguing all the desired outputs (products) needed to achieve the goal of the project. This feeds into creation of the WBS, which identifies the tasks and activities required to deliver those outputs. Supporters of product based planning suggest that this overcomes difficulties that arise from assumptions about what to do and how to do it by focusing instead on the goals and objectives of the project - an oft-quoted analogy is that PBS defines where you want to go, the WBS tells you how to get there.
===

Object-Modeling Technique (OMT) 
The Object-Modeling Technique (OMT) is an object modeling approach for software modeling and designing. It was developed around 1991 by Rumbaugh, Blaha, Premerlani, Eddy and Lorensen as a method to develop object-oriented systems and to support object-oriented programming. Describes Object model or static structure of the system.

OMT was developed as an approach to software development. The purposes of modeling according to Rumbaugh are:

- testing physical entities before building them (simulation),
- communication with customers,
- visualisation (alternative presentation of information), and
- reduction of complexity.

OMT has proposed three main types of models:

Object model: The object model represents the static and most stable phenomena in the modeled domain. Main concepts are classes and associations with attributes and operations. Aggregation and generalisation (with multiple inheritance) are predefined relationships.

Dynamic model: The dynamic model represents a state / transition view on the model. Main concepts are states, transitions between states, and events to trigger transitions. Actions can be modeled as occurring within states. Generalisation and aggregation (concur-rency) are predefined relationships.

Functional model: The functional model handles the process perspective of the model, corresponding roughly to data flow diagrams. Main concepts are process, data store, data flow, and actors.

OMT is a predecessor of the [Unified Modeling Language] (UML). Many OMT modeling elements are common to UML.
===

Structured Systems Analysis and Design Method (SSADM)
Structured Systems Analysis and Design Method (SSADM), originally released as methodology, is a systems approach to the analysis and design of information systems. SSADM was produced for the Central Computer and Telecommunications Agency (now Office of Government Commerce), a UK government office concerned with the use of technology in government, from 1980 onwards.

SSADM is a waterfall method for the analysis and design of information systems. SSADM can be thought to represent a pinnacle of the rigorous document-led approach to system design, and contrasts with more contemporary agile methods such as DSDM or Scrum.

SSADM is one particular implementation and builds on the work of different schools of structured analysis and development methods, such as Peter Checkland's soft systems methodology, Larry Constantine's structured design, Edward Yourdon's Yourdon Structured Method, Michael A. Jackson's Jackson Structured Programming, and Tom DeMarco's structured analysis.

The names "Structured Systems Analysis and Design Method" and "SSADM" are registered trademarks of the Office of Government Commerce (OGC), which is an office of the United Kingdom's Treasury.

===

Lean Project Management
Lean Project Management is the comprehensive adoption of other lean concepts like lean construction, [lean manufacturing] and lean thinking into a project management context. Lean project management has many ideas in common with other lean concepts; however, the main principle of lean project management is delivering more value with less waste in a project context. Lean project management has many techniques that can be applied to projects and one of main methods is standardisation. Key techniques are those "inherited" from [Agile software development] like: blame-free employee involvement, the need for a strong facilitator, pipelining, etc.

Lean project management is the method used to plan and execute a lean (improvement) project. The are many ways to do this, but the two most prevalent are to use [6 Sigma] DMAIC method or use the Deming Cycle (Called the "A3" since the steps are recorded on an A3 size paper). Some companies are 6 Sigma Companies and used 6 Sigma Black Belts to take an improvement project through the steps of Define, Measure, Analyse, Improve, and Control. Other companies use the A3 Problem solving Process which includes the statement of the problem, the current situation, the root cause of the problem, suggest alternative solutions, suggest a recommended solution and have a cost-benefit analysis. This information would fit all on one A3 size sheet of paper.

Generally, these methods allow the project team to follow a disciplined method to measure the current state, define the future state, and put into place countermeasures to improve the process. Associated with the project are metrics that are measured, as well as foundational lean elements that are implemented to improve those metrics. Either method is helpful in achieving better results for the project outcome.

One of the main goals of lean project management is creation and removal of bottlenecks in the production process in order to push process along and accelerate growth. In this way, company teams become more productive. A type of lean project management is called Kanban. Kanban, like other facets of lean project management, makes you more productive by limiting multitasking, keeping your work uninterrupted, urging you to plan ahead, encouraging you to tackle larger tasks first, and to stop just starting and actually finish the projects you've begun.
===

Hammock Activity
A hammock activity (also hammock task) is a schedule or project planning term for a grouping of tasks that "hang" between two end dates it is tied to.

A hammock activity can group tasks which are not related in the hierarchical sense of a [Work Breakdown Structure], or are not related in a logical sense of a task dependency where one task must wait for another.

Usages include:

- Group dissimilar activities that lead to an overall capability, such as preparations under a summary label, e.g. "vacation preparation";
- Group unrelated items for the purpose of a summary such as a calendar-based reporting period, e.g. "First quarter plans";
- Group ongoing or overhead activities that run the length of an effort, e.g. "project management"

The duration of the hammock activity (the size of the hammock) may also be set by the subtasks within it, so that the abstract grouping has a start date of the earliest of any of the subtasks and the finish date is the latest of any of the contents.

A hammock activity is regarded as a form of Summary activity that is similar to but different from a [Level of Effort] (LOE) activity. Use of hammock activities is also a way to simplify the difficulties of performing Work Breakdown Structure decomposition to low levels.
===

Graphical Evaluation and Review Technique - GERT
Graphical Evaluation and Review Technique, commonly known as GERT, is a network analysis technique used in project management that allows probabilistic treatment of both network logic and estimation of activity duration. The technique was first described in 1966 by Dr. Alan B. Pritsker of Purdue University and WW Happ.

Compared to other techniques, GERT is only rarely used in complex systems. Nevertheless, the GERT approach addresses the majority of the limitations associated with [PERT] / [CPM] technique. GERT allows loops between tasks. The fundamental drawback associated with the GERT technique is the complex programme (Monte Carlo simulation) required to model the GERT system. Development in GERT includes Q-GERTS - allowing the user to consider queuing within the system.
===

Gantt Chart
A Gantt chart is a type of bar chart, adapted by Karol Adamiecki in 1896, and independently by Henry Gantt in the 1910s, that illustrates a project schedule. Gantt charts illustrate the start and finish dates of the terminal elements and summary elements of a project. Terminal elements and summary elements comprise the work breakdown structure of the project. Modern Gantt charts also show the dependency (i.e., precedence network) relationships between activities.

The first known tool of this type was developed in 1896 by Karol Adamiecki, who called it a harmonogram. Adamiecki did not publish his chart until 1931, however, and only in Polish, which limited both its adoption and recognition of his authorship. The chart is named after Henry Gantt (1861–1919), who designed his chart around the years 1910–1915.

One of the first major applications of Gantt charts was by the United States during World War I, at the instigation of General William Crozier.

In the 1980s, personal computers allowed for widespread creation of complex and elaborate Gantt charts. The first desktop applications were intended mainly for project managers and project schedulers. With the advent of the internet and increased collaboration over networks at the end of the 1990s, Gantt charts became a common feature of web-based applications, including collaborative groupware.
===

Event Chain Methodology
Event Chain Methodology is an uncertainty modeling and schedule network analysis technique that is focused on identifying and managing events and event chains that affect project schedules. Event chain methodology is the next advance beyond [critical path method] and critical chain project management.

Event chain methodology helps to mitigate the effect of motivational and cognitive biases in estimating and scheduling.
===

Estimation Theory
Estimation theory is a branch of statistics that deals with estimating the values of parameters based on measured / empirical data that has a random component. The parameters describe an underlying physical setting in such a way that their value affects the distribution of the measured data. An estimator attempts to approximate the unknown parameters using the measurements.
===

Earned Value Management (EVM)
Earned value management (EVM), or Earned value project / performance management (EVPM) is a project management technique for measuring project performance and progress in an objective manner.

Earned value management is a project management technique for measuring project performance and progress. It has the ability to combine measurements of the project management triangle:

- Scope
- Schedule, and
- Costs

In a single integrated system, Earned Value Management is able to provide accurate forecasts of project performance problems, which is an important contribution for project management.

Early EVM research showed that the areas of planning and control are significantly impacted by its use; and similarly, using the methodology improves both scope definition as well as the analysis of overall project performance. More recent research studies have shown that the principles of EVM are positive predictors of project success. Popularity of EVM has grown in recent years beyond government contracting, in which sector its importance continues to rise in part because EVM can also surface in and help substantiate contract disputes.

Essential features of any EVM implementation include

- a project plan that identifies work to be accomplished,
- a valuation of planned work, called Planned Value (PV) or Budgeted Cost of Work Scheduled (BCWS), and
- pre-defined “earning rules” (also called metrics) to quantify the accomplishment of work, called Earned Value (EV) or Budgeted Cost of Work Performed (BCWP).

EVM implementations for large or complex projects include many more features, such as indicators and forecasts of cost performance (over budget or under budget) and schedule performance (behind schedule or ahead of schedule). However, the most basic requirement of an EVM system is that it quantifies progress using PV and EV.
===



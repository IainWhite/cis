
Base64
Base64 is a group of similar binary-to-text encoding schemes that represent binary data in an [ASCII] string format by translating it into a radix-64 representation. The term Base64 originates from a specific [MIME] content transfer encoding.

Base64 encoding schemes are commonly used when there is a need to encode binary data that needs to be stored and transferred over media that is designed to deal with textual data. This is to ensure that the data remains intact without modification during transport. Base64 is commonly used in a number of applications, including email via MIME, and storing complex data in [XML].
===

WebGL
WebGL (Web Graphics Library) is a [JavaScript] API for rendering interactive 3D computer graphics and 2D graphics within any compatible web browser without the use of plug-ins. WebGL is integrated completely into all the web standards of the browser allowing GPU accelerated usage of physics and image processing and effects as part of the web page canvas. WebGL elements can be mixed with other [HTML] elements and composited with other parts of the page or page background. WebGL programs consist of control code written in JavaScript and shader code that is executed on a computer's Graphics Processing Unit (GPU). WebGL is designed and maintained by the non-profit Khronos Group.
===

Run Length Encoding (RLE) 
Run Length Encoding (RLE) is a very simple form of data compression in which runs of data (that is, sequences in which the same data value occurs in many consecutive data elements) are stored as a single data value and count, rather than as the original run. This is most useful on data that contains many such runs. Consider, for example, simple graphic images such as icons, line drawings, and animations. It is not useful with files that don't have many runs as it could greatly increase the file size.

RLE may also be used to refer to an early graphics file format supported by [CompuServe] for compressing black and white images, but was widely supplanted by their later [Graphics Interchange Format]. RLE also refers to a little used image format in [Windows 3.x], with the extension .rle, which is a Run Length Encoded Bitmap, used to compress the Windows 3.x startup screen.

Typical applications of this encoding are when the source information comprises long substrings of the same character or binary digit.
===

ANSI Escape Codes
In computing, ANSI escape codes (or escape sequences) are a method using in-band signaling to control the formatting, colour, and other output options on video text terminals. To encode this formatting information, certain sequences of bytes are embedded into the text, which the terminal looks for and interprets as commands, not as character codes.

ANSI codes were introduced in the 1970s and became widespread in the minicomputer / mainframe market by the early 1980s. They were used by the nascent [bulletin board system] market to offer improved displays compared to earlier systems lacking cursor movement, leading to even more widespread use.

Although hardware text terminals have become increasingly rare in the 21st century, the relevance of the ANSI standard persists because most terminal emulators interpret at least some of the ANSI escape sequences in the output text. One notable exception is the win32 console component of [Microsoft Windows].
===

Mac Terminal
Terminal (Terminal.app) is the terminal emulator included in the [OS X] operating system by [Apple].

Terminal originated in [NeXTSTEP] and OPENSTEP, the predecessor operating systems of OS X.

As a terminal emulator, the application provides text-based access to the operating system, in contrast to the mostly graphical nature of the user experience of OS X, by providing a command line interface to the operating system when used in conjunction with a [Unix] shell, such as [bash].

The preferences dialog for Terminal.app in OS X 10.8 ([Mountain Lion]) offers choices for values of the TERM environment variable. Available options are ansi, dtterm, nsterm, rxvt, vt52, vt100, vt102, xterm, xterm-16color and xterm-256color, which differ from the OS X 10.5 ([Leopard]) choices by dropping the xterm-color and adding xterm-16color and xterm-256color. These settings do not alter the operation of Terminal, and the xterm settings do not match the behaviour of xterm.

Terminal includes several features that specifically access OS X APIs and features. These include the ability to use the standard OS X Help search function to find manual pages and integration with Spotlight. Terminal was used by Apple as a showcase for OS X graphics APIs in early advertising of Mac OS X, offering a range of custom font and colouring options, including transparent backgrounds.
===

National Replacement Character Set
The National Replacement Character Set, or NRCS for short, was a feature supported by later models of Digital's ([DEC]) computer terminal systems, starting with the [VT200] series in 1983. NRCS allowed individual characters from one character set to be replaced by one from another set, allowing the construction of different character sets on the fly. It was used to customize the character set to different local languages, without having to change the terminal's [ROM] for different counties, or alternately, include many different sets in a larger ROM. Many 3rd party terminals and terminal emulators supporting VT200 codes also supported NRCS.

[ASCII] is a 7-bit standard, allowing a total of 128 characters in the character set. Some of these are reserved as control characters, leaving 96 printable characters. This set of 96 includes upper and lower case letters, numbers, and basic math and punctuation.

ASCII does not have enough room to include other common characters such as multi-national currency symbols or the various accented letters common in European languages. This led to a number of country specific varieties of 7-bit ASCII with certain characters replaced. For instance, the UK standard simply replaced ASCII's hash mark, #, with the pound symbol, Â£. This normally led to different models of a given computer terminal or printer, differing only in the [glyphs] stored in ROM. These were standardised as part of ISO/IEC 646.

On an [8-bit clean] serial link, ASCII can be expanded to support a total of 256 characters. In this case, instead of replacing the characters in the original printable characters range from 32 to 127, new characters are added in the 128 to 255 range. This offers enough room for a single character set to include all the variety of characters used in North America and western Europe. This capability led to the introduction of the ISO/IEC 8859-1 standard character set containing 191 characters of what it calls the "Latin alphabet no. 1", but normally referred to as "ISO Latin". [Windows-1252] is a slightly expanded superset of ISO Latin.

NRCS was introduced to solve the problem of requiring different terminals for each country by allowing characters in the basic 7-bit ASCII set to be re-defined by copying the glyph from the DEC's version of ISO Latin, the [Multinational Character Set] (MCS). This meant that the ROM had to store only two character sets, standard ASCII and MCS, and could build any required local ASCII variant on the fly. For instance, instead of having a separate "UK ASCII" version of the terminal with a modified glyph in ROM, the terminal included an NRCS with instructions to replace the hash mark glyph with the pound. When used in the UK, typing Shift 3 produced the pound, the same keys pressed on a US terminal produced hash.

The NRCS could be set through a setup command, or more commonly, by replacing the keyboard with a model that sent back a code when first booted. That way simply plugging in a UK keyboard, which had a pound sign on the 3 key, automatically set the NRSC to that same replacement.
===

Multinational Character Set (MCS)
The Multinational Character Set (MCS) is a character encoding created by [Digital Equipment Corporation] for use in the popular [VT220] terminal. It was an [8-bit] extension of ASCII that added accented characters, currency symbols, and other character [glyphs] missing from 7-bit [ASCII]. It is only one of the code pages implemented for the VT220 [National Replacement Character Set].

Such "[extended ASCII]" sets were common (the National Replacement Character Set provided sets for more than a dozen European languages), but MCS has the distinction of being the ancestor of both [ISO 8859-1] and [Unicode].
===

Extended ASCII
Extended ASCII (or high ASCII) is [8-bit] or larger character encodings that include the standard 7-bit [ASCII] characters as well as others. The use of the term is sometimes criticised, because it can be mistakenly interpreted that the ASCII standard has been updated to include more than 128 characters or that the term unambiguously identifies a single encoding, both of which are untrue.
===

Centronics Data Computer Corporation
Centronics Data Computer Corporation was an American manufacturer of computer printers, now remembered primarily for the [parallel interface] that bears its name.

Centronics began as a division of [Wang Laboratories]. Founded and initially operated by Robert Howard (president) and Samuel Lang (vice president and owner of the well known K & L Color Photo Service Lab in New York City), the group produced remote terminals and systems for the casino industry. Printers were developed to print receipts and transaction reports. Wang spun off the business in 1971 and Centronics was formed as a corporation in Hudson, New Hampshire with Howard as president and chairman.

The Centronics Model 101 was introduced at the 1970 National Computer Conference. The print head used an innovative seven-wire solenoid impact system. Based on this design, Centronics later made the claim to have developed the first dot matrix impact printer.

Howard developed a personal relationship with his neighbour, Max Hugel, the founder and president of [Brother International], the United States arm of Brother Industries, Ltd., a manufacturer of sewing machines and typewriters. A business relationship developed when Centronics needed reliable manufacturing of the printer mechanisms a relationship that would help propel Brother into the printer industry. Hugel would later become executive vice president of Centronics. Print heads and electronics were built in Centronics plants in New Hampshire and Ireland, mechanisms were built in Japan by Brother and the printers were assembled in New Hampshire.

In the 1970s, Centronics formed a relationship with Canon to develop non-impact printers. No products were ever produced, but Canon continued to work on laser printers, eventually developing a highly successful series of engines.

In 1977, Centronics sued competitor Mannesmann AG in a patent dispute regarding the return spring used in the print actuator.

In 1975, Centronics formed an [OEM] agreement with [Tandy] and produced DMP and LP series printers for several years. The 6000 series band printers were introduced in 1978. By 1979 company revenues were over $100 million.

In 1980, the Mini-Printer Model 770 was introduced a small, low-cost desktop serial matrix printer. This was the first printer built completely in-house, and there were problems. Flaws in the microprocessor led to a recall and a stoppage of manufacturing for a year. During this period, Epson, Brother and others began to gain market share and Centronics never recovered. 1980 also saw the introduction of the E Series 900 and 1200 LPM band printers.
===

Dot Matrix Printing
Dot matrix printing or impact matrix printing is a type of computer printing which uses a print head that moves back and forth, or in an up and down motion, on the page and prints by impact, striking an ink soaked cloth ribbon against the paper, much like the print mechanism on a typewriter. However, unlike a typewriter or daisy wheel printer, letters are drawn out of a dot matrix, and thus, varied fonts and arbitrary graphics can be produced.

In the 1970s and 1980s, dot matrix impact printers were generally considered the best combination of expense and versatility, and until the 1990s they were by far the most common form of printer used with personal and home computers.

The [Epson] MX-80, introduced in 1979, was the groundbreaking model that sparked the initial popularity of impact printers in the personal computer market. The MX-80 combined affordability with good quality text output (for its time). Early impact printers (including the MX) were notoriously loud during operation, a result of the hammer like mechanism in the print head. The MX-80 even inspired the name of a noise rock band. The MX-80's low dot density (60 dpi horizontal, 72 dpi vertical) produced printouts of a distinctive "computerised" quality. When compared to the crisp typewriter quality of a daisy-wheel printer, the dot-matrix printer's legibility appeared especially bad. In office applications, output quality was a serious issue, as the dot-matrix text's readability would rapidly degrade with each photocopy generation. [IBM] sold the MX-80 as IBM 5125.
===

Parallel Port
A parallel port is a type of interface found on computers (personal and otherwise) for connecting peripherals. In computing, a parallel port is a parallel communication physical interface. It is also known as a printer port or Centronics port. It was an industry de facto standard for many years, and was finally standardised as IEEE 1284 in the late 1990s, which defined the Enhanced Parallel Port (EPP) and Extended Capability Port (ECP) bi-directional versions. Today, the parallel port interface is seeing decreasing use because of the rise of Universal Serial Bus ([USB]) devices, along with network printing using [Ethernet].

The parallel port interface was originally known as the Parallel Printer Adapter on [IBM PC compatible] computers. It was primarily designed to operate a line printer that used [IBM]'s [8-bit] extended [ASCII] character set to print text, but could also be used to adapt other peripherals. Graphical printers, along with a host of other devices, have been designed to communicate with the system.

The term "Centronics port" now commonly refers to an IEEE-1284 Type B or 36-pin micro ribbon interface. The first parallel interface for printers was introduced with the [Centronics] Model 101 printer in 1970. The interface was developed by Dr. An Wang, Robert Howard and Prentice Robinson at Centronics. [Wang] had a surplus stock of 20,000 Amphenol 36-pin micro ribbon connectors that were originally used for one of their early calculators, which they used to create the Centronics interface on their computers. The connector has become so closely associated with Centronics that it is now popularly known as the âCentronics connectorâ.

The Centronics parallel interface quickly became an industry de facto standard; manufacturers of the time tended to use various connectors on the system side, so a variety of cables were required. For example, early [VAX] systems used a DC-37 connector, NCR used the 36-pin micro ribbon connector, [Texas Instruments] used a 25-pin card edge connector and [Data General] used a 50-pin micro ribbon connector.

When IBM implemented the parallel interface on the IBM PC, they used the DB-25F connector at the PC-end of the interface, creating the now familiar parallel cable with a DB25M at one end and a 36 pin micro ribbon connector at the other. [HP] adopted Centronics parallel on their printer models and introduced a bidirectional version known as Bitronics on the LaserJet 4 in 1992. The Bitronics and Centronics interfaces were superseded by the IEEE 1284 standard in 1994.

Centronics parallel is generally compliant with IEEE 1284 compatibility mode. The original Centronics implementation called for the busy lead to toggle with each received line of data (busy by line), whereas IEEE 1284 calls for busy to toggle with each received character (busy by character). Some host systems or print servers may use a strobe signal with a relatively low voltage output or a fast toggle. Any of these issues might cause no or intermittent printing, missing or repeated characters or garbage printing. Some printer models may have a switch or setting to set busy by character; others may require a handshake adapter.
===

USB - Universal Serial Bus
USB, short for Universal Serial Bus, is an industry standard developed in the mid 1990s that defines the cables, connectors and communications protocols used in a bus for connection, communication, and power supply between computers and electronic devices.

USB was designed to standardise the connection of computer peripherals (including keyboards, pointing devices, digital cameras, printers, portable media players, disk drives and network adapters) to personal computers, both to communicate and to supply electric power. It has become commonplace on other devices, such as smartphones, PDAs and video game consoles. USB has effectively replaced a variety of earlier interfaces, such as serial and parallel ports, as well as separate power chargers for portable devices.

Version History
Release name				Release date
USB 0.8						December 1994		
USB 0.9						April 1995		
USB 0.99					August 1995		
USB 1.0 Release Candidate	November 1995		
USB 1.0						January 1996
USB 1.1						August 1998		
USB 2.0						April 2000
USB 3.0						November 2008
USB 3.1						July 2013

USB 1.x
Released in January 1996, USB 1.0 specified data rates of 1.5 Mbit/s (Low Bandwidth or Low Speed) and 12 Mbit/s (Full Bandwidth or Full Speed). It did not allow for extension cables or pass-through monitors, due to timing and power limitations. Few USB devices made it to the market until USB 1.1 was released in August 1998, fixing problems identified in 1.0, mostly related to using hubs. USB 1.1 was the earliest revision that was widely adopted.

USB 2.0
USB 2.0 was released in April 2000, adding a higher maximum signalling rate of 480 Mbit/s called High Speed, in addition to the USB 1.x Full Speed signalling rate of 12 Mbit/s. Due to bus access constraints, the effective throughput of the High Speed signalling rate is limited to 35 MB/s or 280 Mbit/s.

Further modifications to the USB specification have been made via Engineering Change Notices (ECN). The most important of these ECNs are included into the USB 2.0 specification package available from USB.org.

- Mini-A and Mini-B Connector ECN: Released in October 2000.
	- Specifications for mini-A and B plug and receptacle. Also receptacle that accepts both plugs for On-The-Go. These should not be confused with micro-B plug and receptacle.
- Pull-up/Pull-down Resistors ECN: Released in May 2002
	- Interface Associations ECN: Released in May 2003.
	- New standard descriptor was added that allows associating multiple interfaces with a single device function.
- Rounded Chamfer ECN: Released in October 2003.
	- A recommended, backward compatible change to mini-B plugs that results in longer lasting connectors.
- Unicode ECN: Released in February 2005.
	- This ECN specifies that strings are encoded using UTF-16LE. USB 2.0 specified Unicode, but did not specify the encoding.
- Inter-Chip USB Supplement: Released in March 2006
- On-The-Go Supplement 1.3: Released in December 2006.
	- USB On-The-Go makes it possible for two USB devices to communicate with each other without requiring a separate USB host. In practice, one of the USB devices acts as a host for the other device.
- Battery Charging Specification 1.1: Released in March 2007 and updated on 15 April 2009.
	- Adds support for dedicated chargers (power supplies with USB connectors), host chargers (USB hosts that can act as chargers) and the No Dead Battery provision, which allows devices to temporarily draw 100 mA current after they have been attached. If a USB device is connected to dedicated charger, maximum current drawn by the device may be as high as 1.8 A. (Note that this document is not distributed with USB 2.0 specification package, only USB 3.0 and USB On-The-Go.)
- Micro-USB Cables and Connectors Specification 1.01: Released in April 2007.
- Link Power Management Addendum ECN: Released in July 2007.
	- This adds "sleep", a new power state between enabled and suspended states. Device in this state is not required to reduce its power consumption. However, switching between enabled and sleep states is much faster than switching between enabled and suspended states, which allows devices to sleep while idle.
- Battery Charging Specification 1.2 Released in December 2010.
	- Several changes and increasing limits including allowing 1.5 A on charging ports for unconfigured devices, allowing High Speed communication while having a current up to 1.5 A and allowing a maximum current of 5 A.

USB 3.0
USB 3.0 standard was released in November 2008, defining a new SuperSpeed mode. A USB 3.0 port, usually coloured blue, is backward compatible with USB 2.0 devices and cables.

The USB 3.0 Promoter Group announced on 17 November 2008 that the specification of version 3.0 had been completed and had made the transition to the USB Implementers Forum (USB-IF), the managing body of USB specifications. This move effectively opened the specification to hardware developers for implementation in products.

The new SuperSpeed bus provides a fourth transfer mode with a data signalling rate of 5.0 Gbit/s, in addition to the modes supported by earlier versions. The payload throughput is 4 Gbit/s (due to the overhead induced by used 8b/10b encoding), and the specification considers it reasonable to achieve around 3.2 Gbit/s (0.4 GB/s or 400 MB/s), which should increase with future hardware advances. Communication is full-duplex in SuperSpeed transfer mode; in the modes supported previously, by 1.x and 2.0, communication is half-duplex, with direction controlled by the host.

As with previous USB versions, USB 3.0 ports come in low-power and high-power variants, providing 150 mA and 900 mA respectively, while simultaneously transmitting data at SuperSpeed rates. Additionally, there is a Battery Charging Specification (Version 1.2 â December 2010), which increases the power handling capability to 1.5 A but does not allow concurrent data transmission. The Battery Charging Specification requires that the physical ports themselves be capable of handling 5 A of current but limits the maximum current drawn to 1.5 A.

USB 3.1
A January 2013 press release from the USB group revealed plans to update USB 3.0 to 10 Gbit/s. The group ended up creating a new USB version, USB 3.1, which was released on 31 July 2013, introducing a faster transfer mode called "SuperSpeed USB 10 Gbit/s", putting it on par with a single first-generation Thunderbolt channel. The new mode's logo features a "Superspeed+" caption (stylised as SUPERSPEED+). The USB 3.1 standard increases the data signalling rate to 10 Gbit/s in the USB 3.1 Gen2 mode, double that of USB 3.0 (referred to as USB 3.1 Gen1) and reduces line encoding overhead to just 3% by changing the encoding scheme to 128b/132b. The first USB 3.1 implementation demonstrated transfer speeds of 7.2 Gbit/s.

The USB 3.1 standard is backward compatible with USB 3.0 and USB 2.0.

USB Type-C
Developed at roughly the same time as the USB 3.1 specification, but distinct from it, the USB Type-C Specification 1.0 defines a new small reversible plug connector for USB devices. The Type-C plug connects to both hosts and devices, replacing various Type-B and Type-A connectors and cables with a standard meant to be future proof, similar to [Apple] Lightning and Thunderbolt. The 24-pin double-sided connector provides four power / ground pairs, two differential pairs for USB 2.0 data bus (though only one pair is implemented in a Type-C cable), four pairs for high-speed data bus, two "sideband use" pins, and two configuration pins for cable orientation detection, dedicated biphase mark code (BMC) configuration data channel, and VCONN +5 V power for active cables. Type-A and Type-B adaptors and cables will be required for older devices in order to plug into Type-C hosts; adaptors and cables with a Type-C receptacle are not allowed.

Full-featured USB Type-C cables are active, electronically marked cables that contain a chip with an ID function based on the configuration data channel and vendor defined messages (VDMs) from the USB Power Delivery 2.0 specification. USB Type-C devices also support power currents of 1.5 A and 3.0 A over the 5 V power bus in addition to baseline 900 mA; devices can either negotiate increased USB current through the configuration line, or they can support the full Power Delivery specification using both BMC-coded configuration line and legacy BFSK-coded VBUS line.

Alternate Mode dedicates some of the physical wires in the Type-C cable for direct device-to-host transmission of alternate data protocols. The four high-speed lanes, two sideband pins, andââfor dock, detachable device and permanent cable applications only two USB 2.0 pins and one configuration pin can be used for Alternate Mode transmission. The modes are configured using VDMs through the configuration channel.
===

Sound Blaster
The Sound Blaster family of sound cards was the de facto standard for consumer audio on the [IBM PC compatible] system platform, until the widespread transition to [Microsoft Windows 95], which standardised the programming interface at application level (eliminating the importance of backward compatibility with Sound Blaster), and the evolution in PC design led to onboard motherboard-audio, which commoditised PC audio functionality.

The creator of Sound Blaster is the Singapore based firm [Creative Technology Limited], also known by the name of its United States subsidiary, Creative Labs.

Sound Blaster 16
The Sound Blaster 16, announced in June 1992, introduced:

- 16-bit CD-quality digital audio sampling;
- An MPU-401 compatible UART;
- A socket for the optional Advanced Signal Processor or Creative Signal Processor chip (ASP or later CSP); and
- A connector for the Wave Blaster, a 'Wavetable' daughterboard (sample-based synthesis).

The Sound Blaster 16 retained the Yamaha OPL-3 for FM synthesis and a backward compatible programming interface, so most software titles written for the older Sound Blasters and Sound Blaster Pros would run without modification.

Eventually this design proved so popular that Creative made a [PCI] version of this card. Moving the card off the [ISA] bus, which was already approaching obsolescence, meant that no line for host controlled ISA DMA was available, as the PCI slot offers no such line. Instead, the card used PCI bus mastering to transfer data from the main memory to the D/A converters. Since existing [DOS] programs expected to be able to initiate host controlled ISA DMA for producing sound, backward compatibility with the older Sound Blaster cards for DOS programs required a software driver work around; since this work around necessarily depended on the virtual [8086] mode of the PC's CPU in order to catch and reroute accesses from the ISA DMA controller to the card itself, it failed for a number of DOS games that either were not fully compatible with this CPU mode or needed so much free conventional memory that they could not be loaded with the driver occupying part of this memory. In [Microsoft Windows], there was no problem, as Creative's Windows driver software could handle both ISA and PCI cards correctly.

Sound Blaster AWE32
Released in March 1994, the Sound Blaster AWE32 (Advanced Wave Effects) introduced an all new MIDI synthesizer section based on the EMU8000. The AWE32 consisted of two distinct audio sections; the Creative digital audio section (audio codec, optional CSP/ASP chip socket, Yamaha OPL3), and the E-mu MIDI synthesizer section. The synthesizer section consisted of the EMU8000 sampler and effects processor, an EMU8011 1 MB sample ROM, and 512 KB of sample RAM (expandable to 28 MB). To fit the new hardware, the AWE32 was a full-length ISA card, measuring 14 in (360 mm).

Sound Blaster 32
A derivative of the AWE32 design, the Sound Blaster 32 (SB32) was a value-oriented offering from Creative. Announced on 6 June 1995, the SB32 became the new entry-level card in the AWE32 product-line (previously held by the AWE32 Value). The SB32 retained the AWE32's EMU8000/EMU8011 MIDI-synthesis engine and built-in instrument ROM, but dropped the onboard RAM, the Wave Blaster header, and the CSP port. The SB32 used the Vibra chip to reduce component count, which meant bass/treble/gain control was limited compared to the AWE32. The loss of onboard RAM is offset by the inclusion of 30-pin SIMM RAM sockets, which allow up to 8 MB RAM to be installed and used by the EMU engine.

Sound Blaster AWE64
The AWE32's successor, the Sound Blaster AWE64 (November 1996), was significantly smaller, being a "half-length ISA card". It offered similar features to the AWE32, but also had a few notable improvements, including support for greater polyphony, although this was a product of 32 extra software emulated channels. The 30-pin SIMM slots from AWE32/SB32 were replaced with a proprietary memory format which could be (expensively) purchased from Creative.

The main improvements were better compatibility with older SB models, and an improved signal-to-noise ratio. The AWE64 came in three versions: A Value version (with 512KB of RAM), a Standard version (with 1 MB of RAM), and a Gold version (with 4 MB of RAM and a separate S/PDIF output).
===

Industry Standard Architecture (ISA)
Industry Standard Architecture (ISA) is a retronym term for the [16-bit] internal bus of [IBM PC/AT] and similar computers based on the [Intel 80286] and its immediate successors during the 1980s. The bus was (largely) backward compatible with the [8-bit] bus of the [8088] based [IBM PC], including the [IBM PC/XT] as well as [IBM PC compatibles].

Originally referred to as the PC/AT-bus it was also termed I/O Channel by [IBM]. The ISA concept was coined by competing PC-clone manufacturers in the late 1980s or early 1990s as a reaction to IBM attempts to replace the AT-bus with its new and incompatible Micro Channel architecture.

The 16-bit ISA bus was used also with 32-bit processors for several years. An attempt to extend it to 32 bits, called Extended Industry Standard Architecture (EISA), was not very successful, however. Later buses such as [VESA Local Bus] and [PCI] were used instead, often along with ISA slots on the same mainboard. A derivative of the AT bus structure is still used in the PCMCIA standard, Compact Flash, the PC/104 bus, and internally within Super I/O chips.
===

Conventional PCI
Conventional PCI, often shortened to PCI, is a local computer bus for attaching hardware devices in a computer. PCI is the initialism for Peripheral Component Interconnect and is part of the PCI Local Bus standard. The PCI bus supports the functions found on a processor bus but in a standardised format that is independent of any particular processor's native bus. Devices connected to the PCI bus appear to a bus master to be connected directly to its own bus and are assigned addresses in the processor's address space. It is a parallel bus, synchronous to a single bus clock.

Attached devices can take either the form of an integrated circuit fitted onto the motherboard itself (called a planar device in the PCI specification) or an expansion card that fits into a slot. The PCI Local Bus was first implemented in [IBM PC compatibles], where it displaced the combination of several slow [ISA] slots and one fast [VESA Local Bus] slot as the bus configuration. It has subsequently been adopted for other computer types. Typical PCI cards used in PCs include: network cards, sound cards, modems, extra ports such as [USB] or serial, TV tuner cards and disk controllers. PCI video cards replaced ISA and VESA cards until growing bandwidth requirements outgrew the capabilities of PCI. The preferred interface for video cards then became AGP, itself a superset of conventional PCI, before giving way to PCI Express.

The first version of conventional PCI found in consumer desktop computers was a 32-bit bus using a 33 MHz bus clock and 5 V signalling, although the PCI 1.0 standard provided for a 64-bit variant as well. These have one locating notch in the card. Version 2.0 of the PCI standard introduced 3.3 V slots, physically distinguished by a flipped physical connector to preventing accidental insertion of 5 V cards. Universal cards, which can operate on either voltage, have two notches. Version 2.1 of the PCI standard introduced optional 66 MHz operation. A server-oriented variant of conventional PCI, called PCI-X (PCI Extended) operated at frequencies up to 133 MHz for PCI-X 1.0 and up to 533 MHz for PCI-X 2.0. An internal connector for laptop cards, called Mini PCI, was introduced in version 2.2 of the PCI specification. The PCI bus was also adopted for an external laptop connector standardâthe CardBus. The first PCI specification was developed by Intel, but subsequent development of the standard became the responsibility of the PCI Special Interest Group (PCI-SIG).

Conventional PCI and PCI-X are sometimes called Parallel PCI in order to distinguish them technologically from their more recent successor PCI Express, which adopted a serial, lane-based architecture. Conventional PCI's heyday in the desktop computer market was approximately the decade 1995 - 2005. PCI and PCI-X have become obsolete for most purposes; however, they are still common on modern desktops for the purposes of backwards compatibility and the low relative cost to produce. Many kinds of devices previously available on PCI expansion cards are now commonly integrated onto motherboards or available in universal serial bus and PCI Express versions.
===

VESA Local Bus 
The VESA Local Bus (usually abbreviated to VL-Bus or VLB) was mostly used in personal computers. VESA (Video Electronics Standards Association) Local Bus worked alongside the [ISA] bus; it acted as a high-speed conduit for memory-mapped I/O and DMA, while the ISA bus handled interrupts and port-mapped I/O.
===

DOSBox
DOSBox is an emulator program that emulates an [IBM PC compatible] computer running a [DOS] operating system. Many IBM PC compatible graphics and sound cards are also emulated. This means that original DOS programs (including PC games) are provided an environment in which they can run correctly, even though the modern computers have dropped support for that old environment. DOSBox is free software written primarily in [C++] and distributed under the [GNU General Public License]. DOSBox has been downloaded over 25 million times since its release on SourceForge in 2002.

DOSBox can run old DOS software on modern computers which would not work otherwise, because of incompatibilities between the older software and modern hardware and operating systems.

A number of usability enhancements have been added to DOSBox beyond emulating DOS. The added features include virtual hard drives, peer-to-peer networking, screen capture and screencasting from the emulated screen.

The original DOSBox has not been updated in a long time. Active development is happening on forks of DOSBox. Forks such as SVN Daum and DOSBox-X provide additional features, which include support for save states and long filenames.

A number of vintage DOS games have been re-released by video game developers to run on modern computers by encapsulating them inside DOSBox.
===

Character Encoding
In computing, a character encoding is used to represent a repertoire of characters by some kind of an encoding system. Depending on the abstraction level and context, corresponding code points and the resulting code space may be regarded as bit patterns, octets, natural numbers, electrical pulses, etc. A character encoding is used in computation, data storage, and transmission of textual data. Terms such as character set, character map, codeset or code page are sometimes used as near synonyms; however, these terms have related but distinct meanings described in the article.

Early character codes associated with the optical or electrical telegraph could only represent a subset of the characters used in written languages, sometimes restricted to upper case letters, numerals and some punctuation only. The low cost of digital representation of data in modern computer systems allows more elaborate character codes (such as [Unicode]) which represent more of the characters used in many written languages. Character encoding using internationally accepted standards permits worldwide interchange of text in electronic form.
===

ISO/IEC 8859-1
ISO/IEC 8859-1 is a [8-bit] single-byte coded graphic character sets â Part 1: Latin alphabet No. 1, is part of the ISO/IEC 8859 series of [ASCII] based standard character encodings, first edition published in 1987. It is generally intended for Western European languages. It is the basis for most popular 8-bit character sets, including [Windows-1252] and the first block of characters in [Unicode].

ISO-8859-1 is the IANA preferred name for this standard when supplemented with the C0 and C1 control codes from ISO/IEC 6429. The following other aliases are registered for ISO-8859-1: iso-ir-100, csISOLatin1, latin1, l1, IBM819, CP819.

The Windows-1252 codepage coincides with ISO-8859-1 for all codes except the range 128 to 159 (hex 80 to 9F), where the little used C1 controls are replaced with additional characters including all the missing characters provided by ISO-8859-15. Code page 28591 a.k.a. Windows-28591 is the actual ISO-8859-1 codepage.
===

UTF-8
UTF-8 is a character encoding capable of encoding all possible characters, or code points, in [Unicode].

The encoding is variable length and uses [8-bit] code units. It was designed for backward compatibility with [ASCII], and to avoid the complications of endianness and byte order marks in the alternative [UTF-16] and [UTF-32] encodings. The name is derived from: Universal Coded Character Set + Transformation Formatâ8-bit.

UTF-8 is the dominant character encoding for the [World Wide Web], accounting for 84.3% of all Web pages in July 2015. The Internet Mail Consortium (IMC) recommends that all e-mail programs be able to display and create mail using UTF-8, and the [W3C] recommends UTF-8 as the default encoding in [XML] and [HTML].

UTF-8 encodes each of the 1,112,064 valid code points in the Unicode code space (1,114,112 code points minus 2,048 surrogate code points) using one to four 8-bit bytes (a group of 8 bits is known as an octet in the Unicode Standard). Code points with lower numerical values (i.e., earlier code positions in the Unicode character set, which tend to occur more frequently) are encoded using fewer bytes. The first 128 characters of Unicode, which correspond one-to-one with ASCII, are encoded using a single octet with the same binary value as ASCII, making valid ASCII text valid UTF-8-encoded Unicode as well. And ASCII bytes do not occur when encoding non-ASCII code points into UTF-8, making UTF-8 safe to use within most programming and document languages that interpret certain ASCII characters in a special way, e.g. as end of string.
===

UTF-16
UTF-16 (16-bit [Unicode] Transformation Format) is a character encoding capable of encoding all 1,112,064 possible characters in Unicode. The encoding is variable-length, as code points are encoded with one or two [16-bit] code units. (also see Comparison of Unicode encodings for a comparison of [UTF-8], UTF-16 & [UTF-32])

UTF-16 developed from an earlier fixed-width 16-bit encoding known as UCS-2 (for 2-byte Universal Character Set) once it became clear that a fixed-width 2-byte encoding could not encode enough characters to be truly universal.
===

UTF-32
UTF-32 (or UCS-4) stands for [Unicode] Transformation Format [32-bits]. It is a protocol to encode Unicode characters that uses exactly 32-bits per Unicode code point. This makes UTF-32 a fixed-length encoding, in contrast to all other Unicode transformation formats which are variable-length encodings. The UTF-32 form of a character is a direct representation of its codepoint.

The main advantage of UTF-32, versus variable-length encodings, is that the Unicode code points are directly indexable. Examining the n'th code point is a constant time operation. In contrast, a variable-length code requires sequential access to find the n'th code point. This makes UTF-32 a simple replacement in code that uses integers to index characters out of strings, as was commonly done for [ASCII].

The main disadvantage of UTF-32 is that it is space inefficient, using four bytes per character. Non-BMP characters are so rare in most texts, they may as well be considered non-existent for sizing issues, making UTF-32 up to twice the size of UTF-16 and up to four times the size of UTF-8.
===

Windows-1252
Windows-1252 or CP-1252 is a character encoding of the Latin alphabet, used by default in the legacy components of [Microsoft Windows] in English and some other Western languages. It is one version within the group of [Windows code pages].

This character encoding is a superset of [ISO 8859-1], but differs from the IANA's ISO-8859-1 by using displayable characters rather than control characters in the 80 to 9F (hex) range. Notable additional characters are curly quotation marks, the Euro sign, and all the printable characters that are in ISO 8859-15. It is known to Windows by the code page number 1252, and by the IANA-approved name "windowsâ1252".

It is very common to mislabel Windows-1252 text with the charset label ISO-8859-1. A common result was that all the quotes and apostrophes (produced by "smart quotes" in word-processing software) were replaced with question marks or boxes on non-Windows operating systems, making text difficult to read. Most modern web browsers and e-mail clients treat the [MIME] charset ISO-8859-1 as Windows-1252 to accommodate such mislabeling. This is now standard behaviour in the [HTML 5] specification, which requires that documents advertised as ISO-8859-1 actually be parsed with the Windows-1252 encoding.

Historically, the phrase "ANSI Code Page" (ACP) is used in [Windows] to refer to various code pages considered as native. The intention was that most of these would be ANSI standards such as ISO-8859-1. Even though Windows-1252 was the first and by far most popular code page named so in Microsoft Windows parlance, the code page has never been an ANSI standard. Microsoft explains, "The term ANSI as used to signify Windows code pages is a historical reference, but is nowadays a misnomer that continues to persist in the Windows community."
===

Windows Code Pages
Windows code pages are sets of characters or code pages (known as character encodings in other operating systems) used in [Microsoft Windows] from the 1980s and 1990s. Windows code pages were gradually superseded when Unicode was implemented in Windows, although they are still supported both within Windows and other platforms.

There are two groups of code pages in Windows systems: OEM and ANSI code pages. Code pages in both of these groups are extended [ASCII] code pages.

ANSI code page
ANSI code pages (officially called "Windows code pages" after [Microsoft] accepted the former term being a misnomer) are used for native non-Unicode (say, byte oriented) applications using a graphical user interface on Windows systems. ANSI Windows code pages, and especially the code page 1252, were called that way since they were purportedly based on drafts submitted or intended for ANSI. However, ANSI and ISO have not standardised any of these code pages. Instead they are either supersets of the standard sets such as those of ISO 8859 and the various national standards (like Windows-1252 vs. ISO-8859-1), major modifications of these (making them incompatible to various degrees, like Windows-1250 vs. ISO-8859-2) or having no parallel encoding (like Windows-1257 vs. ISO-8859-4; ISO-8859-13 was introduced much later). About twelve of the typography and business characters from CP1252 at code points 0x80â0x9F (in ISO 8859 occupied by C1 control codes, which are useless in Windows) are present in many other ANSI / Windows code pages at the same codes. These code pages are labelled by Internet Assigned Numbers Authority ([IANA]) as "Windows-number".

OEM code page
The OEM code pages (original equipment manufacturer) are used by Win32 console applications, and by virtual DOS, and can be considered a holdover from [DOS] and the original [IBM PC] architecture. A separate suite of code pages was implemented not only due to compatibility, but also because the fonts of [VGA] (and descendant) hardware suggest encoding of line drawing characters to be compatible with code page 437. Most OEM code pages share many code points, particularly for non-letter characters, with the second (non-ASCII) half of CP437.

A typical OEM code page, in its second half, does not resemble any ANSI / Windows code page even roughly. Nevertheless, two single-byte, fixed-width code pages (874 for Thai and 1258 for Vietnamese) and four multibyte CJK code pages (932, 936, 949, 950) are used as both OEM and ANSI code pages. Code page 1258 uses combining diacritics, as Vietnamese requires more than 128 letter-diacritic combinations. This is in contrast to VISCII, which replaces some of the C0 (i.e. ASCII) control codes.

Windows Code Pages

ID		Names					Description						Type		Base				Encoding	Standard
37		CP037, IBM037			IBM EBCDIC US-Canada			Other		EBCDIC derivation	8-bit SBCS	IBM CP037	
437		CP437, IBM437			IBM PC US						OEM			ASCII derivation	8-bit SBCS	IBM CP437	
1250	CP1250, Windows-1250	Latin 2 / Central European		ANSI		ASCII derivation	8-bit SBCS	Microsoft CP1250	
1251	CP1251, Windows-1251	Cyrillic						ANSI		ASCII derivation	8-bit SBCS	Microsoft CP1251	
1252	CP1252, Windows-1252	Latin 1 / Western European		ANSI		ASCII derivation	8-bit SBCS	Microsoft CP1252
1253	CP1253, Windows-1253	Greek							ANSI		ASCII derivation	8-bit SBCS	Microsoft CP1253	
1254	CP1254, Windows-1254	Turkish							ANSI		ASCII derivation	8-bit SBCS	Microsoft CP1254		
1255	CP1255, Windows-1255	Hebrew							ANSI		ASCII derivation	8-bit SBCS	Microsoft CP1255	
1256	CP1256, Windows-1256	Arabic							ANSI		ASCII derivation	8-bit SBCS	Microsoft CP1256	
1257	CP1257, Windows-1257	Baltic							ANSI		ASCII derivation	8-bit SBCS	Microsoft CP1257		
1258	CP1258, Windows-1258	Vietnamese						OEM + ANSI	?					8-bit SBCS	Microsoft CP1258

====

Unicode
Unicode is a computing industry standard for the consistent encoding, representation, and handling of text expressed in most of the world's writing systems. Developed in conjunction with the Universal Character Set standard and published as The Unicode Standard, the latest version of Unicode contains a repertoire of more than 120,000 characters covering 129 modern and historic scripts, as well as multiple symbol sets. The standard consists of a set of code charts for visual reference, an encoding method and set of standard character encodings, a set of reference data files, and a number of related items, such as character properties, rules for normalization, decomposition, collation, rendering, and bidirectional display order (for the correct display of text containing both right-to-left scripts, such as Arabic and Hebrew, and left-to-right scripts).[1] As of June 2015, the most recent version is Unicode 8.0. The standard is maintained by the Unicode Consortium.

Unicode's success at unifying character sets has led to its widespread and predominant use in the internationalization and localization of computer software. The standard has been implemented in many recent technologies, including modern operating systems, XML, the Java programming language, and the Microsoft .NET Framework.

Unicode can be implemented by different character encodings. The most commonly used encodings are UTF-8, UTF-16 and the now-obsolete UCS-2. UTF-8 uses one byte for any ASCII character, all of which have the same code values in both UTF-8 and ASCII encoding, and up to four bytes for other characters. UCS-2 uses a 16-bit code unit (two 8-bit bytes) for each character but cannot encode every character in the current Unicode standard. UTF-16 extends UCS-2, using one 16-bit unit for the characters that were representable in UCS-2 and two 16-bit units (4 Ã 8 bit) to handle each of the additional characters.
===

Universal Coded Character Set (UCS)
The Universal Coded Character Set (UCS), defined by the International Standard ISO/IEC 10646, Information technology â Universal Coded Character Set (UCS) (plus amendments to that standard), is a standard set of characters upon which many character encodings are based. The UCS contains nearly one hundred thousand abstract characters, each identified by an unambiguous name and an integer number called its code point.

Characters (letters, numbers, symbols, ideograms, logograms, etc.) from the many languages, scripts, and traditions of the world are represented in the UCS with unique code points. The inclusiveness of the UCS is continually improving as characters from previously unrepresented writing systems are added.

Since 1991, the Unicode Consortium has worked with ISO to develop The Unicode Standard ("Unicode") and ISO/IEC 10646 in tandem. The repertoire, character names, and code points of Version 2.0 of Unicode exactly match those of ISO/IEC 10646-1 with its first seven published amendments. After the publication of [Unicode] 3.0 in February 2000, corresponding new and updated characters entered the UCS via ISO/IEC 10646-1. In 2003, parts 1 and 2 of ISO/IEC 10646 were combined into a single part, which has since had a number of amendments adding characters to the standard in approximate synchrony with the Unicode standard.

The UCS has over 1.1 million code points available for use, but only the first 65,536 (the Basic Multilingual Plane, or BMP) had entered into common use before 2000. This situation began changing when the People's Republic of China (PRC) ruled in 2000 that all software sold in its jurisdiction would have to support GB 18030. This required software intended for sale in the PRC to move beyond the BMP.

The system deliberately leaves many code points not assigned to characters, even in the BMP. It does this to allow for future expansion or to minimize conflicts with other encoding forms.
===

Punched Card
A punched card, punch card, IBM card, or Hollerith card is a piece of stiff paper that contained either commands for controlling automated machinery or data for data processing applications. Both commands and data were represented by the presence or absence of holes in predefined positions.

Now obsolete as a recording medium, punched cards were widely used throughout the 20th century for controlling textile looms and in the late 19th and early 20th century for controlling fairground organs and related instruments. Punched cards were used through most of the 20th century in what became known as the data processing industry; the use of unit record machines, organised into data processing systems, for data input, processing, and storage. Early digital computers used punched cards, often prepared using keypunch machines, as the primary medium for input of both computer programs and data.
==

Punched Tape
Punched tape or perforated paper tape is a form of data storage, consisting of a long strip of paper in which holes are punched to store data. Now effectively obsolete, it was widely used during much of the twentieth century for teleprinter communication, for input to computers of the 1950s and 1960s, and later as a storage medium for minicomputers and [CNC] machine tools.

The earliest forms of punched tape come from weaving looms and embroidery, where cards with simple instructions about a machine's intended movements were first fed individually as instructions, then controlled by instruction cards, and later were fed as a string of connected cards.

This led to the concept of communicating data not as a stream of individual cards, but one "continuous card", or a tape. Many professional embroidery operations still refer to those individuals who create the designs and machine patterns as "punchers", even though punched cards and paper tape were eventually phased out, after many years of use, in the 1990s.

Tape Formats
Data were represented by the presence or absence of a hole at a particular location. Tapes originally had five rows of holes for data. Later tapes had 6, 7 and 8 rows. An early electro-mechanical calculating machine, the Automatic Sequence Controlled Calculator or Harvard Mark I, used paper tape with 24 rows. A row of narrower holes that were always punched served to feed the tape, originally using a wheel with radial teeth called a sprocket wheel. Later optical readers used the sprocket holes to generate timing pulses.

Text was encoded in several ways. The earliest standard character encoding was Baudot, which dates back to the nineteenth century and had 5 holes. The Baudot code was never used in teleprinters. Instead, modifications such as the Murray code (which added carriage return and line feed), Western Union code, International Telegraphic Alphabet #2 (ITA 2), and American Teletypewriter code (USTTY), were used. Other standards, such as Teletypesetter (TTS), Fieldata and Flexowriter, had 6 holes. In the early 1960s, the American Standards Association led a project to develop a universal code for data processing, which became known as [ASCII]. This 7-level code was adopted by some teleprinter users, including AT&amp;T (Teletype). Others, such as Telex, stayed with the earlier codes.

Dimensions
Tape for punching was 0.00394 inches (0.1 mm) thick. The two most common widths were 11/16 inch (17.46 mm) for five bit codes, and 1 inch (25.4 mm) for tapes with six or more bits. Hole spacing was 0.1 inch (2.54 mm) in both directions. Data holes were 0.072 inches (1.83 mm) in diameter; feed holes were 0.046 inches (1.17 mm). Paper tape rolls in both widths are still commercially available as of 2012.

Chad
Most tape-punching equipment used solid punches to create holes in the tape. This process inevitably created "chad", or small circular pieces of paper. Managing the disposal of chad was an annoying and complex problem, as the tiny paper pieces had a tendency to escape and interfere with the other electromechanical parts of the teleprinter equipment.
===

Disc Filing System (DFS)
The Disc Filing System (DFS) is a computer file system developed by [Acorn Computers], initially as an add-on to the Eurocard-based Acorn System 2.

In 1981, the Education Departments of Western Australia and South Australia announced joint tenders calling for the supply of personal computers to their schools. Acorn's Australian computer distributor, Barson Computers, convinced Joint Managing Directors Hermann Hauser and Chris Curry to allow the soon to be released [Acorn BBC Microcomputer] to be offered with disk storage as part of the bundle. They agreed on condition that Barson adapted the Acorn DFS from the System 2 without assistance from Acorn as they had no resources available. This required some minor hardware and software changes to make the DFS compatible with the BBC Micro.

Barson won the tenders for both states, with the DFS fitted, a year ahead of the UK. It was this early initiative that resulted in the BBC Micro being more heavily focused on the education market in Australia, with very little penetration of the home computer market until the arrival of the [Acorn Electron].

The DFS shipped as a [ROM] and Disk Controller Chip fitted to the BBC Micro's motherboard. The filing system was of extremely limited functionality and storage capability, using a flat directory structure. Each filename can be up to seven letters long, plus one letter for the directory in which the file is stored.

The DFS is remarkable in that unlike most filing systems, there was no single vendor or implementation. The original DFS was written by Acorn, who continued to maintain their own codebase, but various disc drive vendors wrote their own implementations. Companies who wrote their own DFS implementation included Cumana, Opus and [Watford Electronics]. The Watford Electronics implementation is notable for supporting 62 files per disc instead of the usual 31, using a non-standard disc format. Other features in third-party implementations included being able to review free space, and built-in FORMAT and VERIFY commands, which were shipped on a utility disc with the original Acorn DFS.

Acorn followed up their original DFS series with the Acorn 1770 DFS, which used the same disc format as the earlier version but added a set of extra commands and supported the improved WD1770 floppy drive controller chip.
===

Advanced Disc Filing System (ADFS) 
The Advanced Disc Filing System (ADFS) is a computing file system particular to the [Acorn] computer range and RISC OS-based successors. Initially based on the rare Acorn Winchester Filing System, it was renamed to the Advanced Disc Filing System when support for floppy discs was added (utilising a WD1770 floppy disc controller) and on later 32-bit systems a variant of a PC-style floppy controller.

Acorn's original [Disc Filing System] was limited to 31 files per disk surface, 7 characters per file name and a single character for directory names, a format inherited from the earlier [Atom] and System 3â5 Eurocard computers. To overcome some of these restrictions Acorn developed ADFS. The most dramatic change was the introduction of a hierarchical directory structure. The filename length increased from 7 to 10 letters and the number of files in a directory expanded to 47. It retained some superficial attributes from DFS; the directory separator continued to be a dot and $ now indicated the hierarchical root of the filesystem. "^" (minus the quotes) was used to refer to the parent directory and "\" was the previously-visited directory.

The [BBC Master Compact] contained ADFS Version 2.0, which provided the addition of format, verify and backup commands in [ROM].
===

Floppy Disk
A floppy disk, also called a diskette, is a disk storage medium composed of a disk of thin and flexible magnetic storage medium, sealed in a rectangular plastic carrier lined with fabric that removes dust particles. Floppy disks are read and written by a floppy disk drive (FDD).

Floppy disks, initially as 8-inch (200 mm) media and later in 5Â¼-inch (133 mm) and 3Â½-inch (90 mm) sizes, were a ubiquitous form of data storage and exchange from the mid 1970s well into the 2000s.

By 2010, computer motherboards were rarely manufactured with floppy drive support; 3Â½-inch floppy disks can be used with an external USB floppy disk drive, but USB drives for 5Â¼-inch, 8-inch and non-standard diskettes are rare or non-existent, and those formats must usually be handled by old equipment.

While floppy disk drives still have some limited uses, especially with legacy industrial computer equipment, they have been superseded by data storage methods with much greater capacity, such as USB flash drives, portable external hard disk drives, optical discs, memory cards and computer networks.

8-inch Floppy Disk
The first floppy disk was 8 inches in diameter, was protected by a flexible plastic jacket and was a read-only device used by [IBM] as a way of loading microcode. Read / Write floppy disks and their drives became available in 1972 but it was IBM's 1973 introduction of the 3740 data entry system that began the establishment of floppy disks, called by IBM the "Diskette 1," as an industry standard for information interchange. Early microcomputers used for engineering, business, or word processing often used one or more 8-inch disk drives for removable storage; the [CP/M] operating system was developed for microcomputers with 8-inch drives.

The family of 8-inch disks and drives increased over time and later versions could store up to 1.2MB many microcomputer applications did not need that much capacity on one disk, so a smaller size disk with lower-cost media and drives was feasible. The 5Â¼-inch inch drive succeeded the 8-inch size in many applications, and developed to about the same storage capacity as the original 8-inch size, using higher-density media and recording techniques.

5Â¼-inch Floppy Disk
The head gap of an 80âtrack high-density (1.2MB in the MFM format) 5Â¼âinch drive (a.k.a. Mini diskette, Mini disk, or Minifloppy) is smaller than that of a 40âtrack double-density (360KB) drive but can format, read and write 40âtrack disks well provided the controller supports double stepping or has a switch to do such a process. A blank 40âtrack disk formatted and written on an 80âtrack drive can be taken to its native drive without problems, and a disk formatted on a 40âtrack drive can be used on an 80âtrack drive. Disks written on a 40âtrack drive and then updated on an 80 track drive become unreadable on any 40âtrack drives due to track width incompatibility.

Single sided disks were coated on both sides, despite the availability of more expensive double sided disks. The reason usually given for the higher cost was that double sided disks were certified error-free on both sides of the media. Architectural differences among computer platforms negated this claim, however, with RadioShack TRS-80 Model I computers using one side and the Apple II machines the other. Double-sided disks could be used in drives for single-sided disks, one side at a time, by turning them over (flippy disks); more expensive dual-head drives which could read both sides without turning over were later produced, and eventually became used universally.

3Â½-inch Floppy Disk
In the early 1980s, a number of manufacturers introduced smaller floppy drives and media in various formats. A consortium of 21 companies eventually settled on a 3Â½-inch floppy disk (actually 90 mm wide) a.k.a. Micro diskette, Micro disk, or Micro floppy, similar to a [Sony] design, but improved to support both single-sided and double-sided media, with formatted capacities generally of 360KB and 720KB respectively. Single-sided drives shipped in 1983, and double sided in 1984. What became the most common format, the double-sided, high-density (HD) 1.44MB disk drive, shipped in 1986.

The first [Macintosh] computers used single-sided 3Â½-inch inch floppy disks, but with 400KB formatted capacity. These were followed in 1986 by double-sided 800KB floppies. The higher capacity was achieved at the same recording density by varying the disk rotation speed with arm position so that the linear speed of the head was closer to constant. Later Macs could also read and write 1.44MB HD disks in [PC] format with fixed rotation speed.

All 3Â½-inch disks have a rectangular hole in one corner which, if obstructed, write-enabled the disk. The HD 1.44MB disks have a second, unobstructed hole in the opposite corner which identifies them as being of that capacity.

In [IBM-compatible PCs], the three densities of 3Â½-inch floppy disks are backwards-compatible: higher density drives can read, write and format lower density media. It is physically possible to format a disk at the wrong density, although the resulting disk will not work properly. Fresh disks manufactured as high density can theoretically be formatted at double density only if no information has been written on the disk in high density, or the disk has been thoroughly demagnetised with a bulk eraser, as the magnetic strength of a high density record is stronger and overrides lower density, remaining on the disk and causing problems.

Writing at different densities than disks were intended for, sometimes by altering or drilling holes, was possible but deprecated. The holes on the right side of a 3Â½âinch disk can be altered as to make some disk drives and operating systems treat the disk as one of higher or lower density, for bidirectional compatibility or economical reasons. Some computers, such as the [PS/2] and [Acorn Archimedes], ignored these holes altogether.

It is possible to make a 3Â½-inch floppy disk drive be recognised by a system as a 5Â¼âinch 360KB or 1200KB drive, and to read and write disks with the same number of tracks and sectors as those disks; this had some application in data exchange with obsolete [CP/M] systems.
==

Hard Disk Drive (HDD)
A hard disk drive (HDD), hard disk, hard drive or fixed disk is a data storage device used for storing and retrieving digital information using one or more rigid ("hard") rapidly rotating disks (platters) coated with magnetic material. The platters are paired with magnetic heads arranged on a moving actuator arm, which read and write data to the platter surfaces. Data is accessed in a random-access manner, meaning that individual blocks of data can be stored or retrieved in any order rather than sequentially. An HDD retains its data even when powered off.

Introduced by [IBM] in 1956, HDDs became the dominant secondary storage device for general purpose computers by the early 1960s. Continuously improved, HDDs have maintained this position into the modern era of servers and personal computers. More than 200 companies have produced HDD units, though most current units are manufactured by [Seagate], [Toshiba] and [Western Digital].

The primary characteristics of an HDD are its capacity and performance. Capacity is specified in unit prefixes corresponding to powers of 1000: a 1-terabyte (TB) drive has a capacity of 1,000 gigabytes (GB; where 1 gigabyte = 1 billion bytes). Typically, some of an HDD's capacity is unavailable to the user because it is used by the file system and the computer operating system, and possibly inbuilt redundancy for error correction and recovery. Performance is specified by the time required to move the heads to a track or cylinder (average access time) plus the time it takes for the desired sector to move under the head (average latency, which is a function of the physical rotational speed in revolutions per minute), and finally the speed at which the data is transmitted (data rate).

The two most common form factors for modern HDDs are 3.5-inch, for desktop computers, and 2.5-inch, primarily for laptops. HDDs are connected to systems by standard interface cables such as SATA (Serial ATA), USB or SAS (Serial attached SCSI) cables.

As of 2015, the primary competing technology for secondary storage is flash memory in the form of solid-state drives ([SSD]s), which have higher data transfer rates and significantly lower latency and access times, but HDDs remain the dominant medium for secondary storage due to advantages in price per unit of storage and recording capacity. However, SSDs are replacing HDDs where speed, power consumption and durability are more important considerations.
===

Solid State Drive (SSD) 
A solid state drive (SSD) (also known as a solid state disk though it contains no actual disk, nor a drive motor to spin a disk) is a solid state storage device that uses integrated circuit assemblies as memory to store data persistently. SSD technology primarily uses electronic interfaces compatible with traditional block input/output (I/O) hard disk drives, which permit simple replacements in common applications. Additionally, new I/O interfaces, like SATA Express, have been designed to address specific requirements of the SSD technology.

SSDs have no moving (mechanical) components. This distinguishes them from traditional electromechanical magnetic disks such as [hard disk drives] (HDDs) or [floppy disks], which contain spinning disks and movable read/write heads. Compared with electromechanical disks, SSDs are typically more resistant to physical shock, run silently, have lower access time, and less latency. However, while the price of SSDs has continued to decline over time, consumer grade SSDs are still roughly six to seven times more expensive per unit of storage than consumer grade HDDs.

As of 2014, most SSDs use NAND based flash memory, which retains data without power. For applications requiring fast access, but not necessarily data persistence after power loss, SSDs may be constructed from random access memory (RAM). Such devices may employ separate power sources, such as batteries, to maintain data after power loss.

Hybrid drives or solid state hybrid drives (SSHDs) combine the features of SSDs and HDDs in the same unit, containing a large hard disk drive and an SSD cache to improve performance of frequently accessed data.
===

Light Pen 
A light pen is a computer input device in the form of a light sensitive wand used in conjunction with a computer's [CRT] display.

It allows the user to point to displayed objects or draw on the screen in a similar way to a touchscreen but with greater positional accuracy. A light pen can work with any CRT based display and other display technologies, but its ability to be used with LCDs was unclear (though Toshiba and Hitachi displayed a similar idea at the "Display 2006" show in Japan).

A light pen detects a change of brightness of nearby screen pixels when scanned by cathode ray tube electron beam and communicates the timing of this event to the computer. Since a CRT scans the entire screen one pixel at a time, the computer can keep track of the expected time of scanning various locations on screen by the beam and infer the pen's position from the latest timestamp.

The first light pen was created around 1955 as part of the Whirlwind project at [MIT].

During the 1960s light pens were common on graphics terminals such as the IBM 2250, and were also available for the IBM 3270 text-only terminal.

The light pen was used in the early 1980s. It was notable for its use in the Fairlight CMI, and the [BBC Micro]. [IBM PC compatible] [CGA], [HGC] and some [EGA] graphics cards featured a connector for a light pen as well. Even some consumer products were given light pens, such as the Thomson MO5 computer family as well as the [Atari 8-bit] and [Commodore 8-bit] home computers.

Because the user was required to hold his / her arm in front of the screen for long periods of time or to use a desk that tilts the monitor, the light pen fell out of use as a general purpose input device.
===

Trackball
A trackball is a pointing device consisting of a ball held by a socket containing sensors to detect a rotation of the ball about two axesâlike an upside-down mouse with an exposed protruding ball. The user rolls the ball with the thumb, fingers, or the palm of the hand to move a pointer.

Compared with a mouse, a trackball has no limits on effective travel; at times, a mouse can reach an edge of its working area while the operator still wishes to move the screen pointer farther. With a trackball, the operator just continues rolling, whereas a mouse would have to be lifted and re-positioned. Some trackballs have notably low friction, as well as being made of dense material such as glass, so they can be spun to make them coast. The trackball's buttons may be situated to that of a mouse or to a unique style that suits the user.

Large trackballs are common on [CAD] workstations for easy precision. Before the advent of the touchpad, small trackballs were common on portable computers, where there may be no desk space on which to run a mouse. Some small thumbballs clip onto the side of the keyboard and have integral buttons with the same function as mouse buttons.

The trackball was invented as part of a post World War II era radar plotting system named Comprehensive Display System (CDS) by Ralph Benjamin when working for the British Royal Navy Scientific Service. Benjamin's project used analog computers to calculate the future position of target aircraft based on several initial input points provided by a user with a joystick. Benjamin felt that a more elegant input device was needed and invented a ball tracker system called the roller ball for this purpose in 1946. The device was patented in 1947, but only a prototype using a metal ball rolling on two rubber-coated wheels was ever built and the device was kept as a military secret.
===

Graphics Tablet
A graphics tablet or digitiser is a computer input device that enables a user to hand draw images, animations and graphics, similar to the way a person draws images with a pencil and paper. These tablets may also be used to capture data or handwritten signatures. It can also be used to trace an image from a piece of paper which is taped or otherwise secured to the surface. Capturing data in this way, by tracing or entering the corners of linear poly-lines or shapes, is called digitising.

The device consists of a flat surface upon which the user may "draw" or trace an image using an attached stylus, a pen like drawing apparatus. The image is displayed on the computer monitor, although some graphics tablets also have a screen.

Some tablets are intended as a replacement for the mouse as the primary pointing and navigation device for desktop computers.

Digitisers were popularised in the mid 1970s and early 1980s by the commercial success of the ID (Intelligent Digitiser) and BitPad manufactured by the Summagraphics Corp. These digitisers were used as the input device for many high-end CAD (Computer Aided Design) systems as well as bundled with PCs and PC-based CAD software like [AutoCAD].

Summagraphics also made an [OEM] version of its BitPad which was sold by [Apple Computer] as the Apple Graphics Tablet accessory to their [Apple II]. These tablets used a magnetostriction technology which used wires made of a special alloy stretched over a solid substrate to accurately locate the tip of a stylus or the center of a digitiser cursor on the surface of the tablet. This technology also allowed Proximity or "Z" axis measurement.

The first home computer graphics tablet was the KoalaPad. Though originally designed for the Apple II, the Koala eventually broadened its applicability to practically all home computers with graphics support, examples of which include the TRS-80 Color Computer, [Commodore 64], and [Atari 8-bit family]. Competing tablets were eventually produced; the tablets produced by Atari were generally considered to be of high quality.

In 1981, musician Todd Rundgren created the first color graphics tablet software for personal computers, which was licensed to Apple as the Utopia Graphics Tablet System.

In the 1980s, several vendors of graphics tablets began to include additional functions, such as handwriting recognition and on tablet menus.
===

Webcam
A webcam is a video camera that feeds or streams its image in real time to or through a computer to computer network. When "captured" by the computer, the video stream may be saved, viewed or sent on to other networks via systems such as the Internet, and email as an attachment. When sent to a remote location, the video stream may be saved, viewed or on sent there. Unlike an IP camera (which connects using [Ethernet] or [Wi-Fi]), a webcam is generally connected by a USB cable, or similar cable, or built into computer hardware, such as laptops.

The term 'webcam' (a clipped compound) may also be used in its original sense of a video camera connected to the Web continuously for an indefinite time, rather than for a particular session, generally supplying a view for anyone who visits its web page over the Internet. Some of them, for example, those used as online traffic cameras, are expensive, rugged professional video cameras.
===

Plotter
The plotter is a computer printer for printing vector graphics. In the past, plotters were used in applications such as computer aided design ([CAD]), though they have generally been replaced with wide format conventional printers. A plotter gives a hard copy of the output. It draws pictures on a paper using a pen. Plotters are used to print designs of ships and machines, plans for buildings and so on.

Pen plotters print by moving a pen or other instrument across the surface of a piece of paper. This means that plotters are vector graphics devices, rather than raster graphics as with other printers. Pen plotters can draw complex line art, including text, but do so slowly because of the mechanical movement of the pens. They are often incapable of efficiently creating a solid region of color, but can hatch an area by drawing a number of close, regular lines.

Plotters offered the fastest way to efficiently produce very large drawings or colour high-resolution vector-based artwork when computer memory was very expensive and processor power was very limited, and other types of printers had limited graphic output capabilities.

Pen plotters have essentially become obsolete, and have been replaced by large format inkjet printers and LED toner based printers. Such devices may still understand vector languages originally designed for plotter use, because in many uses, they offer a more efficient alternative to raster data.

Electrostatic Plotters
Electrostatic plotters used a dry toner transfer process similar to that in many photocopiers. They were faster than pen plotters and were available in large formats, suitable for reproducing engineering drawings. The quality of image was often not as good as contemporary pen plotters. Electrostatic plotters were made in both flat-bed and drum types.

Cutting Plotters
Cutting plotters use knives to cut into a piece of material (such as paper, mylar or vinyl) that is lying on the flat surface area of the plotter. It is achieved because the cutting plotter is connected to a computer, which is equipped with specialised cutting design or drawing computer software programs. Those computer software programs are responsible for sending the necessary cutting dimensions or designs in order to command the cutting knife to produce the correct project cutting needs.

In recent years the use of cutting plotters (generally called die-cut machines) has become popular with home enthusiasts of paper crafts such as card making and scrapbooking. Such tools allow desired card shapes to be cut out very precisely, and repeated perfectly identically.
===

CRT - Cathode Ray Tube
The Cathode Ray Tube (CRT) is a vacuum tube containing one or more electron guns, and a fluorescent screen used to view images. It has a means to accelerate and deflect the electron beam(s) onto the screen to create the images. The images may represent electrical waveforms (oscilloscope), pictures (television, computer monitor), radar targets or others. CRTs have also been used as memory devices, in which case the visible light emitted from the fluorescent material (if any) is not intended to have significant meaning to a visual observer (though the visible pattern on the tube face may cryptically represent the stored data).

The CRT uses an evacuated glass envelope which is large, deep (i.e. long from front screen face to rear end), fairly heavy, and relatively fragile. As a matter of safety, the face is typically made of thick lead glass so as to be highly shatter-resistant and to block most X-ray emissions, particularly if the CRT is used in a consumer product.

CRTs have largely been superseded by newer display technologies such as [LCD], [plasma display], and [OLED], which have lower manufacturing costs, power consumption, weight and bulk.

The vacuum level inside the tube is high vacuum on the order of 0.01 Pa to 133 nPa.

In television sets and computer monitors, the entire front area of the tube is scanned repetitively and systematically in a fixed pattern called a raster. An image is produced by controlling the intensity of each of the three electron beams, one for each additive primary colour (red, green, and blue) with a video signal as a reference. In all modern CRT monitors and televisions, the beams are bent by magnetic deflection, a varying magnetic field generated by coils and driven by electronic circuits around the neck of the tube, although electrostatic deflection is commonly used in oscilloscopes, a type of diagnostic instrument.
==

OLED - Organic Light Emitting Diode
An Organic Light Emitting Diode (OLED) is a Light Emitting Diode ([LED]) in which the emissive electroluminescent layer is a film of organic compound which emits light in response to an electric current. This layer of organic semiconductor is situated between two electrodes; typically, at least one of these electrodes is transparent. OLEDs are used to create digital displays in devices such as television screens, computer monitors, portable systems such as mobile phones, handheld game consoles and PDAs. A major area of research is the development of white OLED devices for use in solid-state lighting applications.

There are two main families of OLED: those based on small molecules and those employing polymers. Adding mobile ions to an OLED creates a light emitting electrochemical cell (LEC) which has a slightly different mode of operation. OLED displays can use either passive-matrix (PMOLED) or active-matrix addressing schemes. Active-matrix OLEDs (AMOLED) require a thin-film transistor backplane to switch each individual pixel on or off, but allow for higher resolution and larger display sizes.

An OLED display works without a backlight; thus, it can display deep black levels and can be thinner and lighter than a Liquid Crystal Display ([LCD]). In low ambient light conditions (such as a dark room), an OLED screen can achieve a higher contrast ratio than an LCD, regardless of whether the LCD uses cold cathode fluorescent lamps or an LED backlight.
===

Plasma Display
A plasma display panel (PDP) is a type of flat panel display common to large TV displays 30 inches (76 cm) or larger. They are called "plasma" displays because they use small cells containing electrically charged ionised gases, which are plasmas.

Plasma displays are bright (1,000 lux or higher for the module), have a wide color gamut, and can be produced in fairly large sizesâup to 3.8 metres (150 in) diagonally. They had a very low-luminance "dark-room" black level compared with the lighter grey of the unilluminated parts of an LCD screen at least in the early history of the competing technologies (in the early history of plasma panels the blacks were blacker on plasmas and greyer on LCDs). LED backlit LCD televisions have been developed to reduce this distinction. The display panel itself is about 6 cm (2.4 in) thick, generally allowing the device's total thickness (including electronics) to be less than 10 cm (3.9 in). Power consumption varies greatly with picture content, with bright scenes drawing significantly more power than darker ones â this is also true for [CRTs] as well as modern LCDs where LED backlight brightness is adjusted dynamically. The plasma that illuminates the screen can reach a temperature of at least 1200 Â°C (2200 Â°F). Typical power consumption is 400 watts for a 127 cm (50 in) screen. 200 to 310 watts for a 127 cm (50 in) display when set to cinema mode. Most screens are set to "shop" mode by default, which draws at least twice the power (around 500 â 700 watts) of a "home" setting of less extreme brightness. Panasonic has greatly reduced power consumption ("1/3 of 2007 models"). Panasonic states that PDPs will consume only half the power of their previous series of plasma sets to achieve the same overall brightness for a given display size. The lifetime of the latest generation of plasma displays is estimated at 100,000 hours of actual display time, or 27 years at 10 hours per day. This is the estimated time over which maximum picture brightness degrades to half the original value.

This causes glare from reflected objects in the viewing area. Companies such as Panasonic coat their newer plasma screens with an anti-glare filter material. Currently, plasma panels cannot be economically manufactured in screen sizes smaller than 82 centimetres (32 in). Although a few companies have been able to make plasma enhanced definition televisions (EDTV) this small, even fewer have made 32 inch plasma HDTVs. With the trend toward large-screen television technology, the 32 inch screen size is rapidly disappearing. Though considered bulky and thick compared with their LCD counterparts, some sets such as Panasonic's Z1 and Samsung's B860 series are as slim as 2.5 cm (1 in) thick making them comparable to LCDs in this respect.

Competing display technologies include Cathode Ray Tube ([CRT]), Organic Light Emitting Diode ([OLED]), AMLCD, Digital Light Processing DLP, SED-tv, LED display, field emission display (FED), and quantum dot display (QLED).
===

Liquid Crystal Display (LCD)
A Liquid Crystal Display (LCD) is a flat panel display, electronic visual display, or video display that uses the light modulating properties of liquid crystals. Liquid crystals do not emit light directly.

LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images which can be displayed or hidden, such as preset words, digits, and 7-segment displays as in a digital clock. They use the same basic technology, except that arbitrary images are made up of a large number of small pixels, while other displays have larger elements.

LCDs are used in a wide range of applications including computer monitors, televisions, instrument panels, aircraft cockpit displays, and signage. They are common in consumer devices such as DVD players, gaming devices, clocks, watches, calculators, and telephones, and have replaced Cathode Ray Tube (CRT) displays in most applications. They are available in a wider range of screen sizes than CRT and plasma displays, and since they do not use phosphors, they do not suffer image burn-in. LCDs are, however, susceptible to image persistence.

The LCD screen is more energy efficient and can be disposed of more safely than a CRT. Its low electrical power consumption enables it to be used in battery-powered electronic equipment. It is an electronically modulated optical device made up of any number of segments filled with liquid crystals and arrayed in front of a light source (backlight) or reflector to produce images in colour or monochrome. Liquid crystals were first discovered in 1888. By 2008, annual sales of televisions with LCD screens exceeded sales of CRT units worldwide, and the CRT became obsolete for most purposes.
===

Computer Monitor
A monitor or a display is an electronic visual display for computers. The monitor comprises the display device, circuitry and an enclosure. The display device in modern monitors is typically a thin film transistor liquid crystal display (TFT-LCD) thin panel, while older monitors used a Cathode Ray Tube ([CRT]) about as deep as the screen size.

Originally, computer monitors were used for data processing while television receivers were used for entertainment. From the 1980s onwards, computers (and their monitors) have been used for both data processing and entertainment, while televisions have implemented some computer functionality. The common aspect ratio of televisions, and then computer monitors, has also changed from 4:3 to 16:9.
===

Computer Port
In computer hardware, a port serves as an interface between the computer and other computers or peripheral devices. In computer terms, a port generally refers to the female part of connection. Computer ports have many uses, to connect a monitor, webcam, speakers, or other peripheral devices. On the physical layer, a computer port is a specialised outlet on a piece of equipment to which a plug or cable connects. Electronically, the several conductors where the port and cable contacts connect, provide a method to transfer signals between devices.
===

FireWire
IEEE 1394 is an interface standard for a serial bus for high-speed communications and isochronous real-time data transfer. It was developed in the late 1980s and early 1990s by [Apple], who called it FireWire. The 1394 interface is comparable to [USB] though USB has more market share. Apple first included FireWire in some of its 1999 [Macintosh] models, and most Apple Macintosh computers manufactured in the years 2000 - 2011 included FireWire ports. However, in 2011 Apple began replacing Firewire with the [Thunderbolt] interface and, as of 2014, FireWire has been replaced by Thunderbolt on new Macs. The 1394 interface is also known by the brand i.LINK (Sony), and Lynx (Texas Instruments). IEEE 1394 replaced parallel SCSI in many applications, because of lower implementation costs and a simplified, more adaptable cabling system. The 1394 standard also defines a backplane interface, though this is not as widely used.

IEEE 1394 was the High-Definition Audio-Video Network Alliance (HANA) standard connection interface for A/V (audio/visual) component communication and control. (HANA was dissolved in September 2009 and the 1394 Trade Association assumed control of all HANA generated intellectual property). FireWire is also available in wireless, fiber optic, and coaxial versions using the isochronous protocols.
===

Digital Visual Interface (DVI)
Digital Visual Interface (DVI) is a video display interface developed by the Digital Display Working Group (DDWG). The digital interface is used to connect a video source, such as a display controller to a display device, such as a computer monitor. It was developed with the intention of creating an industry standard for the transfer of digital video content.

The interface is designed to transmit uncompressed digital video and can be configured to support multiple modes such as DVI-D (digital only), DVI-A (analog only), or DVI-I (digital and analog). Featuring support for analog connections, the DVI specification is compatible with the VGA interface. This compatibility, along with other advantages, led to its widespread acceptance over competing digital display standards Plug and Display (P&amp;D) and Digital Flat Panel (DFP). Although DVI is predominantly associated with computers, it is sometimes used in other consumer electronics such as television sets, video game consoles, and DVD players.
===

PS/2 connector
The PS/2 connector is a 6-pin mini-DIN connector used for connecting some keyboards and mice to a [PC compatible] computer system. Its name comes from the [IBM Personal System/2] series of personal computers, with which it was introduced in 1987. The PS/2 mouse connector generally replaced the older DE-9 RS-232 "serial mouse" connector, while the PS/2 keyboard connector replaced the larger 5-pin/180Â° DIN connector used in the [IBM PC/AT] design. The PS/2 designs on keyboard and mouse interfaces are electrically similar and employ the same communication protocol. However, a given system's keyboard and mouse port may not be interchangeable since the two devices use a different set of commands.
===

HDMI
HDMI (High-Definition Multimedia Interface) is a proprietary audio / video interface for transferring uncompressed video data and compressed or uncompressed digital audio data from an HDMI compliant source device, such as a display controller, to a compatible computer monitor, video projector, digital television, or digital audio device. HDMI is a digital replacement for analog video standards.

HDMI implements the EIA/CEA-861 standards, which define video formats and waveforms, transport of compressed, uncompressed, and LPCM audio, auxiliary data, and implementations of the VESA EDID. CEA-861 signals carried by HDMI are electrically compatible with the CEA-861 signals used by the digital visual interface (DVI). No signal conversion is necessary, nor is there a loss of video quality when a DVI-to-HDMI adapter is used. The CEC (Consumer Electronics Control) capability allows HDMI devices to control each other when necessary and allows the user to operate multiple devices with one remote control handset.

Several versions of HDMI have been developed and deployed since initial release of the technology but all use the same cable and connector. Other than improved audio and video capacity, performance, resolution and colour spaces, newer versions have optional advanced features such as 3D, Ethernet data connection, and CEC (Consumer Electronics Control) extensions.

Production of consumer HDMI products started in late 2003. In Europe either DVI-HDCP or HDMI is included in the HD ready in-store labeling specification for TV sets for HDTV, formulated by EICTA with SES Astra in 2005. HDMI began to appear on consumer HDTV camcorders and digital still cameras in 2006. As of 8 January 2013 (ten years after the release of the first HDMI specification), over 3 billion HDMI devices have been sold.
===

ATI
ATI Technologies Inc (commonly referred to as ATI) was a semiconductor technology corporation based in Markham, Ontario, Canada, that specialised in the development of graphics processing units and chipsets. Founded in 1985 as Array Technology Inc, the company listed publicly in 1993. Advanced Micro Devices ([AMD]) acquired ATI in 2006. As a major fabrication less or fabless semiconductor company, ATI conducted research and development in-house and outsourced the manufacturing and assembly of its products. With the decline and eventual bankruptcy of 3dfx in 2000, ATI and its chief rival Nvidia emerged as the two dominant players in the graphics processors industry, eventually forcing other manufacturers into niche roles.

The acquisition of ATI in 2006 was important to AMD's strategic development of its Fusion generation of computer processors, which integrated general processing abilities with graphics processing functions within a single chip. Since 2010 AMD's graphics processor products have ceased using the ATI brand name.
===

DisplayPort
DisplayPort is a digital display interface developed by the Video Electronics Standards Association ([VESA]). The interface is primarily used to connect a video source to a display device such as a computer monitor, though it can also be used to carry audio, [USB], and other forms of data.

VESA designed it to replace [VGA], [DVI], and FPD-Link. DisplayPort is backward compatible with VGA and DVI through the use of adapters.

DisplayPort is the first display interface to rely on packetised data transmission, a form of digital communication found in technologies including [Ethernet], USB, and PCI Express. It allows both internal and external display connections and, unlike legacy standards where differential pairs are fixed to transmitting a clock signal with each output, the DisplayPort protocol is based on small data packets known as micro packets, which can embed the clock signal within the data stream, allowing higher resolutions with fewer pins. The use of data packets also allows DisplayPort to be extensible, meaning additional features can be added over time without significant changes to the physical interface itself.

DisplayPort can be used to transmit audio and video simultaneously, but each one is optional and can be transmitted without the other. The video signal path can have six to sixteen bits per color channel, and the audio path can have up to eight channels of 24-bit 192 kHz uncompressed PCM audio or can encapsulate compressed audio formats in the audio stream. A bi-directional, half-duplex auxiliary channel carries device management and device control data for the Main Link, such as VESA EDID, MCCS, and DPMS standards. In addition, the interface is capable of carrying bi-directional USB signals.

The DisplayPort LVDS signal protocol is not compatible with DVI or HDMI. However, Dual-mode DisplayPorts are designed to transmit a single-link DVI or HDMI 1.2/1.4 TMDS protocol across the interface through the use of an external passive adapter that selects the desired signal and converts it from 3.3 volts to 5 volts. Analog VGA and dual-link DVI require powered active adapters to convert the protocol and signal levels and do not rely on Dual-Mode. VGA adapters are powered by the DisplayPort connector, while dual-link DVI adapters may rely on an external power source (see Dual-mode).

The DisplayPort connector can have one, two, or four differential data pairs (lanes) in a Main Link, each with a raw bit rate of 1.62, 2.7, 5.4, or 8.1 Gbit/s per lane with self-clock running at 162, 270, 540, or 810 MHz. The effective data rates after decoding are 1.296, 2.16, 4.32, or 6.48 Gbit/s per lane (or 80% of the total), since data is 8b/10b encoded so each eight bits of information are encoded with a ten-bit symbol.
===

VESA
VESA or the Video Electronics Standards Association, is an international non-profit corporation standards body for computer graphics formed in 1988 by NEC Home Electronics, maker of the MultiSync monitor line, and eight video display adapter manufacturers: [ATI Technologies], Genoa Systems, Orchid Technology, Renaissance GRX, STB Systems, Tecmar, Video 7 and Western Digital/Paradise Systems.

VESA's initial goal was to produce a standard for 800x600 [SVGA] resolution video displays. Since then VESA has issued a number of standards, mostly relating to the function of video peripherals in personal computers.

In November 2010, VESA announced a cooperative agreement with the Wireless Gigabit Alliance (WiGig) for sharing technology expertise and specifications to develop multi-gigabit wireless DisplayPort capabilities. DisplayPort is a VESA technology that provides digital display connectivity for Monitor mount.
===

Thunderbolt
Thunderbolt, developed under the name Light Peak, is a hardware interface that allows the connection of external peripherals to a computer. Thunderbolt 1 and 2 use the same connector as [Mini DisplayPort] (MDP), while Thunderbolt 3 will use USB Type-C. It was first sold as part of a consumer product on 24 February 2011.

Thunderbolt combines PCI Express (PCIe) and DisplayPort (DP) into one serial signal, and additionally provides DC power, all in one cable. Up to six peripherals may be supported by one connector through various topologies.

The interface was originally intended to run exclusively on an optical physical layer using components and flexible optical fiber cabling developed by [Intel] partners and at Intel's Silicon Photonics lab. It was initially marketed under the name Light Peak, and after 2011 as Silicon Photonics Link. However, it was discovered that conventional copper wiring could furnish the desired 10 Gbit/s per channel at lower cost.

This copper based version of the Light Peak concept was co-developed by [Apple] and [Intel]. Apple registered Thunderbolt as a trademark, but later transferred the mark to Intel, which held overriding intellectual property rights.

Thunderbolt controllers multiplex one or more individual data lanes from connected PCIe and DisplayPort devices for transmission via one duplex Thunderbolt lane, then de-multiplex them for use by PCIe and DisplayPort devices on the other end. A single Thunderbolt port supports up to six Thunderbolt devices via hubs or daisy chains; as many of these as the host has DP sources may be Thunderbolt monitors.

A single Mini DisplayPort monitor or other device of any kind may be connected directly or at the very end of the chain. Thunderbolt is interoperable with DP-1.1a compatible devices. When connected to a DP compatible device, the Thunderbolt port can provide a native DisplayPort signal with four lanes of output data at no more than 5.4 Gbit/s per Thunderbolt lane. When connected to a Thunderbolt device, the per-lane data rate becomes 10 Gbit/s and the four Thunderbolt lanes are configured as two duplex lanes, each 10 Gbit/s comprising one lane of input and one lane of output.

Thunderbolt can be implemented on PCIe graphics cards, which have access to DisplayPort data and PCIe connectivity, or on the motherboard of new computers with onboard video, such as the MacBook Air.

Sumitomo Electric Industries started selling up to 30 metre long (100 ft) optical Thunderbolt cables in Japan in January 2013, with US company Corning Inc. selling up to 60 metre long (200 ft) optical cables from late September 2013.

Thunderbolt was commercially introduced on Apple's 2011 MacBook Pro, using the same Apple developed connector as Mini DisplayPort, which is electrically identical to DisplayPort, but uses a smaller, non-locking connector.
===

Mini DisplayPort 
The Mini DisplayPort (MiniDP or mDP) is a miniaturised version of the [DisplayPort] audio-visual digital interface.

It was announced by [Apple] in October 2008. As of 2013, all new [Apple Macintosh] computers had the port. The Mini DisplayPort is also fitted to some [PC] motherboards, and some PC notebooks from [Asus], [Microsoft], [Lenovo], [Toshiba], [HP], [Dell], and other manufacturers.

Unlike its Mini-DVI and Micro-DVI predecessors, the Mini DisplayPort can drive display devices with resolutions up to 2560Ã1600 (WQXGA) in its DisplayPort 1.1a implementation, and 4096x2160 (4K) in its DisplayPort 1.2 implementation. With an adapter, the Mini DisplayPort can drive display devices with [VGA], [DVI], or [HDMI] interfaces.

Apple offers a free license for the Mini DisplayPort but they reserve the right to cancel the license should the licensee "commence an action for patent infringement against Apple".
===

iTunes Store
The iTunes Store, originally the iTunes Music Store, is a software based online digital media store operated by [Apple Inc]. It opened on 28 April 2003, and has been the largest music vendor in the United States since April 2008, and the largest music vendor in the world since February 2010. It offers over 37 million songs, 700,000 apps, 190,000 TV episodes and 45,000 films as of 12 September 2012. The iTunes Store's revenues in the first quarter of 2011 totalled nearly US$1.4 billion, by 6 February 2013, the store had sold 25 billion songs worldwide.

While most downloaded files initially included usage restrictions enforced by [FairPlay], Apple's implementation of digital rights management ([DRM]), iTunes later initiated a shift into selling DRM free music in most countries, marketed as iTunes Plus. On 6 January 2009, Apple announced that DRM had been removed from 80% of its music catalog in the US. Full iTunes Plus availability was achieved in the US on 7 April 2009, coinciding with the introduction of a three-tiered pricing model; however, television episodes, many books, and films are still FairPlay protected. As of June 2013, the iTunes Store possesses 575 million active user accounts, and serves over 315 million mobile devices, including [Apple Watches], [iPods], [iPhones], [Apple TV] and [iPads].
===

DRM - Digital Rights Management
Digital Rights Management (DRM) is a class of copy protection technologies that are used by hardware and software manufacturers, publishers, copyright holders, and individuals with the intent to control the use of digital content and devices after sale; there are, however, many competing definitions. With first-generation DRM software, the intent is to control copying; with second-generation DRM, the intent is to control executing, viewing, copying, printing, and altering of works or devices. The term is also sometimes referred to as copy protection, copy prevention, and copy control, although the correctness of doing so is disputed. DRM is a set of access control technologies. In 1998, the [Digital Millennium Copyright Act] (DMCA) was passed in the United States to impose criminal penalties on those who make available technologies whose primary purpose and function are to circumvent content protection technologies.

The use of digital rights management is not universally accepted. Some content providers claim that DRM is necessary to fight copyright infringement and that it can help the copyright holder maintain artistic control or ensure continued revenue streams. Proponents argue that digital locks should be considered necessary to prevent "intellectual property" from being copied freely, just as physical locks are needed to prevent personal property from being stolen. Those opposed to DRM contend there is no evidence that DRM helps prevent copyright infringement, arguing instead that it serves only to inconvenience legitimate customers, and that DRM helps big business stifle innovation and competition. Furthermore, works can become permanently inaccessible if the DRM scheme changes or if the service is discontinued.

Digital locks placed in accordance with DRM policies can also restrict users from exercising their legal rights under copyright law, such as backing up copies of CDs or DVDs, lending materials out through a library, accessing works in the public domain, or using copyrighted materials for research and education under the US fair use laws, and under French law. The [Electronic Frontier Foundation] (EFF) and the [Free Software Foundation] (FSF) consider the use of DRM systems to be anti-competitive practice.
===

Digital Millennium Copyright Act (DMCA)
The Digital Millennium Copyright Act (DMCA) is a United States copyright law that implements two 1996 treaties of the [World Intellectual Property Organisation] (WIPO). It criminalizes production and dissemination of technology, devices, or services intended to circumvent measures (commonly known as digital rights management or [DRM]) that control access to copyrighted works. It also criminalizes the act of circumventing an access control, whether or not there is actual infringement of copyright itself. In addition, the DMCA heightens the penalties for copyright infringement on the Internet. Passed on 12 October 1998, by a unanimous vote in the United States Senate and signed into law by President Bill Clinton on 28 October 1998, the DMCA amended Title 17 of the United States Code to extend the reach of copyright, while limiting the liability of the providers of online services for copyright infringement by their users.

The DMCA's principal innovation in the field of copyright is the exemption from direct and indirect liability of Internet service providers and other intermediaries. This exemption was adopted by the European Union in the Electronic Commerce Directive 2000. The Copyright Directive 2001 implemented the 1996 WIPO Copyright Treaty in the EU.
===

World Intellectual Property Organisation (WIPO)
The World Intellectual Property Organisation (WIPO) is one of the 17 specialised agencies of the United Nations.

WIPO was created in 1967 "to encourage creative activity, to promote the protection of intellectual property throughout the world".

WIPO currently has 188 member states, administers 26 international treaties, and is headquartered in Geneva, Switzerland. The current Director-General of WIPO is Francis Gurry, who took office on 1 October 2008. 186 of the UN Members as well as the Holy See and Niue are Members of WIPO. Non-members are the states of Marshall Islands, Federated States of Micronesia, Nauru, Palau, Solomon Islands, South Sudan and Timor-Leste.
===

Electronic Frontier Foundation (EFF) 
The Electronic Frontier Foundation (EFF) is an international non-profit digital rights group based in the United States.

EFF provides funds for legal defence in court, presents amicus curiae briefs, defends individuals and new technologies from what it considers baseless or misdirected legal threats, works to expose government malfeasance, provides guidance to the government and courts, organizes political action and mass mailings, supports some new technologies which it believes preserve personal freedoms, maintains a database and web sites of related news and information, monitors and challenges potential legislation that it believes would infringe on personal liberties and fair use, and solicits a list of what it considers patent abuses with intentions to defeat those that it considers without merit.
===

FairPlay
FairPlay is a digital rights management ([DRM]) technology created by [Apple Inc], based on technology created by the company Veridisc. FairPlay is built into the [QuickTime] multimedia software and used by the [iPhone], [iPod], [iPad], [Apple TV], and [iTunes Store] and the [App Store]. Formerly, all songs in the iTunes Store were encoded with FairPlay. Apple later started offering a selection of songs that, after an additional 30 cents is paid per song, could be downloaded FairPlay free. Apple no longer sells individual songs or albums with FairPlay encryption from the iTunes store. However, apps downloaded from the iTunes store and Apple Music subscription songs saved for offline listening are still encrypted with FairPlay. FairPlay digitally encrypts AAC audio files and prevents users from playing these files on unauthorised computers.

The majority of FairPlay encrypted content is purchased through the iTunes Store, using the iTunes software. The iTunes software relies on Apple's Quicktime multimedia software for decoding and playback of the encrypted files. Every media player capable of using QuickTime is capable of playing back FairPlay encrypted files, including [RealPlayer], JRiver Media Center, Media Player Classic and Songbird.
===

Toshiba
Toshiba Corporation is a Japanese multinational conglomerate corporation headquartered in Tokyo, Japan. Its diversified products and services include information technology and communications equipment and systems, electronic components and materials, power systems, industrial and social infrastructure systems, consumer electronics, household appliances, medical equipment, office equipment, lighting and logistics.

Toshiba was founded in 1938 as Tokyo Shibaura Electric K.K. through the merger of Shibaura Seisaku-sho (founded in 1875) and Tokyo Denki (founded in 1890). The company name was officially changed to Toshiba Corporation in 1978. Toshiba has made numerous corporate acquisitions during its history, including of Semp in 1977, of Westinghouse Electric LLC, a nuclear energy company in 2006, of Landis+Gyr in 2011, and of [IBM]'s point-of-sale business in 2012.

Toshiba is organised into four business groupings: the Digital Products Group, the Electronic Devices Group, the Home Appliances Group and the Social Infrastructure Group. In 2010, Toshiba was the world's fifth-largest personal computer vendor measured by revenues (after [Hewlett-Packard], [Dell], [Acer] and [Lenovo]). In the same year, it was also the world's fourth-largest manufacturer of semiconductors by revenues (after [Intel Corporation], [Samsung Electronics] and [Texas Instruments]).

Toshiba is listed on the Tokyo Stock Exchange, where it is a constituent of the Nikkei 225 and TOPIX indices, the Osaka Securities Exchange and the Nagoya Stock Exchange.
===

Lenovo
Lenovo Group Ltd is a Chinese multinational computer technology company with headquarters in Beijing, China, and Morrisville, North Carolina, United States. It designs, develops, manufactures and sells personal computers, tablet computers, smartphones, workstations, servers, electronic storage devices, IT management software and smart televisions. In 2014, Lenovo was the world's largest personal computer vendor by unit sales. It markets the ThinkPad line of notebook computers and the ThinkCentre line of desktops.

Lenovo has operations in more than 60 countries and sells its products in around 160 countries. Lenovo's principal facilities are in Beijing, Morrisville and Singapore, with research centers in those locations, as well as Shanghai, Shenzhen, Xiamen, and Chengdu in China, and Yamato in Kanagawa Prefecture, Japan. It operates a joint venture with EMC, LenovoEMC, which sells network-attached storage solutions. It also has a joint venture with NEC, Lenovo NEC Holdings, which produces personal computers for the Japanese market.

Lenovo was founded in Beijing in 1984 as Legend and was incorporated in Hong Kong in 1988. Lenovo acquired [IBM]'s personal computer business in 2005 and agreed to acquire its [Intel] based server business in 2014. Lenovo entered the smartphone market in 2012 and as of 2014 is the largest vendor of smartphones in Mainland China. In January 2014, Lenovo agreed to acquire the mobile phone handset maker Motorola Mobility from [Google], and in October 2014 the deal was finalised.

Lenovo is listed on the Hong Kong Stock Exchange and is a constituent of the Hang Seng China Affiliated Corporations Index, often referred to as "Red Chips".
===

LED - Light Emitting Diode 
A Light Emitting Diode (LED) is a two-lead semiconductor light source. It is a pân junction diode, which emits light when activated. When a suitable voltage is applied to the leads, electrons are able to recombine with electron holes within the device, releasing energy in the form of photons. This effect is called electroluminescence, and the colour of the light (corresponding to the energy of the photon) is determined by the energy band gap of the semiconductor.

An LED is often small in area (less than 1 mm2) and integrated optical components may be used to shape its radiation pattern.

Appearing as practical electronic components in 1962, the earliest LEDs emitted low-intensity infrared light. Infrared LEDs are still frequently used as transmitting elements in remote control circuits, such as those in remote controls for a wide variety of consumer electronics. The first visible light LEDs were also of low intensity, and limited to red. Modern LEDs are available across the visible, ultraviolet, and infrared wavelengths, with very high brightness.

Early LEDs were often used as indicator lamps for electronic devices, replacing small incandescent bulbs. They were soon packaged into numeric readouts in the form of seven-segment displays, and were commonly seen in digital clocks.

Recent developments in LEDs permit them to be used in environmental and task lighting. LEDs have many advantages over incandescent light sources including lower energy consumption, longer lifetime, improved physical robustness, smaller size, and faster switching. Light Emitting Diodes are now used in applications as diverse as aviation lighting, automotive headlamps, advertising, general lighting, traffic signals, camera flashes and even LED wallpaper. However, LEDs powerful enough for room lighting are still relatively expensive, and require more precise current and heat management than compact fluorescent lamp sources of comparable output.
===

Plug and Play 
In computing, a plug and play device or computer bus, is one with a specification that facilitates the discovery of a hardware component in a system without the need for physical device configuration or user intervention in resolving resource conflicts.

Plug and play devices can be due to boot time assignment of device resources and to hot plug systems such as [USB] and IEEE 1394 ([FireWire]).
===

PC Card / PCMCIA Card
In computing, PC Card is a configuration for computer peripheral interface designed for laptop computers. Originally introduced as PCMCIA Card, the PC Card standard as well as its successors like CardBus were defined and developed by the Personal Computer Memory Card International Association (PCMCIA).

It was originally designed as a standard for memory expansion cards for computer storage. The existence of a usable general standard for notebook peripherals led to many kinds of devices being made available based on its configurability, including network cards, modems, and hard disks.
===

GPU - Graphics Processor Unit
A Graphics Processor Unit (GPU), also occasionally called Visual Processor Unit (VPU), is a specialised electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display. GPUs are used in embedded systems, mobile phones, personal computers, workstations, and game consoles. Modern GPUs are very efficient at manipulating computer graphics and image processing, and their highly parallel structure makes them more effective than general purpose [CPUs] for algorithms where processing of large blocks of data is done in parallel. In a personal computer, a GPU can be present on a video card, or it can be embedded on the motherboard or in certain CPUs on the CPU die.

The term GPU was popularised by [Nvidia] in 1999, who marketed the [GeForce 256] as "the world's first GPU", or Graphics Processing Unit, a single-chip processor with integrated transform, lighting, triangle setup / clipping, and rendering engines that are capable of processing a minimum of 10 million polygons per second". Rival [ATI Technologies] coined the term Visual Processing Unit or VPU with the release of the [Radeon 9700] in 2002.
===

Radeon
Radeon is a brand of computer products, including Graphics Processing Units ([GPU], random access memory, RAM disk software, solid-state drives, produced by [Advanced Micro Devices]. The brand was launched in 2000 by [ATI Technologies], which was acquired by AMD in 2006.

Radeon Graphics is the successor to the [Rage] line. Three different families of microarchitectures can be roughly distinguished, the fixed-pipeline family and the unified shader model families of TeraScale and Graphics Core Next. ATI/AMD have developed different technologies, such as TruForm, HyperMemory, HyperZ, XGP, Eyefinity for multi-monitor setups, PowerPlay for power-saving, CrossFire (for multi-GPU) or Hybrid Graphics. A range of SIP blocks is also to be found on certain models in the Radeon products line: Unified Video Decoder, Video Coding Engine and TrueAudio.

The brand was previously only known as "ATI Radeon" until August 2010, when it was renamed to increase AMD's brand awareness on a global scale. Products up to and including the HD 5000 series are branded as ATI Radeon, while the HD 6000 series and beyond use the new AMD Radeon branding.
===

GeForce
GeForce is a brand of Graphics Processing Units ([GPU]) designed by [Nvidia]. As of 2013, there have been twelve iterations of the design. The first GeForce products were discrete GPUs designed for add on graphics boards, intended for the high margin [PC] gaming market, and later diversification of the product line covered all tiers of the PC graphics market, ranging from cost sensitive GPUs integrated on motherboards, to mainstream add-in retail boards. Most recently, GeForce technology has been introduced into Nvidia's line of embedded application processors, designed for electronic handhelds and mobile handsets.

With respect to discrete GPUs, found in add-in graphics boards, Nvidia's GeForce and [AMD]'s [Radeon] GPUs are the only remaining competitors in the high-end market. Along with its nearest competitor, the AMD Radeon, the GeForce architecture is moving toward GPGPU (General Purpose-Graphics Processor Unit). GPGPU is expected to expand GPU functionality beyond the traditional rasterisation of 3D graphics, to turn it into a high performance computing device able to execute arbitrary programming code in the same way a [CPU] does, but with different strengths (highly parallel execution of straightforward calculations) and weaknesses (worse performance for complex decision making code).

Name Origin
The "GeForce" name originated from a contest held by Nvidia in early 1999 called "Name That Chip". The company called out to the public to name the successor to the RIVA TNT2 line of graphics boards. There were over 12,000 entries received and 7 winners received a RIVA TNT2 Ultra graphics card as a reward.
===

OpenGL
OpenGL (Open Graphics Library) is a cross language, multi-platform application programming interface (API) for rendering 2D and 3D vector graphics. The API is typically used to interact with a Graphics Processing Unit ([GPU]), to achieve hardware accelerated rendering.

[Silicon Graphics Inc] (SGI) started developing OpenGL in 1991 and released it in January 1992; applications use it extensively in the fields of [CAD], virtual reality, scientific visualisation, information visualisation, flight simulation, and video games. OpenGL is managed by the non-profit technology consortium Khronos Group.
===

Magic Mouse
The Magic Mouse is a multi-touch [mouse] manufactured and sold by [Apple]. It was first sold on 20 October 2009. The Magic Mouse is the first consumer mouse to have multi-touch capabilities. Taking after the [iPhone], [iPad], [iPod Touch], and multi-touch trackpads, the Magic Mouse allows the use of gestures such as swiping and scrolling across the top surface of the mouse to interact with desktop computers. It connects via [Bluetooth] and runs on two AA batteries. Apple includes two non-rechargeable batteries in the box. Just like the predecessor, the [Mighty Mouse], the Magic Mouse is capable of right-clicking.

The mouse requires minimum [Mac OS X 10.5.8]. It can be configured as a two-buttoned left-handed or right-handed mouse, but the default is a single button. It uses laser tracking for increased pointer accuracy over previous generation Apple mice. Since its release, it has been included along with a wireless keyboard with the 2009 generation of iMacs, and with a wired keyboard with the 2010 Mac Pro workstations. It can also be purchased separately.

Initial reception to the Magic Mouse was negative, with reactions to its inability to perform simple day-to-day functions such as the ability to middle click (without any additional software), or trigger ExposÃ©, Dashboard, or Spaces, features that had been offered by its predecessor. Many of those features can be enabled on the Magic Mouse with the use of third-party tools.

Gestures
Not all gestures are supported on all operating systems:

-Click
-Two-button click
-360Â°-scroll
-Screen zoom
-Screen pan
-Two-finger swipe
-One-finger swipe
-Two-finger double tap
-One-finger double tap

Gestures can be customised and new ones can be added via third-party software. Inertia scrolling is said to be available in [Snow Leopard] only after installing a software update, but it could also be enabled in Leopard with a terminal command.
==

Apple Mighty Mouse
The Apple Mouse (formerly Apple Mighty Mouse) is a multi-control USB [mouse] manufactured by Mitsumi Electric and sold by [Apple Inc]. It was announced and sold for the first time on 2 August 2005, and a [Bluetooth] version was available from 2006 to 2009. Before the Mighty Mouse, Apple had sold only one-button mice with its computers, beginning with the [Apple Lisa] 22 years earlier.

On 20 October 2009, the wireless Mighty Mouse was discontinued and replaced by the multi-touch [Magic Mouse]. The wired version of the device remains available, but was renamed the "Apple Mouse" as of the same date, due to trademark issues with another manufacturer of a device named "Mighty Mouse".

The Mighty Mouse is made of white plastic and has a recessed Apple logo on the mouse's face. The mouse has four functional controls: a left capacitive sensor, a right capacitive sensor, a track ball with a pressure sensor and side squeeze sensors. The track ball enables users to scroll a page or document in any direction, including diagonally. Instead of mechanical buttons, the touch-sensitive topshell and the pressure sensing trackball allow the mouse to detect which side is being touched or whether the trackball is being held in.

The mouse emits a sound when the scroll ball is rolled, but this is not a direct product of the ball moving; the sound is actually produced by a tiny speaker inside the mouse. There is no way to disable this feature other than physically disabling the speaker inside the mouse.

Currently, [Mac OS X] is the only operating system that fully supports the mouse without third party software. When used with Mac OS X, the sensors can be set to launch applications or trigger features of the Apple operating system, such as Dashboard and ExposÃ©. If not used with Mac OS X, the mouse behaves as a four "button" mouse with a vertical and horizontal scroll wheel. There are third-party drivers (XMouse, AppleM) that provide more functions to users of other platforms such as [Windows].

The Mighty Mouse does not report whether the right and left sensors are activated simultaneously. In fact, it reports a right click only when there is no finger contact on the left side of the mouse. Thus a right click requires lifting the finger off the mouse, then right clicking. This also means that the Mighty Mouse cannot support mouse chording, used by [CAD] software, games, and other applications where multiple functions are mapped to the mouse.

Name
Prior to launching the device, Apple received a license to the name "Mighty Mouse" from Viacom, and subsequently CBS Operations, as owner of the Mighty Mouse cartoon series, the title having been registered in the U.S. as a trademark with respect to various merchandise (such as T-shirts and multivitamins) associated with the character. However, the trademark did not cover computer peripherals, and CBS did not apply to trademark the term in the U.S. with respect to computer mice until mid 2007.

On 21 May 2008, it was announced that Man & Machine Inc, a supplier of keyboards and mice to laboratories and hospitals, had sued Apple Inc for trademark infringement over its use of the name Mighty Mouse. Man & Machine Inc. had four registered or pending trademarks on various computer pointing related technologies, including "Cool Mouse", "Really Cool", and "Man and Machine and Design". The particular Mighty Mouse trademark in dispute was first filed by Man & Machine Inc, on 18 December 2007 with the description "Computer cursor control devices, namely, computer mice" - after CBS's filing, but claiming first use in 2004, before the introduction of the Apple device. There also was another scroll mouse named Mighty Mouse developed by NTT and ETH ZÃ¼rich in 1985.

Following opposition proceedings on both sides against the other, CBS subsequently withdrew its application, allowing Man & Machine to register the U.S. trademark for computer mice. As a result, Apple stopped selling mice under the "Mighty Mouse" name on 20 October 2009, when it introduced the wireless [Magic Mouse] and renamed the existing wired mouse the "Apple Mouse".

Incidentally, CBS was successful in registering "Mighty Mouse" as a trademark for computer mice in some other countries, including Canada, although Apple nevertheless chose to change its product name internationally.
===

Magic Trackpad
The Magic Trackpad is a multi-touch trackpad produced by [Apple Inc] Announced on 27 July 2010, it is similar to the trackpad found on the current MacBook family of laptops, albeit 80% larger. The trackpad is fully compatible with [Macintosh] computers running [Mac OS X Snow Leopard] versions 10.6.4 and higher with a software update, as well as [Windows 7], [Windows XP], and [Windows Vista] in Apple's [Boot Camp] with an added device driver. It is also capable of performing in a basic capacity when paired with a [Windows] computer or a Macintosh without the necessary software. [Ubuntu Linux] computers can be configured to support most of the multitouch gestures that Mac OS supports, and additionally custom gestures can be added for most applications which do not natively support multi-touch.
===

Boot Camp
Boot Camp is a multi boot utility included with [Apple Inc]'s [OS X] that assists users in installing [Microsoft Windows] operating systems on [Intel] based [Macintosh] computers. The utility's Boot Camp Assistant guides users through non-destructive [disk partitioning] (including resizing of an existing HFS+ partition, if necessary) of their hard disk drive and installation of Windows device drivers. The utility also installs a Windows Control Panel applet for selecting the boot operating system.

Initially introduced as an unsupported beta for [Mac OS X Tiger], the utility was first included with [Mac OS X Leopard] and has been included in subsequent versions of the operating system ever since. Previous versions of Boot Camp supported [Windows XP], [Windows Vista] and [Windows 7]. Boot Camp 4.0 for [Mac OS X Snow Leopard] up to [OS X Mountain Lion] version 10.8.2 only supported [Windows 7]. However, with the release of Boot Camp 5.0 for [OS X Mountain Lion] version 10.8.3, only 64-bit versions of Windows 7 and [Windows 8] are officially supported. Users have also installed [Linux] using the utility, although Apple has not listed support for Linux operating systems.
===

Disk Partitioning
Disk partitioning is used to mean the partitioning or division of certain kinds of secondary storage (such as hard disk drives (HDDs)), via the creation of multiple partitions. Partitions are logical containers which are usually used to house filesystems, where operating systems, applications, and data are installed on. A single partition may span the entirety of a physical storage device.

A partition editor software program can be used to create, resize, delete, and manipulate these partitions on the HDD. A partition on a traditional mechanical hard drive consists of a range of cylinders of HDD i.e. each partition is defined by both a start and end cylinder (the size of cylinders varying from disk to disk).
===

PartitionMagic
PartitionMagic is a computer program for hard disk drive [partitioning] originally made by the [PowerQuest] corporation, but now owned by [Symantec]. As of 8 December 2009, the Symantec website stated that they no longer offer Partition Magic. The program runs on [Microsoft Windows] operating systems including [Windows 2000] and [Windows XP], but the application is incompatible with [Windows Vista], [7], or [8] and must use a bootable disk for partitioning drives instead. The utility can also be run from a bootable CD-ROM and enables creation and modification of partitions. Existing partitions can be resized without loss of data.

PartitionMagic is capable of resizing [NTFS], [FAT16] or [FAT32] partitions without data loss, and can copy and move partitions, including to other disks. It also has various other features, including being able to convert between FAT16, FAT32 and NTFS, modify the cluster size of FAT16, FAT32 and NTFS filesystems, and merge adjacent FAT or NTFS filesystems (all without data loss, though some NTFS only metadata is lost on conversion to FAT). Additionally, it had somewhat limited support for ext2 and ext3 partitions. PartitionMagic was the first commercial product of its kind containing patented technology.

The first version of PartitionMagic was released with [DOS] and [OS/2] support. Versions 2â3 were offered with DOS, OS/2 and Windows support. Symantec's PartitionMagic version 8 dropped the OS/2 version. A server version was also offered under the name Server Magic for Windows and [Novell NetWare] servers.

The stable version of PartitionMagic 8.05 also includes for a rescue floppy disk an additional DOS version of PartitionMagic. This DOS version of PartitionMagic (include [DR-DOS] or [MS-DOS]) is matching on two 1.44 MB or one 2.88 MB floppy disks.
===

Drive Image
Drive Image (PQDI) is a software disk cloning package for [Intel] based computers. The software was developed and distributed by the former [PowerQuest Corporation]. Drive Image version 7 became the basis for [Norton Ghost] 9.0, which was released to retail markets in August 2004. Ghost was a competing product, developed by Binary Research, before [Symantec] bought the company in 1998. This also explains the different file extensions used for Ghost image files: formerly it was .gho, now in versions 9.0 and above it is .v2i.
===

Ghost
Ghost (an acronym for general hardware-oriented system transfer) is a discontinued disk cloning and backup tool originally developed by Murray Haszard in 1995 for Binary Research. The technology was acquired in 1998 by [Symantec].

The backup and recovery functionality has been replaced by Symantec System Recovery (SSR), although the Ghost imaging technology is still actively developed and is available as part of Symantec Ghost Solution Suite.
===

NTFS
NTFS (New Technology File System) is a proprietary file system developed by [Microsoft]. Starting with [Windows NT 3.1], it is the default file system of Windows NT family.

NTFS has several technical improvements over [FAT] and [HPFS] (High Performance File System), the file systems that it superseded, such as improved support for metadata, and the use of advanced data structures to improve performance, reliability, and disk space utilisation, plus additional extensions, such as security Access Control Lists ([ACL]) and file system journaling.
===

Access Control List (ACL),
An Access Control List (ACL), with respect to a computer file system, is a list of permissions attached to an object. An ACL specifies which users or system processes are granted access to objects, as well as what operations are allowed on given objects. Each entry in a typical ACL specifies a subject and an operation. For instance, if a file object has an ACL that contains (Mary: read,write; Iain: read), this would give Mary permission to read and write the file and Iain to only read it.
===

FAT16
On 14 August 1984, [IBM] released the [PC AT], which featured a 20MB hard disk and [PC DOS] 3.0. [Microsoft] introduced [MS-DOS] 3.0 in parallel. Cluster addresses were increased to [16-bit], allowing for up to 65,524 clusters per volume, and consequently much greater file system sizes, at least in theory. However, the maximum possible number of sectors and the maximum (partition, rather than disk) size of 32MB did not change. Therefore, although cluster addresses were 16 bits, this format was not what today is commonly understood as FAT16. A partition type 0x04 indicates this form of FAT16 with less than 65536 sectors (less than 32MB for sector size 512).

With the initial implementation of FAT16 not actually providing for larger partition sizes than FAT12, the early benefit of FAT16 was to enable the use of smaller clusters, making disk usage more efficient, particularly for large numbers of files only a few hundred bytes in size.

MS-DOS 2.x hard disks larger than 15MB are incompatible with later versions of MS-DOS. A 20MB hard disk formatted under MS-DOS 3.0 was not accessible by the older MS-DOS 2.0 because MS-DOS 2.0 did not support version 3.0's FAT16. MS-DOS 3.0 could still access MS-DOS 2.0 style 8KB cluster partitions under 15MB.
===

FAT32
In order to overcome the volume size limit of [FAT16], while at the same time allowing [DOS] real mode code to handle the format, [Microsoft] designed a new version of the file system, FAT32, which supported an increased number of possible clusters, but could reuse most of the existing code, so that the conventional memory footprint was increased by less than 5KB under DOS. Cluster values are represented by [32-bit] numbers, of which 28 bits are used to hold the cluster number. The boot sector uses a 32-bit field for the sector count, limiting the FAT32 volume size to 2TB for a sector size of 512 bytes and 16TB for a sector size of 4,096 bytes. FAT32 was introduced with [MS-DOS] 7.1 / [Windows 95] OSR2 in 1996, although reformatting was needed to use it, and DriveSpace 3 (the version that came with Windows 95 OSR2 and [Windows 98]) never supported it. Windows 98 introduced a utility to convert existing hard disks from [FAT16] to FAT32 without loss of data. In the [Windows NT] line, native support for FAT32 arrived in [Windows 2000]. A free FAT32 driver for Windows NT 4.0 was available from Winternals, a company later acquired by Microsoft. Since the acquisition the driver is no longer officially available. Since 1998, Caldera's dynamically loadable DRFAT32 driver could be used to enable FAT32 support in [DR-DOS]. The first version of DR-DOS to natively support FAT32 and LBA access was OEM DR-DOS 7.04 in 1999. That same year IMS introduced native FAT32 support with REAL/32 7.90, and IBM 4690 OS added FAT32 support with version 2. Ahead Software provided another dynamically loadable FAT32.EXE driver for DR-DOS 7.03 with Nero Burning ROM in 2004. [IBM PC DOS] introduced native FAT32 support with OEM PC DOS 7.10 in 2003.

The maximum possible size for a file on a FAT32 volume is 4GB minus 1 byte or 4,294,967,295 (232 - 1) bytes. This limit is a consequence of the file length entry in the directory table and would also affect huge FAT16 partitions with a sufficient sector size. Large video files, DVD images, and databases easily exceed this limit.

As with previous file systems, the design of the FAT32 file system does not include direct built in support for long filenames, but FAT32 volumes can optionally hold VFAT long filenames in addition to short filenames in exactly the same way as VFAT long filenames have been optionally implemented for FAT12 and FAT16 volumes.

Two partition types have been reserved for FAT32 partitions, 0x0B and 0x0C. The latter type is also named FAT32X in order to indicate usage of LBA disk access instead of CHS. On such partitions, CHS related geometry entries, namely the CHS sector addresses in the MBR as well as the number of sectors per track and the number of heads in the EBPB record, may contain no or misleading values and should not be used.
===

FAT12
Between April and August 1980, while borrowing the [FAT] concept for SCP's own [8086] operating system [QDOS] 0.10, Tim Paterson extended the table elements to 12 bits, reduced the number of FATs to two, redefined the semantics of some of the reserved cluster values, and modified the disk layout, so that the root directory was now located between the FAT and the data area for his implementation of FAT12. Paterson also increased the nine-character (6.3) filename length limit to eleven characters in order to support [CP/M] style 8.3 filenames and File Control Blocks. The format used in [Microsoft] Standalone Disk [BASIC]'s 8-bit file system precursor was not supported by QDOS. By August 1980, QDOS had been renamed into [86-DOS] already. Starting with 86-DOS 0.42, the size and layout of directory entries was changed from 16 bytes to 32 bytes in order to add a file date stamp and increase the theoretical file size limit beyond the previous limit of 16MB. 86-DOS 1.00 became available in early 1981. Later in 1981, 86-DOS evolved into Microsoft's [MS-DOS] and [IBM PC DOS]. The capability to read previously formatted volumes with 16-byte directory entries was dropped with MS-DOS 1.20.
===

FAT - File Allocation Table
File Allocation Table (FAT) is a computer file system architecture and a family of industry standard file systems utilising it. The FAT file system is a legacy file system which is simple and robust. It offers good performance even in light weight implementations, but cannot deliver the same performance, reliability and scalability as some modern file systems. It is, however, supported for compatibility reasons by nearly all currently developed operating systems for personal computers and many mobile devices and embedded systems, and thus is a well suited format for data exchange between computers and devices of almost any type and age from 1981 up to the present.

Originally designed in 1977 for use on floppy disks, FAT was soon adapted and used almost universally on hard disks throughout the [DOS] and [Windows 9x] eras for two decades. As disk drives evolved, the capabilities of the file system have been extended accordingly, resulting in three major file system variants: [FAT12], [FAT16] and [FAT32]. The FAT standard has also been expanded in other ways while generally preserving backward compatibility with existing software.

With the introduction of more powerful computers and operating systems, as well as the development of more complex file systems for them, FAT is no longer the default file system for usage on [Microsoft Windows] computers.

Today, FAT file systems are still commonly found on floppy disks, USB sticks, flash and other solid-state memory cards and modules, and many portable and embedded devices. DCF implements FAT as the standard file system for digital cameras. FAT is also utilised in the boot stage of EFI-compliant computers.
===

GRUB
GNU GRUB (short for GNU GRand Unified Bootloader) is a boot loader package from the GNU Project. GRUB is the reference implementation of the Free Software Foundation's Multiboot Specification, which provides a user the choice to boot one of multiple operating systems installed on a computer or select a specific kernel configuration available on a particular operating system's partitions.

GNU GRUB was developed from a package called the Grand Unified Bootloader (a play on Grand Unified Theory). It is predominantly used for [Unix-like] systems. The GNU operating system uses GNU GRUB as its boot loader, as do most [Linux distributions]. The [Solaris] operating system has used GRUB as its boot loader on [x86] systems, starting with the Solaris 10 1/06 release.
===

Digg
Digg is a news aggregator with a curated front page, aiming to select stories specifically for the Internet audience such as science, trending political issues, and viral Internet issues. It was launched in its current form on 31 July 2012, with support for sharing content to other social platforms such as [Twitter] and [Facebook].

It formerly had been a very popular social news website, allowing people to vote web content up or down, called digging and burying, respectively. Quantcast had estimated Digg's monthly U.S. unique visits at 3.8 million. Digg's popularity prompted the creation of similar social networking sites with story submission and voting systems such as [Reddit].

In July 2008, the former company took part in advanced acquisition talks with [Google] for a reported $200 million price tag, but the deal ultimately fell through. After a controversial 2010 redesign and the departure of co-founders Jay Adelson and Kevin Rose, in July 2012 Digg was sold in three parts: the Digg brand, website and technology were sold to the current owner, Betaworks, for an estimated $500,000; 15 staff were transferred to the Washington Postâ'âs "SocialCode" for a reported $12 million; and a suite of patents were sold to [LinkedIn] for about $4 million.

According to third-party web analytics provider SimilarWeb, the DailyTech.com site has over 14 million visits per month, as of 2015, and is ranked #387 among News and Media sites.
===

ATI Rage
The ATI Rage is a series of graphics chipsets offering GUI 2D acceleration, video acceleration, and 3D acceleration. It is the successor to the Mach series of 2D accelerators.
===

RealPlayer
RealPlayer, formerly RealAudio Player, RealOne Player and RealPlayer G2, is a cross-platform media player app, developed by RealNetworks. The media player is compatible with numerous container file formats of the multimedia realm, including MP3, MP4, [QuickTime] File Format, Windows Media format, and the proprietary RealAudio and RealVideo formats. RealPlayer is also available for other operating systems ([OS]) and [Linux], [Unix], Palm OS, [Windows Mobile] and Symbian versions have been released.

The program is powered by an underlying open-source media engine called Helix.
===

VLC Media Player
VLC media player (commonly known as VLC) is a portable, free and open-source, cross-platform media player and streaming media server written by the VideoLAN project.

VLC media player supports many audio and video compression methods and file formats, including DVD-Video, video CD and streaming protocols. It is able to stream media over computer networks and to transcode multimedia files.

The default distribution of VLC includes a large number of free decoding and encoding libraries, avoiding the need for finding / calibrating proprietary plugins. The libavcodec library from the FFmpeg project provides many of VLC's codecs, but the player mainly uses its own muxers, and demuxers. It also has its own protocol implementations. It also gained distinction as the first player to support playback of encrypted DVDs on [Linux] and [OS X] by using the libdvdcss DVD decryption library.
===

Winamp
Winamp is a media player for [Windows], [Android], and [OS X] developed by Justin Frankel and Dmitry Boldyrev by their company Nullsoft, which they later sold to [AOL], who sold to Radionomy in January 2014. Since version 2 it has been sold as freemium and supports extensibility with plug-ins and skins, and features music visualisation, playlist and a media library, supported by a large online community.

Version 1 of Winamp was released in 1997, and grew quickly popular with over 3 million downloads, paralleling the developing trend of MP3 (music) file sharing. Winamp 2.0 was released on 8 September 1998. The 2.x versions were widely used and made Winamp one of the most downloaded Windows applications. By 2000, Winamp had over 25 million registered users.

A poor reception to the 2002 rewrite, Winamp 3, was followed by the release of Winamp 5 in 2003, and a later release of version 5.5 in 2007.
===

Windows Media Player
Windows Media Player (abbreviated WMP) is a media player and media library application developed by [Microsoft] that is used for playing audio, video and viewing images on personal computers running the [Microsoft Windows] operating system, as well as on Pocket PC and [Windows Mobile] based devices. Editions of Windows Media Player were also released for [Mac OS], [Mac OS X] and [Solaris] but development of these has since been discontinued.

In addition to being a media player, Windows Media Player includes the ability to rip music from and copy music to compact discs, burn recordable discs in Audio CD format or as data discs with playlists such as an MP3 CD, synchronise content with a digital audio player (MP3 player) or other mobile devices, and enable users to purchase or rent music from a number of online music stores.

Windows Media Player replaced an earlier application called Media Player, adding features beyond simple video or audio playback.

Windows Media Player 11 is available for [Windows XP] and included in [Windows Vista] and [Windows Server 2008]. The default file formats are Windows Media Video (WMV), Windows Media Audio (WMA), and Advanced Systems Format (ASF), and its own [XML] based playlist format called Windows Playlist (WPL). The player is also able to utilize a digital rights management service in the form of Windows Media DRM.

Windows Media Player 12 is the most recent version of Windows Media Player. It was released on 22 July 2009 along with [Windows 7] and has not available for previous versions of Windows nor has it been updated since for [Windows 8], [Windows 8.1] and Windows 10. Unlike Windows 8, [Windows RT] does not run Windows Media Player.
===

QuickTime
QuickTime is an extensible multimedia framework developed by [Apple Inc], capable of handling various formats of digital video, picture, sound, panoramic images, and interactivity. The classic version of QuickTime is available for [Windows XP] and later, as well as [Mac OS X Leopard] and later operating systems. A more recent version, QuickTime X, is currently available on Mac OS X Snow Leopard and newer.

As of the [Mac OS X Lion], the underlying media framework for Quicktime, QTKit, is deprecated in favor of a newer graphics framework, AV Foundation. The Quicktime X player however is still included with the new releases of the OS.
===

GPS - Global Positioning System
The Global Positioning System (GPS) is a space based navigation system that provides location and time information in all weather conditions, anywhere on or near the earth where there is an unobstructed line of sight to four or more GPS satellites. The system provides critical capabilities to military, civil, and commercial users around the world. The United States government created the system, maintains it, and makes it freely accessible to anyone with a GPS receiver.

The US began the GPS project in 1973 to overcome the limitations of previous navigation systems, integrating ideas from several predecessors, including a number of classified engineering design studies from the 1960s. The U.S. Department of Defence (DoD) developed the system, which originally used 24 satellites. It became fully operational in 1995. Bradford Parkinson, Roger L. Easton, and Ivan A. Getting are credited with inventing it.

Advances in technology and new demands on the existing system have now led to efforts to modernize the GPS system and implement the next generation of GPS Block IIIA satellites and Next Generation Operational Control System (OCX). Announcements from Vice President Al Gore and the White House in 1998 initiated these changes. In 2000, the U.S. Congress authorised the modernisation effort, GPS III.

In addition to GPS, other systems are in use or under development. The Russian Global Navigation Satellite System (GLONASS) was developed contemporaneously with GPS, but suffered from incomplete coverage of the globe until the mid 2000s. There are also the planned European Union Galileo positioning system, India's Indian Regional Navigation Satellite System, and the Chinese BeiDou Navigation Satellite System.
===

iPhone OS 1.x
First iteration of [Apple]'s touch-centric mobile operating system. No official name given on its initial release; Apple marketing literature simply stating the [iPhone] runs a version of Apple's desktop operating system, [OS X]. On 6 March 2008, with the release of the iPhone software development kit (iPhone SDK), Apple named it iPhone OS (they went on to rename it "[iOS]" on 7 June 2010).

iPhone OS 2.x
iPhone OS 2.0, the second major release of [iOS], became available on 11 July 2008 with the release of the [iPhone 3G]. Devices running 1.x are upgradable to this version. This version of the [O/S] introduces the [App Store], making third-party applications available to the [iPhone] and [iPod Touch]. Prior to the public release of iPhone OS 2.0, Apple held a keynote event to announce the iPhone OS Software Development Kit ("SDK") to developers.

iPhone OS 3.x
iPhone OS 3.0 became available with the [iPhone 3GS]. It was released on 17 June 2009. This release added features such as copy and paste, and MMS. Not all features were available on the original [iPhone]. Devices running iPhone OS 2.x were upgradeable to this software. The final release supported on the original iPhone and [iPod touch] is iPhone OS 3.1.3. The [iPad] was introduced with iOS 3.2. iOS 3.2 was the first version to be called "[iOS]".

iOS 4
iOS 4 (formerly iPhone OS) was made available to the public for the [iPhone] and [iPod Touch] on 21 June 2010. This is the first major [iOS] release to drop support for some devices (original [iPhone] and [iPod Touch]) and that iPod Touch users do not have to pay for.

The [iPhone 3G] and iPod Touch (2nd generation) have limited features, including lack of multitasking capabilities and the ability to set a home screen wallpaper, while the [iPhone 4], [iPhone 3GS], iPod Touch (3rd & 4th generation) have all features enabled, such as multitasking. The iPhone and iPod Touch (1st generation) cannot run iOS 4.0 and above.

iOS 4.2.1, released 22 November 2010, added [iPad] compatibility. It was the initial release on the [iPad 2]. It also was the last version to support iPhone 3G and iPod Touch (2nd generation). iOS 4.2.1 replaced iOS 4.2 due to a [Wi-Fi] bug in iOS 4.2 beta 3, causing [Apple] to release 2 golden masters (4.2 GM and 4.2.1 GM).

iOS 5
iOS 5 was previewed to the public on 6 June 2011. It was released for [iPhone 3GS], [iPhone 4] (GSM and CDMA), [iPhone 4S], [iPod Touch] (3rd & 4th generation), [iPad], and [iPad 2] on 12 October 2011.

iOS 5.1.1 is the final release supported for the iPad (1st generation) and iPod Touch (3rd generation).

iOS 6
iOS 6 was announced and previewed on 11 June 2012 during [Apple] Worldwide Developers Conference ([WWDC]) 2012, and its release was stated as Fall 2012. Following the pattern of previous [iOS] releases, some older devices were no longer supported, specifically the [iPod Touch] (3rd generation), and the [iPad] (1st generation). Supported devices include the [iPhone 3GS] and later; the iPod Touch (4th generation) and later; and the [iPad 2] and later. iOS 6 has limited support on the iPhone 3GS, iPad 2, and iPod Touch (4th generation).

On 12 September 2012 at San Francisco's Yerba Buena Center for the Arts, among other items unveiled, Apple announced three iOS related items: the next generation [iPhone 5], the redesigned iPod Touch (5th generation), and the announcement of the release of iOS 6.0 the following week.

iOS 6 was released to the public on 19 September 2012, through [iTunes] and over-the-air updates.

iOS 6.1.6 is the final release supported for the [iPhone 3GS] and iPod Touch (4th generation).

iOS 7
[Apple] announced iOS 7 on 10 June 2013 at its annual Apple Worldwide Developers Conference ([WWDC]) event, with release announced for sometime in Fall (Northern Hemisphere) or Spring (Southern Hemisphere) 2013. At their [iPhone] event on 10 September 2013, Apple announced the full release of iOS 7 for 18 September  2013, while also unveiling two new iPhone models: the [iPhone 5C] and [iPhone 5S]. With this release, support was once again dropped for older devices, specifically the [iPhone 3GS] (due to hardware limitations) and the iPod Touch (4th generation) (due to performance issues). Supported devices on this release include the [iPhone 4] onwards, iPod Touch (5th generation), the [iPad 2] onwards, and the [iPad Mini] (1st generation) onwards. iOS 7.1.2 is the final release on the iPhone 4. But, Apple can detect an unauthorised install and deactivate the device.

iOS 8
[Apple] announced iOS 8 on 2 June 2014 at its annual Apple Worldwide Developers Conference ([WWDC]) event, with release announced for sometime in Fall (Northern Hemisphere) or Spring (Southern Hemisphere) 2014. At their [iPhone] event on 9 September 2014, Apple announced the full release of iOS 8 for 17 September 2014, while also unveiling the [iPhone 6] and [iPhone 6 Plus]. With this release, Apple resumed the cycle of dropping support for older devices, specifically the [iPhone 4]. Supported devices on this release include the [iPhone 4S] onwards, [iPod Touch] (5th generation), the [iPad 2] onwards, and the [iPad Mini] (1st generation) onwards. iOS 8 has limited support on the iPad 2, iPhone 4S, and the iPod Touch (5th generation). The current version of iOS is iOS 8.4. This release added support for the all new Apple Music streaming service.

iOS 9
[Apple] announced iOS 9 on 8 June 2015 at its annual Apple Worldwide Developers Conference ([WWDC]) event, with release announced for sometime in Fall (Northern Hemisphere) or Spring (Southern Hemisphere) 2015. With this release, Apple did not drop support for any iOS devices, with all devices supporting iOS 8 being eligible for an upgrade. Supported devices on this release include the [iPhone 4S] onwards, [iPod Touch] (5th generation) onwards, the [iPad 2] onwards, and the [iPad Mini] (1st generation) onwards. The iPad 2 is also the first iOS device to support 6 major releases of iOS, supporting iOS 4, 5, 6, 7, 8, and 9. This is the greatest amount of major iOS releases a single iOS device has supported, surpassing the iPhone 4S which supports 5 major releases (iOS 5, 6, 7, 8, and 9) and iPod Touch 5th Generation supports 4 major releases (iOS 6, 7, 8, and 9). However, iOS 9 has limited support for the iPad 2, iPhone 4S, the iPad Mini (1st Generation), and the iPod touch 5th Generation. iOS 9 is currently in the beta stage with the latest beta being iOS 9.0 beta 3. Apple released a public beta similar to OS X El Capitan to users willing to test the beta on 8 July 2015.
===

Android 1.0
Android 1.0, the first commercial version of the software, was released on 23 September 2008. The first commercially available Android device was the [HTC] Dream. 

Android 1.1
On 9 February 2009, the Android 1.1 update was released, initially for the [HTC] Dream only. Android 1.1 was known as "Petit Four" internally, though this name was not used officially. The update resolved bugs, changed the Android API and added a number of features.

Android 1.5 - Cupcake
On 27 April 2009, the Android 1.5 update was released, based on [Linux kernel] 2.6.27. This was the first release to officially use a codename based on a dessert item ("Cupcake"), a theme which would be used for all releases henceforth. The update included several new features and UI amendments.

Android 1.6 - Donut
On 15 September 2009, the Android 1.6 SDK - dubbed Donut - was released, based on [Linux kernel] 2.6.29. Included in the update were numerous new features.

Android 2.0 - Ãclair 
On 26 October 2009, the Android 2.0 SDK - codenamed Ãclair - was released, based on [Linux kernel] 2.6.29. 

Android 2.2 - Froyo
On 20 May 2010, the SDK for Android 2.2 (Froyo, short for frozen yogurt) was released, based on [Linux kernel] 2.6.32.

Android 2.3 - Gingerbread
On 6 December 2010, the Android 2.3 (Gingerbread) SDK was released, based on [Linux kernel] 2.6.35. 

Android 3.0 - Honeycomb
On 22 February 2011, the Android 3.0 (Honeycomb) SDK - the first tablet only [Android] update - was released, based on [Linux kernel] 2.6.36. The first device featuring this version, the Motorola Xoom tablet, was released on 24 February 2011.
Most first and second generation [Google TV] enabled devices utilize Honeycomb 3.2.

Android 4.0.1 - Ice Cream Sandwich
The SDK for Android 4.0.1 (Ice Cream Sandwich), based on [Linux kernel] 3.0.1, was publicly released on 19 October 2011. [Google]'s Gabe Cohen stated that Android 4.0 was "theoretically compatible" with any Android 2.3.x device in production at that time. The source code for Android 4.0 became available on 14 November 2011. Ice Cream Sandwich was the last version to officially support [Adobe Systems] [Flash player]. The update introduced numerous new features.

Android 4.1 - Jelly Bean
[Google] announced Android 4.1 (Jelly Bean) at the Google I/O conference on 27 June 2012. Based on [Linux kernel] 3.0.31, Jelly Bean was an incremental update with the primary aim of improving the functionality and performance of the user interface. The performance improvement involved "Project Butter", which uses touch anticipation, triple buffering, extended vsync timing and a fixed frame rate of 60fps to create a fluid and "buttery-smooth" UI. Android 4.1 Jelly Bean was released to the Android Open Source Project on 9 July 2012, and the Nexus 7 tablet, the first device to run Jelly Bean, was released on 13 July 2012.

Google was expected to announce Jelly Bean 4.2 at an event in New York City on 29 October 2012, but the event was cancelled due to Hurricane Sandy. Instead of rescheduling the live event, Google announced the new version with a press release, under the slogan "A new flavour of Jelly Bean". Jelly Bean 4.2 was based on [Linux kernel] 3.4.0, and debuted on Google's Nexus 4 and Nexus 10, which were released on 13 November 2012.

Google released Jelly Bean 4.3 under the slogan "An even sweeter Jelly Bean" on July 24, 2013, during an event in San Francisco called "Breakfast with Sundar Pichai". Most Nexus devices received the update within a week, although the second generation Nexus 7 tablet was the first device to officially ship with it. A minor bugfix update was released on 22 August 2013.

Android 4.4 - KitKat
[Google] announced Android 4.4 KitKat on 3 September 2013. Although initially under the "Key Lime Pie" ("KLP") codename, the name was changed because "very few people actually know the taste of a key lime pie". Some technology bloggers also expected the "Key Lime Pie" release to be Android 5. KitKat debuted on Google's Nexus 5 on 31 October 2013, and was optimised to run on a greater range of devices than earlier Android versions, having 512MB of RAM as a recommended minimum; those improvements were known as "Project Svelte" internally at Google. The required minimum amount of RAM available to Android is 340MB, and all devices with less than 512MB of RAM must report themselves as "low RAM" devices.

Android 5.0 - Lollipop
Android 5.0 "Lollipop" was unveiled under the codename "Android L" on 25 June 2014, during [Google] I/O. It became available as official over-the-air (OTA) updates on 12 November 2014, for select devices that run distributions of [Android] serviced by Google, including Nexus and [Google Play] edition devices. Its source code was made available on 3 November 2014.

Lollipop features a redesigned user interface built around a responsive design language referred to as "material design". Other changes include improvements to the notifications, which can be accessed from the lockscreen and displayed within applications as top-of-the-screen banners. Furthermore, Google made internal changes to the platform, with the Android Runtime (ART) officially replacing Dalvik for improved application performance, and with changes intended to improve and optimize battery usage, known internally as Project Volta.
===

Google Nexus
Google Nexus is a line of consumer electronic devices that run the [Android] operating system. Google manages the design, development, marketing, and support of these devices, but some development and all manufacturing are carried out by partnering original equipment manufacturers (OEMs). The product family consists mostly of mobile devices six smartphones and four tablet computers have been released to date. As of April 2015, the devices currently available in the line are the Nexus 6 smartphone (made with Motorola Mobility), Nexus 9 tablet (made with HTC), and Nexus Player digital media player (made with Asus).

Devices in the Nexus line are considered Google's flagship Android products. They contain little to no manufacturer or wireless carrier modifications to Android (such as custom graphical user interfaces), although devices sold through carriers are sometimes SIM locked and may bear some extra branding. Nexus 6 devices sold through AT&amp;T, for example, are SIM locked and feature a custom boot splash screen and a logo on the back of the device, despite having otherwise identical hardware to the unlocked variant. The Verizon Galaxy Nexus featured a Verizon logo on the back and received software updates at a slower pace than the unlocked variant, though it featured different hardware to accommodate Verizon's CDMA network. All Nexus devices feature an unlock-able boot-loader to allow further development and end user modification. Nexus devices are often among the first Android devices to receive updates to the operating system.
===

iMac
The iMac is a range of all-in-one [Macintosh] desktop computers designed and built by [Apple Inc]. It has been the primary part of Apple's consumer desktop offerings since its debut in August 1998 (shipped; introduced June 1998), and has evolved through six distinct forms.

In its original form, the [iMac G3] had a gumdrop or egg-shaped look, with a [CRT] monitor, mainly enclosed by a coloured, translucent plastic case, which was refreshed early on with a sleeker design notable for its slot loaded optical drive. The second major revision, the [iMac G4], moved the design to a hemispherical base containing all the main components and an [LCD] monitor on a freely moving arm attached to it. The third and fourth major revisions, the [iMac G5] and the [Intel iMac] respectively, placed all the components immediately behind the display, creating a slim unified design that tilts only up and down on a simple metal base. The fifth major revision shared the same form as the previous model, but was thinner and used anodised aluminum and a glass panel over the entire front.

The newest iMac uses a different display unit, omits the SuperDrive, and uses different production techniques from the older unibody versions. This allows it to be thinner at the edge than older models, with an edge thickness of 5.9mm (but the same maximum depth). It also includes a dual microphone setup, and includes solid-state drive ([SSD]) or hard disk storage, or an Apple Fusion Drive, a hybrid of solid state and hard disk drives. This version of the iMac was announced on 23 October 2012, with the 21.5-inch (55 cm) version released on 30 November and the 27-inch (69 cm) version released in December; these were refreshed on 24 September 2013, with new Haswell processors, faster graphics, faster and larger SSD options and 802.11ac WiFi cards.

On 16 October 2014, a new version of the 27-inch (69 cm) iMac was announced, whose main feature is a "Retina 5K" display at a resolution of 5120 x 2880 pixels. The new model also includes a new processor, graphics chip, and IO, along with several new storage options.
===

iMac G3
The iMac G3 is a line of personal computers developed, manufactured, and sold by [Apple Computer] from 1998 until 2003. Noted for its innovative design via the use of translucent and brightly coloured plastics, it was the first consumer facing Apple product to debut under the recently returned interim CEO [Steve Jobs]. The iMac G3, among other factors, was responsible for Apple's turnaround from financial ruin during the late nineties and revitalised the Apple brand as design oriented and simple. It was, nevertheless, criticised for abandoning then current technological standards like the floppy drive and the Apple Desktop Bus connector in favor of the emerging [USB] standard. From its introduction in May 1998, the iMac G3 was updated over time with new hardware and colours until it was supplanted by the [iMac G4], as well as the [eMac].

Steve Jobs reduced the company's large product lines immediately upon becoming Apple's interim CEO in 1997. Toward the end of the year, Apple trimmed its line of desktop Macs down to the beige [Power Macintosh G3] series, which included the iMac's immediate predecessor, the Power Macintosh G3 All In One, which featured nearly identical specifications and was sold only to the educational market. Having discontinued the consumer targeted Performa series, Apple needed a replacement for the Performa's price point. The company announced the iMac on 6 May 1998 and began shipping the iMac G3 on 15 August 1998.

The iMac was dramatically different from any previous mainstream computer. It was made of translucent "Bondi Blue" coloured plastic, and was egg-shaped around a 14-inch (35.5 cm) [CRT] display. The case included a handle, and the peripheral connectors were hidden behind a door on the right hand side of the machine. Dual headphone jacks in the front complemented the built-in stereo speakers. Sir Jonathan Ive, currently Senior Vice President of Industrial Design at Apple, is credited with the industrial design. Its unique shape and color options helped ingrain itself into late 1990s pop culture. The iMac was the first computer to exclusively offer USB ports as standard, including as the connector for its new keyboard and mouse, thus abandoning previous Macintosh peripheral connections, such as the ADB, SCSI and GeoPort serial ports.

A further radical step was to abandon the 3Â½-inch floppy disk drive which had been present in every Macintosh since the first in 1984. Apple argued that recordable CDs, the Internet, and office networks were quickly making diskettes obsolete, however, Apple's omission generated controversy. At the time of iMac's introduction, third-party manufacturers offered external USB floppy disk drives, often in translucent plastic to match the iMac's enclosure. Apple had initially announced the internal modem in the iMac would operate at only 33.6 kbit/s rather than the new 56 kbit/s speed, but was forced by consumer pressure to adopt the faster standard.
===

eMac
The eMac, short for education Mac, is a [Macintosh] desktop computer made by [Apple Inc]. It was originally aimed at the education market, but was later made available as a cheaper mass market alternative to Apple's second-generation [LCD] display [iMac G4]. The eMac was pulled from retail on 12 October 2005 and was sold exclusively to educational institutions thereafter. It was discontinued by Apple on 5 July 2006 and replaced by a cheaper, low-end iMac that, like the eMac, was originally sold exclusively to educational institutions.

The eMac design closely resembles the first generation [iMac]. Compared to the first iMac, eMacs feature a PowerPC G4 processor that is significantly faster than the previous generation G3 processors, as well as a 17-inch flat CRT display. Unlike the [iMac G3], however, the eMac is not meant to be portable as it weighs 50 lb (23 kg) and lacks a carrying handle.
===

iMac G4
The iMac G4 is an all-in-one desktop computer produced and sold by [Apple Inc] from 2002 to mid 2004, succeeding the egg-shaped [iMac G3] and being succeeded by the [iMac G5].

The iMac G4 features an [LCD] display mounted on an adjustable arm above a hemisphere containing a full-size, tray-loading optical drive and a sixteenth generation PowerPC G4 74xx-series processor. The arm allowed the display to hold almost any angle around the dome shaped bottom. The iMac G4 was sold only in white, and was not translucent like the iMac G3. The machine was sold with the Apple Pro Keyboard and Apple Pro Mouse, which would be later redesigned and renamed the Apple Keyboard and Apple Mouse, respectively. Optional Apple Pro Speakers, which were of better quality than the internal speakers, were also available. The Apple Pro Speakers use a unique adapter, designed to work only with a select few Apple Macintosh models.

The iMac G4 originally included both [Mac OS 9] and [Mac OS X], due to the machine being released the year Mac OS 9 was discontinued. When running newer versions of Mac OS X ([Tiger] and [Leopard]), the iMac G4's GeForce4 MX GPU is not capable of Core Image rendering. This causes some minor graphical issues. One such issue would be the lack of the Dashboard ripple effect when a widget is introduced. Another would be an opaque menu bar in Mac OS X Leopard.

It was originally known as the The New iMac, while the existing iMac G3 continued to be sold for several months. During this time, Apple had all but eliminated [CRT] displays from its product line. However, the LCD iMacs were unable to match the low price point of the iMac G3, largely due to the higher cost of the LCD technology at the time. The iMac G3 was obsolete by this point, but low-cost machines were particularly important for the education market. Because of this affordability issue, Apple created the [eMac] in April 2002 and ended production of the iMac G3. The iMac G4 was then marketed as the "iMac" until its discontinuation, then was retroactively labeled iMac G4 to distinguish itself from the succeeding iMac G5 in August 2004.

Apple advertised the iMac G4 as having the adjustability of a desk lamp, and was nicknamed the "iLamp", similar to "Luxo Jr.", who was featured in a short film produced by Pixar, another venture of Apple co-founder [Steve Jobs]. One of the advertisements for the machine featured it sitting in a store window "reacting" to every move made by a passer-by on the street. At the end, when the man sticks out his tongue, the iMac responds by opening its optical drive. It was also known as the "Sunflower".
===

iMac G5 
The iMac G5 is an all-in-one desktop computer designed and built by [Apple Inc] It was the final iMac to use a [PowerPC] processor, making it the last model that could natively run [Mac OS 9] (Classic) applications. It was replaced in 2006 by the [Intel iMac].

In August 2004, the [iMac] design was overhauled. By this time, the PowerPC 970 processor had been released and was being used in the Power Mac G5 line. Famously, the Power Mac G5 needed multiple fans in a large casing because of the high heat output from the PowerPC 970.

Apple's new iMac managed to incorporate the PowerPC 970 into an all-in-one design with a distinctive form factor. The computer used the same 17 and 20-inch widescreen [LCD]s found in the [iMac G4], with the main logic board and optical drive now mounted directly behind the LCD panel; this gave the appearance of a thickened desktop LCD monitor. The approximately two inches deep enclosure is suspended above the desk by an aluminum arm that can be replaced by a VESA mounting plate. The iMac G5 uses an advanced cooling system controlled by the operating system; at low CPU loads this rendered the iMac G5 virtually silent. Apple boasted that it was the slimmest desktop computer on the market.

The iMac G5 was updated in March 2005 to the Ambient Light Sensor (ALS) revision. It included a handful of configuration differences - more RAM, a larger hard drive, improved graphics, Gigabit Ethernet, and standard AirPort Extreme (802.11g) and Bluetooth 2.0+EDR.

In October 2005, the final revision was released, adding an integrated iSight webcam mounted above the LCD and Apple's Front Row media interface. Other improvements included faster processors, more RAM, larger hard drives, and improved graphics. Notably this became the first Apple computer to use the PCI Express expansion bus and DDR2 SDRAM, with these features appearing shortly before they were incorporated into the Power Mac G5. It was declared "The Gold Standard of desktop PCs" by Walt Mossberg of the Wall Street Journal.

Although the iMac G5 iSight looked outwardly similar to the two previous revisions, it had a slimmer, internally new design. Improvements included superior cooling and performance increases. The stand could no longer be replaced with a VESA mount. This case, unlike the previous models, opened only from the front and requires the LCD screen to be removed before internal components can be accessed. Apple recommend no user serviceable items other than RAM, which is accessible through a small door at the base of the housing. In the intervening years, many guides have been posted on the Internet to support replacing other components including the hard drive and optical drive, though doing so voids any remaining Apple warranty.

The iMac G5 was succeeded by the [Intel] based iMac on 10 January 2006, beginning the 6 month transition of Apple's entire line of computers to the Intel architecture.
===

Intel iMAc
The [iMac] is a series of [Macintosh] desktop computers offered by [Apple Inc]. The current Apple iMac features either an [Intel Core i5] or [Core i7] processor, Intel Iris, [Nvidia GeForce] 700 Series, or [AMD Radeon] R9 M200 Series graphics cards, and a choice of either a 21.5" or 27" LED-LCD display.

Previous iMac models featured either a white polycarbonate enclosure or an aluminium enclosure. The late 2009 iMac model featured a unibody aluminium enclosure, which can still be seen on the current model. The current iMacs released in October 2012 also feature a much thinner display, with the edge measuring just 5mm.

At the Macworld Conference and Expo on 10 January 2006, [Steve Jobs] announced that the new iMac would be the first Macintosh to use an [Intel] CPU, the Core Duo. The introduction of the new iMac along with the Intel based [MacBook Pro] signaled the start of a six month transition from [PowerPC] to Intel processors.

The features, price, and case design remained unchanged from the [iMac G5]. The processor speed, however, according to tests run by Apple using SPEC, was declared to be two to three times faster than the iMac G5.

Polycarbonate iMac
Alongside the MacBook Pro, the iMac Core Duo represents Apple's first computer to feature Intel processors instead of PowerPC processors, a transition that completed in November 2006. Since the introduction of the iMac Core Duo, other lines have followed, including the introduction of the Intel Core powered [Mac mini] on 28 February 2006, the [MacBook] consumer line of laptop computers on 16 May 2006, the [Mac Pro] on 7 August 2006, and the Xserve in November 2006, completing the Macintosh family transition to Intel processors.

In early February 2006, Apple confirmed reports of video display problems on the new Intel based iMacs. When playing video on Apple's Front Row media browser, some 20-inch iMacs (those built-to-order with upgraded video cards) showed random horizontal lines, ghosting, video tearing and other problems. The problem was fixed with a software update.

In late 2006, Apple introduced a new version of the iMac which included a Core 2 Duo chip and a lower price. Apple added a new 24-inch model with IPS display and a resolution of 1920 Ã 1200 (WUXGA), making it the first iMac to be able to display 1080p content in its full resolution, and a VESA Flat Display Mounting Interface. Except for the 17-inch 1.83 GHz processor model, this version also included an 802.11n draft card.

Aluminum iMac
In August 2007, Apple introduced a complete redesign of the iMac, featuring an aluminum, glass and plastic enclosure. There is only one visible screw on the entire computer, located at the base of the iMac for accessing the memory slots. The back is no longer removable and is now a continuation of the aluminum body from the front and sides. The 17-inch model was completely removed from the lineup.

In March 2009, Apple released a minor refresh of the iMac line. Changes included a fourth USB port, removal of the FireWire 400 port, and a slightly redesigned base. The exterior design was almost identical to the older Intel based iMacs. The models were one 20-inch configuration and three 24-inch configurations (instead of two at each screen size as before).

Apple doubled the default RAM and hard-disk size on all models, moving the RAM to the DDR3 specification. This revision also introduced a new, smaller, and more compact Apple Keyboard that excluded the numeric keypad and forward delete key in favor of the fn + Delete keys shortcut by default. Users could, however, replace this version with a more traditional, full-size model with a numeric keypad by requesting Apple to build their machine to order through its online store.

Unibody iMac
In October 2009, a 16:9 aspect ratio screen was introduced in 21.5" and 27" models, replacing the 20" and 24" 16:10 aspect ratio screens of the previous generation. Video card options entirely switched to [AMD], save for the standard onboard [Nvidia] card in the base model. The iMac's processor selection saw a significant increase.

Default RAM has also been increased across the iMac range. With the advent of the larger screens, Apple doubled the number of memory slots from two to four. Consequently, the maximum memory capacity was also doubled (to 16GB).

On 3 May 2011, Intel's new Core i5 and Core i7 chips, based on the [Sandy Bridge microarchitecture], became available standard. The current iMac ships with [Bluetooth] and [AirPort] cards, an internal FaceTime HD camera, a power cord, the Apple Wireless Keyboard, and the wireless [Apple Magic Mouse] or [Apple Magic Trackpad].

Slim Unibody iMac
In October 2012, a new iMac model was introduced that featured a considerably smaller body depth than the previous models, measuring 5mm at its thinnest point. This was partly achieved by using a process called Full lamination. The display and glass are laminated together eliminating a 2 mm gap between them. The 21.5 in and 27 in screens remained at their previous resolutions, 1920Ã1080 and 2560Ã1440 respectively.

As with the 2009 model, memory has been upgraded; the standard specification is now 8GB, with the 21.5 in model supporting up to 16GB and the 27 in model supporting up to 32GB. It was reported that the 21.5 in iMac would have non-replaceable soldered memory similar to the [MacBook Air] and Retina display [MacBook Pro] though tear-downs show that it uses removable memory but accessing the modules requires ungluing the screen and removing the logic board. The 27 inch version features an access port to upgrade memory without disassembling the display. Apple also upgraded the computers' processors, using Intel's [Ivy Bridge microarchitecture] based Core i5 and Core i7 microprocessors.

Video cards are now Nvidia as standard. USB 3.0 ports are now included for the first time. The 2012 iMac also features the option of a Fusion Drive which combines an SSD and a conventional HDD to create more efficient and faster storage. Apple also removed the built-in optical drive starting with this iMac generation.

On 5 March 2013, Apple quietly announced an education only version of the iMac, with less powerful specs for a cheaper price. It includes a 3.3 GHz dual-core Intel i3 processor, 4GB of memory, a 500GB hard drive and Intel HD Graphics 4000, retailing for US$1099, $200 cheaper than the base-level consumer iMac.

On 24 September 2013, the 2012 iMac model was updated with 4th generation Intel Haswell processors and Nvidia 7xx series GPU, promising up to 1.4x improvements in performance. It also has 802.11ac Wi-Fi, which is capable of reaching speeds up to 1300 Mbit/s and PCIe-based flash storage, offering up to 1.5x the performance of previous generation (Ivy Bridge) iMacs. This applies to both the Fusion Drive and pure-SSD options.

iMac with Retina 5K Display
A Retina Display "5K" model with a resolution of 5120 x 2880 was introduced alongside the previous year's models during a keynote on 16 October 2014. This 27" model was given faster Haswell processors and its two [Thunderbolt] ports were updated to Thunderbolt 2. Secondary storage was also upgraded to a 1TB Fusion drive as standard and video options changed over to [AMD Radeon] R9 M290X and M295X.
===

Power Macintosh G3 Beige
The Power Macintosh G3, commonly called "beige G3s" or "platinum G3s" for the colour of their cases, is a series of personal computers designed, manufactured, and sold by [Apple Computer] from November 1997 to January 1999. It was the first [Macintosh] to use the PowerPC G3 (PPC750) microprocessor, and replaced a number of earlier Power Macintosh models, in particular the 7300, 8600 and 9600 models. It was succeeded by the [Power Macintosh G3 (Blue &amp; White)], which kept the name but introduced a radically different design. The introduction of the Desktop and Minitower G3 models coincided with Apple starting to sell user configurable Macs directly from its web site in an online store.

The Power Mac G3 introduced a fast and large Level 2 backside cache to Apple's product lineup, running at half processor speed. As a result, these machines were widely considered to be faster than Intel PCs of similar CPU clock speed at launch, an assertion that was backed up by benchmarks performed by Byte Magazine, which prompted Apple to create the "Snail" and "Toasted Bunnies" television commercials.

The Power Macintosh G3 was originally intended to be a midrange series, between the low-end Performa/LC models and the six-PCI slot Power Macintosh 9600. It is the earliest Old World ROM Macintosh model officially able to boot into [Mac OS X], and one of only two Old World ROM models able to boot into Mac OS X, the other model being the early PowerBook G3.

Apple developed a prototype G3 based six-slot full tower to be designated the Power Macintosh 9700. Despite demand from high-end users for more PCI slots in a G3 powered computer, Apple decided not to develop the prototype (dubbed "Power Express") into a shipping product, leaving the 9600 as the last six-slot Mac Apple would ever make.
===

Power Macintosh G3 (Blue &amp; White)
The Power Macintosh G3 series (commonly known as the "Blue and White G3", or sometimes either as the "B&W G3" or "Smurf Tower" to distinguish it from the original [Power Macintosh G3]) is a short lived series of personal computers designed, manufactured and sold by [Apple Computer Inc] as part of their Power Macintosh line. It was introduced in January 1999, succeeding the original "beige" Power Macintosh G3, with which it shared the name and processor architecture but little else; it was discontinued in favor of the Power Mac G4 line in August 1999.

The Blue & White G3 used a modified version of the memory/PCI controller, the [Motorola] MPC106 (codenamed "Grackle"); it used the MPC106 v4. The I/O "Heathrow" had been replaced by "Paddington" (adding 100 Mbit Ethernet and power save features), the audio chip "Screamer" (on the beige G3's "Personality Card") had been replaced by "Burgundy", and other controllers for Firewire (Texas Instruments PCI-Lynx), for USB etc. were added.

Though still based on the PowerPC G3 architecture, the G3 B&W was a totally new design. The first new Power Mac model after the release of the [iMac], it used a novel enclosure with the logic board on the folding "door", which swung down onto the desk for easy access (a design that was also used on all Power Mac G4 models except for the Cube), and borrowed the iMac's blue-and-white colour scheme. It also introduced the New World ROM to the Power Macintosh line.
===

MacBook Pro
The MacBook Pro (sometimes abbreviated MBP) is a line of [Macintosh] portable computers introduced in January 2006 by [Apple Inc], and now in its third generation. Replacing the [PowerBook G4], the MacBook Pro was the second model, after the [iMac], to be announced in the AppleâIntel transition. It is also the high-end model of the MacBook family and is currently produced with 13 and 15 inch screens, while a 17 inch version was also available in the past.

The first generation MacBook Pro appeared externally similar to the PowerBook G4, but used the [Intel Core] processors instead of [PowerPC] G4 chips. The 15 inch model was released in January 2006, a 17 inch model in April, both of which received several updates and Core 2 Duo processors later in the year.

The second model, known as the "unibody" model, has a more tapered design and a casing made from a single block of aluminum. It debuted in October 2008 as the 15 inch MacBook Pro and the 13 inch aluminum unibody MacBook. The following January brought the design to the 17 inch model, along with the built-in battery that joined the rest of the MacBook Pro line in June, including the 13 inch model which Apple absorbed into the MacBook Pro line. Subsequent updates brought upgraded Intel Core i5 and i7 processors and introduced Intel's Thunderbolt technology.

Apple released the third generation of MacBook Pro in June 2012 with a 15 inch screen. At the same time, slightly updated versions of the previous generation 13 and 15 inch unibody models were announced and sold in parallel, and the 17 inch variant was discontinued. While dimensionally smaller than its predecessor, the similarly styled third generation model retained a unibody design. The most substantial differences in the third generation MacBook Pro are the fitting of a significantly higher resolution [Retina display], the elimination of the optical drive, and replacement of hard disk drives with solid-state drives. A 13 inch third generation MacBook Pro was released in October 2012.
===

MacBook Air
The MacBook Air is a line of [Macintosh] ultraportable notebook computers from [Apple Inc]. The Air was designed to balance both performance and portability, consisting of a full-sized keyboard design, a machined casing made of aluminum, and a very light and thin structure. The MacBook Air is available in two sizes, with the length of the diagonal display determining the model size: 13.3 inch and 11.6 inch (or 33.78 cm and 29.46 cm, respectively). A range of model choices with different specifications are produced by Apple, and as of 2011, all Air models use solid-state drive (SSD) storage and [Intel] Core i5 or i7 central processing units (CPUs).

In the current Macintosh product line, the MacBook Air sits below both the thicker, higher performance [MacBook Pro] and thinner, lighter new [MacBook]. The MacBook Air was originally released as a premium ultraportable which was positioned above the then entry level MacBook. Since then, the MacBook Air has become Apple's entry-level laptop due to the discontinuation of the original MacBook in 2011, as well as lowered prices on subsequent iterations of the MacBook Air. In recent years, the MacBook Air has become the best-selling Macintosh computer and the best-selling ultraportable notebook, being credited with revolutionising lightweight yet powerful laptops known as Ultrabooks.
===

MacBook
The MacBook is a brand of notebook computers manufactured by [Apple] from early 2006 to late 2011, and relaunched in 2015. It replaced the [iBook] series and 12 inch [PowerBook] series of notebooks as a part of the Apple-Intel transition from [PowerPC]. Positioned as the low end of the MacBook family, below the premium ultra-portable [MacBook Air] and the powerful [MacBook Pro], the MacBook was aimed at the consumer and education markets. It was the best-selling Macintosh ever. For five months in 2008, it was the best-selling laptop of any brand in US retail stores. Collectively, the MacBook brand is the "world's top-selling line of premium laptops".

There have been four separate designs of the MacBook. The original model used a combination of polycarbonate and fiberglass casing which was modeled after the iBook G4. The second type was introduced in October 2008 alongside the 15 inch MacBook Pro; the MacBook shared the more expensive laptop's unibody aluminum casing, but omitted [FireWire], which hurt sales. A third design, introduced in late 2009, had a polycarbonate unibody casing and no FireWire ports.

On 20 July 2011, the MacBook was quietly discontinued for consumer purchase as it had been effectively superseded by the MacBook Air whose starting price was lowered. Apple continued to sell the MacBook to educational institutions until February 2012.

A new, redesigned MacBook line was launched on 9 March 2015. Available in silver, gold or space grey, it is thinner than the MacBook Air and removes the traditional MagSafe charging port (along with all other ports, except the headphone port) in favor of the multi-purpose USB Type-C port.

==
iPad Mini
iPad Miniis a line of mini tablet computers designed, developed, and marketed by [Apple Inc]. It is a sub-series of the [iPad] line of tablets, with a reduced screen size of 7.9 inches, in contrast to the standard 9.7 inches. The [first generation iPad Mini] was announced on 23 October 2012, and was released on 2 November 2012, in nearly all of Apple's markets. It features similar internal specifications to the [iPad 2], including its display resolution.

The [second generation iPad Mini], with a faster processor and a [Retina Display], was announced on 22 October 2013 and released on 12 November 2013. The [third generation iPad Mini] was announced on 16 October 2014 and was released on 24 October 2014; it features the same hardware as the [Mini 2] and the addition of a Touch ID fingerprint sensor compatible with Apple Pay.
===

iPad Mini (1st generation)
The first generation iPad Mini is a mini tablet computer designed, developed, and marketed by [Apple Inc]. It was announced on 23 October 2012, as the fifth major product in the [iPad] line and the first of the [iPad Mini] line, which features a reduced screen size of 7.9 inches, in contrast to the standard 9.7 inches. It features similar internal specifications to the [iPad 2], including its display resolution.

The first generation iPad Mini received positive reviews, with reviewers praising the device's size, design, and availability of applications, while criticising its use of a proprietary power connector, its lack of expandable storage, and the lack of [Retina display].
===

iPad Mini 2
The iPad Mini 2 is the second generation [iPad Mini] tablet computer produced and marketed by [Apple Inc]. It has a design almost identical to that of the [first generation iPad Mini] but features internal revisions such as the addition of the A7 system-on-a-chip and 2,048 x 1,536 resolution [Retina Display]. Internally, the iPad Mini 2 has nearly the same hardware as its sibling device, the [iPad Air]. Apple quietly released the iPad Mini 2 in Space Gray and Silver colours on 12 November 2013.

Its successor, the [iPad Mini 3], was unveiled on 16 October  2014.
===

iPad Mini 3
The iPad Mini 3 is the third generation [iPad Mini] tablet computer designed, developed and marketed by [Apple Inc]. It was announced alongside the [iPad Air 2] on 16 October 2014 and then released on 22 October. It uses primarily the same design and hardware as that of its predecessor, the [iPad Mini 2]. Its new features are the addition of the Touch ID sensor compatible with Apple Pay, differing storage sizes and being available in gold colour, as well as the previous colours.
===

First Generation iPad
The first generation iPad is a tablet computer designed and marketed by [Apple Inc]. The device features an Apple A4 processor, a 9.7" touchscreen display and the capability of accessing Cellular networks, though the latter is only available on certain variants of the first generation iPad. Using the [iOS] operating system, the iPad can play music, send and receive email and browse the web. Other functions, which include the ability to play games and access references, GPS navigation software and social network services can be enabled by downloading apps.

The device was announced and unveiled on 27 January 2010 at a media conference. On 4 April 2010, the [Wi-Fi] variant of the device was released in the United States, followed by the release of the Wi-Fi + Cellular variant on 30 April. On 28 May, it was released in Australia, Canada, France, Japan, Italy, Germany, Spain, Switzerland and the United Kingdom.

The device received primarily positive reviews from various technology blogs and publications. Reviewers praised the device for its wide range of capabilities and labelled it as a competitor to laptops and netbooks. Some aspects were criticised, including the closed nature of the operating system and the lack of support for the [Adobe Flash] multimedia format. During the first 80 days, three million iPads were sold. By the launch of the [iPad 2], Apple sold more than 15 million iPads.

On 2 March 2011, Apple announced the new iPad 2 and the discontinuation of production of the original iPad.
===

iPad 2
The second generation of the iPad, the iPad 2, is a tablet computer designed, developed and marketed by [Apple Inc]. It serves as a platform for audio-visual media including books, news, movies, music, games, presentations and web content. The iPad 2 has a lithium-ion polymer battery that lasts up to 10 hours, a dual core Apple A5 processor and was the first iPad to feature VGA front-facing and 720p rear-facing cameras designed for FaceTime video calling.

The device was available initially with three storage sizes, 16, 32 and 64 GB and two varying connectivity options, Wi-Fi only or Wi-Fi and cellular. Each variation of the device is available with either a black or white front glass panel. However, upon the release of the 3rd generation iPad, only the 16 GB variation with two connectivity options and two front glass panel options is available. The iPad 2 is the first [iOS] device to receive six major versions of iOS: these being iOS 4, 5, 6, 7, 8, and 9.

Apple unveiled the device on 2 March 2011. Upon the announcement of the iPad 2, the original model of the iPad was discontinued. Sales of the iPad 2 online and at retail stores began in the United States on 11 March 11. it was then released in 25 other Oceanian, North American and Western European countries on 25 March and released in eleven Asian countries as well as one African country on 29 April. Subsequently on 6 and 27 May, the device was released in three South American, six Eastern European and three Asian countries.

The device received mixed to positive reception from various blogs and publications. Although it was praised for its hardware improvement, such as the new Apple A5 chip, the software restriction on the iPad 2 and iOS in general drew criticism from various technology commentators. The device sold well in its first month of sales with 2.4â2.6 million units sold and 11.12 million units were sold in the third quarter of 2011.
===

iPad 3
The third generation iPad (originally marketed as The new iPad, retrospectively marketed as the iPad 3) is a tablet computer, developed and marketed by [Apple Inc]. The third device in the [iPad] line of tablets, it added a [Retina display], the new Apple A5X chip with a quad-core graphics processor, a 5 megapixel camera, HD 1080p video recording, voice dictation, and support for LTE networks in North America. It shipped with [iOS 5.1], which also provides a platform for audio-visual media, including electronic books, periodicals, films, music, computer games, presentations and web content.

In the US and Canada, nine variations of the third generation iPad were offered, compared to six in the rest of the world, although some countries had only the Wi-Fi only model. Each variation was available with black or white front glass panels, with options for 16, 32, or 64 GB of storage. In North America, connectivity options were Wi-Fi only, Wi-Fi + 4G (LTE) on Verizon, AT&amp;T, Telus, Rogers, or Bell. For the rest of the world outside North America, connectivity options are Wi-Fi only (on the Wi-Fi model) or Wi-Fi + 3G (on the Wi-Fi + Cellular model), with the latter unavailable in some countries, as 4G (LTE) connectivity for the device is not available outside North America. The Wi-Fi + Cellular model includes GPS capability.

Initially, the cellular version was titled and marketed worldwide as the "Wi-Fi + 4G" model, but due to lack of 4G (LTE) connectivity outside of North America, Apple later rebranded and altered their marketing to call this the "Wi-Fi + Cellular" model.

The tablet was released in ten countries on 16 March 2012. It gained mostly positive reviews, earning praise for its [Retina display], processor and 4G (LTE) capabilities. However, controversy arose when the LTE incompatibilities became known. Three million units were sold in the first three days.

After only 221 days of official availability, the third generation iPad was discontinued on 23 October 2012, following the announcement of the [fourth generation] iPad.
===

iPad 4
The fourth generation iPad (originally marketed as iPad with Retina display, retrospectively marketed as the iPad 4) is a tablet computer produced and marketed by [Apple Inc]. Compared to its predecessor, the fourth generation [iPad] maintained the [Retina Display] but featured new and upgraded components such as the Apple A6X chip, and the Lightning connector, which was introduced on 12 September 2012. It shipped with [iOS 6.0], which provides a platform for audio-visual media, including electronic books, periodicals, films, music, computer games, presentations and web content.

It was announced at a media conference on 23 October 2012 as the fourth generation of the iPad line, succeeding the third generation iPad, and was first released on 2 November 2012 in thirty five countries. The device was released throughout December in ten other countries including China, India and Brazil. The third generation was discontinued following the fourth's announcement.

The device is available with either a black or white front glass panel and various connectivity and storage options. Storage size options include 16GB, 32GB, 64GB, and 128GB; the available connectivity options are Wi-Fi only and Wi-Fi + Cellular with LTE capabilities.

The fourth generation iPad received primarily positive reviews and was praised for its hardware improvements as well as the Retina display, which was also featured in the device's predecessor. Furthermore, benchmarks reveal that the fourth generation iPad is able to perform CPU reliant tasks twice as fast as its predecessor. During the first weekend of sales, an aggregated amount of three million fourth generation iPads and [iPad Minis] were sold.
===

iPad Air
The iPad Air is the fifth generation [iPad] tablet computer designed, developed and marketed by [Apple Inc]. It was announced on 22 October 2013, and was released in space gray and silver colours on 1 November 2013. The iPad Air features a thinner design with similarities to the [iPad Mini], along with the same 64-bit Apple A7 processor with M7 coprocessor.

Its successor, the [iPad Air 2], was unveiled on 16 October 2014.
===

iPad Air 2 
The iPad Air 2 is the sixth generation iPad tablet computer designed, developed, and marketed by [Apple Inc]. It was announced on 16 October 2014 alongside the [iPad Mini 3] and then both were released on 22 October. The iPad Air 2 is thinner and faster than its predecessor, the iPad Air, and features Touch ID although the design, height and screen size are the same as those of the iPad Air.
===

iPhone 1
The iPhone (retroactively labeled the original iPhone and often referred to as iPhone 1, iPhone 1G, or iPhone 2G) is a smartphone that was designed and marketed by [Apple Inc]. It is the first generation of [iPhone] and was announced on 9 January 2007 after years of rumours and speculation.

It was introduced in the United States on 29 June 2007. It featured quad-band GSM cellular connectivity with GPRS and EDGE support for data transfer.

On 9 June 2008, Apple announced its successor, the [iPhone 3G]. The original iPhone no longer receives software updates from Apple; its final official firmware version was iPhone OS (now iOS) 3.1.3.

Since 11 June 2013, the original iPhone has been considered "obsolete" in Apple retail stores, "vintage" by other service providers in the US, and "obsolete" in all other regions. Apple does not service vintage or obsolete products, and replacement parts for obsolete products will not be available to service providers.
===

iPhone 3G
The iPhone 3G is a smartphone that was designed and marketed by [Apple Inc]. It is the second generation of [iPhone], and was introduced on 9 June 2008, at the [WWDC] 2008 at the Moscone Center in San Francisco, United States.

The iPhone 3G is internally similar to its predecessor, but includes several new hardware features, such as GPS, 3G data and tri-band UMTS/HSDPA. The device was originally loaded with the concurrently launched [iPhone OS 2.0]. In addition to other features (including push email and turn-by-turn navigation), this new operating system introduced the [App Store] Apple's new distribution platform for third-party applications.
===

iPhone 3GS
The iPhone 3GS is a smartphone that was designed and marketed by [Apple Inc]. It is the third generation [iPhone], successor to the [iPhone 3G]. It was introduced on 8 June 2009, at the [WWDC] 2009 which took place at the Moscone Center, San Francisco.

This iPhone is named "3GS" where "S" stood for Speed (Phil Schiller had mentioned it in the launch keynote). Improvements include performance, a 3-megapixel camera with higher resolution and video ability, voice control, and support for 7.2 Mbit/s HSDPA downloading (but remains limited to 384 kbps uploading as Apple had not implemented the HSUPA protocol). It was released in the U.S., Canada and six European countries on 8 June 2009, in Australia and Japan on 27 June and internationally in July and August 2009.

The iPhone 3GS runs Apple's [iOS] operating system. It is controlled mostly by a user's fingertips on a multi-touch display. It was succeeded as Apple's flagship smartphone in 2010 by the [iPhone 4]; however, the 3GS continued in production until September 2012 when the [iPhone 5] was announced.
===

iPhone 4 
The iPhone 4 is a smartphone that was designed and marketed by [Apple Inc]. Following a number of notable leaks, the iPhone 4 was first unveiled on 7 June 2010, at Apple's Worldwide Developers Conference in San Francisco, and was released on 24 June 2010, in the United States, United Kingdom, France, Germany and Japan. It is the 4th generation of iPhone, succeeding the [iPhone 3GS] and preceding the very similar [iPhone 4S].

The iPhone 4 introduced a new hardware design to the iPhone line, which Apple's CEO [Steve Jobs] touted as the thinnest smartphone in the world at the time; it consisted of an uninsulated stainless steel frame which doubles as an antenna, with internal components situated between chemically strengthened aluminosilicate glass. The iPhone 4 also introduced Apple's new high-resolution "[Retina Display]"; while maintaining the same physical size and display resolution as its precursors, its liquid crystal display had a pixel density of 326 pixels per inch. The iPhone 4 also introduced Apple's A4 system-on-chip, along with [iOS 4] which notably introduced multitasking functionality and Apple's new FaceTime video chat service. The iPhone 4 was also the first iPhone to include a front-facing camera, and the first to be released in a version for CDMA networks, ending AT&amp;T's period as the exclusive carrier of iPhone products in the United States.

It was succeeded as Apple's flagship smartphone in 2011 by the iPhone 4S; however, the 4 continued in production until 2013.

The iPhone 4 received generally positive reception, with critics praising its revamped design and more powerful hardware in comparison to previous models. While it was a market success, with over 600,000 pre-orders within 24 hours, the release of the iPhone 4 was plagued by highly publicised reports that abnormalities in its new antenna design caused the device to lose its cellular signal if held in a certain way.

The iPhone 4 spent the longest time as Apple's flagship iPhone model at fifteen months, and had the longest lifespan of any iPhone ever produced, spanning close to four years and available in some developing countries until early 2014.
===

iPhone 4S
The iPhone 4S (retroactively stylised with a lowercase 's' as iPhone 4s as of September 2013) is a smartphone that was designed and marketed by [Apple Inc]. It is the fifth generation of the [iPhone], succeeding the [iPhone 4] and preceding the [iPhone 5]. Announced on 4 October 2011 at Apple's Cupertino campus, its media coverage was accompanied by the death of former Apple CEO and co-founder [Steve Jobs] on the following day.

Available for pre-order on 7 October and coming to mainstream availability in retail stores on 14 October in the United States, Australia, Canada, the United Kingdom, France, Germany, and Japan, sales peaked over its predecessor with over a million sales in the first twenty four hours of preorder availability and over four million sales in the first four days of retail availability. Further worldwide rollout, including 22 additional countries on 28 October came over the next several months.

This iPhone was named "4S" where "S" stood for Siri (Apple CEO Tim Cook confirmed that during the Q&amp;A session at the D10 conference in May 2012), an iPhone 4S exclusive intelligent personal assistant that was later included in future generations of mobile Apple products. Retaining the external design of the iPhone 4, the 4S hosted revised hardware specifications, most notably an upgrade to the Apple A5 chipset, and an 8-megapixel camera with 1080p video recording. It debuted with [iOS 5], the fifth major version of iOS, Apple's mobile operating system, that introduced features including [iCloud], iMessage, Notification Center, Reminders, and [Twitter] integration.

Reception to the iPhone 4S was generally favorable. Reviewers noted [Siri], the new camera, and processing speeds as significant advantages over the prior model. It was succeeded by the iPhone 5 as Apple's flagship phone on 12 September 2012. The iPhone 4S remained in production, albeit being sold with reduced storage (from 16/32/64 GB down to 8 GB.) It was officially discontinued on 9 September 2014 following the announcement of the [iPhone 6] but is currently supported as of [iOS 9]: so the iPhone 4S is the first iPhone to support five major versions of iOS: these being iOS 5, 6, 7, 8, and 9.
===

iPhone 5
The iPhone 5 is a smartphone that was designed and marketed by [Apple Inc]. It is the sixth generation of the [iPhone], succeeding the [iPhone 4S] and preceding the [iPhone 5S] and [iPhone 5C]. Formally unveiled as part of a press event on 12 September 2012, it was released on 21 September 2012. The iPhone 5 featured major design changes in comparison to its predecessor. These included an aluminum-based body which was thinner and lighter than previous models, a taller screen with a nearly 16:9 aspect ratio, the Apple A6 system-on-chip, LTE support, and Lightning, a new compact dock connector which replaces the 30-pin design used by previous iPhone models. This was the second Apple phone to include its new [Sony] made 8MP Camera, first introduced on the iPhone 4S.

Apple began taking pre-orders on 14 September 2012, and over two million were received within 24 hours. Initial demand for the iPhone 5 exceeded the supply available at launch on 21 September 2012, and was described by Apple as "extraordinary", with pre-orders having sold twenty times faster than its predecessors. While reception to the iPhone 5 was generally positive, consumers and reviewers noted hardware issues, such as an unintended purple hue in photos taken, and the phone's coating being prone to chipping. Reception was also mixed over Apple's decision to switch to a different dock connector design, as the change affected iPhone 5's compatibility with accessories that were otherwise compatible with previous iterations of the line.

The iPhone 5 was officially discontinued by Apple on 10 September 2013 with the announcement of its successor, iPhone 5S, and iPhone 5C, the latter being a lower cost variation of the iPhone 5 with similar internal hardware and plastic casing. The introduction of the 5C deviated from Apple's previous market strategy, where the previous iPhone model would remain in production, but sold at a lower price point below the new model.

On 28 April 2014, Apple initiated an out of warranty recall program to replace any failing power buttons of iPhone 5 models which were manufactured prior to March 2013 at no cost. On 23 August 2014, Apple announced a program to replace batteries of iPhone 5 models that "may suddenly experience shorter battery life or need to be charged more frequently" which were sold between September 2012 and January 2013.
===

iPhone 5C
The iPhone 5C (marketed with a stylised lowercase 'c' as iPhone 5c) is a smartphone designed and marketed by [Apple Inc]. It is one of two successors to the [iPhone 5] and one of two predecessors to the [iPhone 6], along with its higher-end counterpart, the [iPhone 5S]. Apple held an event to formally introduce the iPhone 5C and 5S on 10 September 2013, and they were released on 20 September 2013, therefore discontinuing sales of the previous iPhone 5.

The 5C originally shipped with [iOS 7], Apple's mobile operating system. The current version of [iOS] for the iPhone 5C is [iOS 8.4]. The 5C uses much of the same hardware as the iPhone 5, with some iOS 7 optimisation like slightly improved battery life and software hardware colour coherence. However, there are a few differences from the iPhone 5; the 5C uses a hard-coated polycarbonate casing instead of aluminum used by the 5, along with a standard black glass front (instead of a white glass front offered on silver and gold iPhone models). The 5C lacks some of the features from the 5S; it uses the A6 chip instead of the A7 with motion co-processor, does not include Touch ID, does not support OpenGL ES 3.0, and lacked the Burst iSight camera mode and slow-motion video recording mode until [iOS 8]. Similar to the fifth generation [iPod Touch] models, the iPhone 5C is available in five colours: blue, green, pink, yellow, and white.

On 9 September 2014, the 16 and 32GB iPhone 5C models were discontinued in unison with the announcement of the [iPhone 6] and [iPhone 6 Plus], and the 16 and 32GB models were replaced by the 8GB model.
===

Phone 5S
Phone 5S is an [iOS] smartphone designed and marketed by [Apple Inc]. Apple held an event to formally introduce the high-range phone and its mid-range counterpart, the [iPhone 5C], on 10 September 2013, and they were released on 20 September 2013.

As with the naming precedents of the [iPhone 3GS] and [iPhone 4S], the [iPhone 5S] is a revised version of its predecessor, [iPhone 5]. The phone maintains a very similar design to its predecessor, aside from the introduction of a new home button design using a laser-cut sapphire cover surrounded by a metallic ring, Touch ID, a fingerprint recognition system built directly into the home button which can be used to unlock the phone and authenticate [App Store] and [iTunes Store] purchases, and an updated camera with a larger aperture and a dual-LED flash optimised for different colour temperatures. It also introduced the A7 dual-core processor, the first 64-bit (ARMv8-A) processor to be used on a smartphone, accompanied by the M7 "motion co-processor", a dedicated processor for processing motion data from its accelerometer and gyroscopes without requiring the attention of the main processor. It was also the first Apple device to ship with [iOS 7], which introduced a revamped visual appearance and other new features.

Reception towards the device was generally positive, with some outlets considering it to be best smartphone available on the market due to its upgraded hardware, Touch ID, and other changes introduced by iOS 7. However, others criticised iPhone 5S for being too similar to its predecessors, while others expressed security concerns about the Touch ID system. Nine million units of the iPhone 5S and iPhone 5C were sold on their weekend of release, breaking Apple's sales record for iPhones. The iPhone 5S was the best selling phone on all major U.S. carriers in September 2013.

On 19 September 2014, the iPhone 5S was succeeded as Apple's flagship cellphone by the [iPhone 6] and [iPhone 6 Plus], but the older model remains available for purchase at a reduced price.
===

iPhone 6 / iPhone 6 Plus
The iPhone 6 and iPhone 6 Plus are smartphones designed and marketed by [Apple Inc]. The devices are part of the [iPhone] series and were unveiled on 9 September 2014 and released on 19 September 2014. The iPhone 6 and iPhone 6 Plus jointly serve as successors to the [iPhone 5C] and [iPhone 5S]. The iPhone 6 and iPhone 6 Plus include a number of changes over its predecessor, including models with larger 4.7 and 5.5 inches (120 and 140 mm) displays, a faster processor, upgraded cameras, improved LTE and Wi-Fi connectivity, and support for a near-field communications-based mobile payments offering.

Pre-orders of the iPhone 6 and iPhone 6 Plus exceeded four million within its first 24 hours of availability an Apple record. More than ten million iPhone 6 and iPhone 6 Plus devices were sold in the first three days, another Apple record.
===

4G
4G, short for fourth generation, is the fourth generation of mobile telecommunications technology, succeeding [3G]. A 4G system, in addition to the usual voice and other services of 3G, provides mobile broadband Internet access, for example to laptops with wireless modems, to smartphones, and to other mobile devices. Potential and current applications include amended mobile web access, IP telephony, gaming services, high-definition mobile TV, video conferencing, 3D television, and cloud computing.
===

3G
3G, short form of third generation, is the third generation of mobile telecommunications technology. This is based on a set of standards used for mobile devices and mobile telecommunications use services and networks that comply with the International Mobile Telecommunications-2000 (IMT-2000) specifications by the International Telecommunication Union. 3G finds application in wireless voice telephony, mobile Internet access, fixed wireless Internet access, video calls and mobile TV.

3G telecommunication networks support services that provide an information transfer rate of at least 200 kbit/s. Later 3G releases, often denoted 3.5G and 3.75G, also provide mobile broadband access of several Mbit/s to smartphones and mobile modems in laptop computers. This ensures it can be applied to wireless voice telephony, mobile Internet access, fixed wireless Internet access, video calls and mobile TV technologies.

A new generation of cellular standards has appeared approximately every tenth year since [1G] systems were introduced in 1981 / 1982. Each generation is characterised by new frequency bands, higher data rates and non backward compatible transmission technology. The first 3G networks were introduced in 1998 and fourth generation "[4G]" networks in 2008.
===

1G
1G refers to the first generation of wireless telephone technology (mobile telecommunications). These are the analog telecommunications standards that were introduced in the 1980s and continued until being replaced by [2G] digital telecommunications. The main difference between the two mobile telephone systems (1G and 2G), is that the radio signals used by 1G networks are analog, while 2G networks are digital.

Although both systems use digital signalling to connect the radio towers (which listen to the handsets) to the rest of the telephone system, the voice itself during a call is encoded to digital signals in 2G whereas 1G is only modulated to higher frequency, typically 150 MHz and up. The inherent advantages of digital technology over that of analog meant that 2G networks eventually replaced them almost everywhere.

One such standard is NMT (Nordic Mobile Telephone), used in Nordic countries, Switzerland, the Netherlands, Eastern Europe and Russia. Others include AMPS (Advanced Mobile Phone System) used in North America and Australia, TACS (Total Access Communications System) in the United Kingdom, C-450 in West Germany, Portugal and South Africa, Radiocom 2000 in France, and RTMI in Italy. In Japan there were multiple systems. Three standards, TZ-801, TZ-802, and TZ-803 were developed by NTT (Nippon Telegraph and Telephone Corporation), while a competing system operated by DDI (Daini Denden Planning, Inc.[3]) used the JTACS (Japan Total Access Communications System) standard.

The antecedent to 1G technology is the mobile radio telephone, or 0G.
===

2G
2G is short for second generation wireless telephone technology. Second generation 2G cellular telecom networks were commercially launched on the GSM standard in Finland by Radiolinja (now part of Elisa Oyj) in 1991. Three primary benefits of 2G networks over their predecessors were that phone conversations were digitally encrypted; 2G systems were significantly more efficient on the spectrum allowing for far greater mobile phone penetration levels; and 2G introduced data services for mobile, starting with SMS text messages. 2G technologies enabled the various mobile phone networks to provide the services such as text messages, picture messages and MMS (multi media messages). All text messages sent over 2G are digitally encrypted, allowing for the transfer of data in such a way that only the intended receiver can receive and read it.

After 2G was launched, the previous mobile telephone systems were retrospectively dubbed [1G]. While radio signals on 1G networks are analog, radio signals on 2G networks are digital. Both systems use digital signalling to connect the radio towers (which listen to the handsets) to the rest of the telephone system.

2G has been superseded by newer technologies such as 2.5G, 2.75G, [3G], and [4G]; however, 2G networks are still used in many parts of the world.
===

Confluence
Confluence is team collaboration software. Written in [Java] and mainly used in corporate environments, it is developed and marketed by [Atlassian]. Confluence is sold as either on premises software or as a hosted solution.

Confluence 1.0 was released on 25 March 2004. The stated purpose of version 1.0 was "to build an application that was built to the requirements of an enterprise knowledge management system, without losing the essential, powerful simplicity of the wiki in the process".

In recent versions, Confluence has evolved into part of an integrated collaboration platform, and has been adapted to work in conjunction with [JIRA] and other Atlassian software products: FishEye, Clover, Crucible, [Bamboo] and Crowd.

In 2014, Confluence Data Center was released, to offer customers high availability with load balancing across nodes in a clustered setup.
===

HipChat
HipChat is a Web service for internal / private chat and [instant messaging]. As well as one-on-one and group / topic chat, it also features cloud-based file storage, video calling, searchable message history and inline image viewing. HipChat is available to download onto computers running [Windows], [Mac] or [Linux], as well as [Android] and [iOS] smartphones and tablets. HipChat is currently based on a freemium model, as much of the service is free with some additional features requiring organisations to pay $2 per user per month.

Having launched in January 2010, HipChat was founded by Chris Rivers, Garret Heaton and Pete Curley, the trio behind HipCal and Plaxo Pulse. HipChat was later acquired by [Atlassian] in March 2012.

HipChat has surpassed the billion message mark and has entered a cycle of exponential growth, as the number of messages has doubled every few months. As of January 2014, it was estimated that the service handles 60 messages per second and boasts 1.2 billion messages stored and half a terabyte of searchable data. HipChat is mainly written in [PHP] and [Python] using the Twisted framework, but features an extensive platform that utilizes numerous third-party services.
===

Bamboo
Bamboo is a continuous integration server from [Atlassian], the makers of [JIRA], [Confluence] and Crowd.

Bamboo is free for philanthropic and open-source projects. Commercial organisations are charged based on the number of build agents needed. Academic organisations receive a 50% discount on licensing costs under Atlassian's academic licensing program.

Bamboo supports builds in any programming language using any build tool, including [Ant], [Maven], [make], and any command line tools. Build notifications can be customised based on the type of event, and received via email, instant message, RSS, or pop-up windows in Eclipse based IDEs and [IntelliJ IDEA].
===

Bitbucket
Bitbucket is a web based hosting service for projects that use either the [Mercurial] (since launch) or [Git] (since October 2011) revision control systems. Bitbucket offers both commercial plans and free accounts. It offers free accounts with an unlimited number of private repositories (which can have up to five users in the case of free accounts) as of September 2010, but by inviting three users to join Bitbucket, three more users can be added, for eight users in total. Bitbucket is written in [Python] using the [Django] web framework.

It is similar to [GitHub], which primarily uses Git. In a 2008 blog post, Bruce Eckel compared Bitbucket favorably to Launchpad, which uses [Bazaar].
===

Von Neumann architecture
The Von Neumann architecture, also known as the Von Neumann model and Princeton architecture, is a computer architecture based on that described in 1945 by the mathematician and physicist [John von Neumann] and others in the First Draft of a Report on the EDVAC. This describes a design architecture for an electronic digital computer with parts consisting of a processing unit containing an arithmetic logic unit and processor registers, a control unit containing an instruction register and program counter, a memory to store both data and instructions, external mass storage, and input and output mechanisms. The meaning has evolved to be any stored program computer in which an instruction fetch and a data operation cannot occur at the same time because they share a common bus. This is referred to as the [Von Neumann bottleneck] and often limits the performance of the system.

The design of a Von Neumann architecture is simpler than the more modern [Harvard architecture] which is also a stored program system but has one dedicated set of address and data buses for reading data from and writing data to memory, and another set of address and data buses for fetching instructions.

A stored program digital computer is one that keeps its program instructions, as well as its data, in read-write, random-access memory (RAM). Stored program computers were an advancement over the program controlled computers of the 1940s, such as the [Colossus] and the ENIAC, which were programmed by setting switches and inserting patch leads to route data and to control signals between various functional units. In the vast majority of modern computers, the same memory is used for both data and program instructions, and the Von Neumann vs. Harvard distinction applies to the cache architecture, not the main memory.
===

John von Neumann
John von Neumann (28 December 1903 - 8 February 1957) was a Jewish born Hungarian and later American pure and applied mathematician, physicist, inventor, polymath, and polyglot. He made major contributions to a number of fields, including mathematics (foundations of mathematics, functional analysis, ergodic theory, geometry, topology, and numerical analysis), physics (quantum mechanics, hydrodynamics, and fluid dynamics), economics (game theory), computing ([Von Neumann architecture], linear programming, self replicating machines, stochastic computing), and statistics. He was a pioneer of the application of operator theory to quantum mechanics, in the development of functional analysis, a principal member of the Manhattan Project and the Institute for Advanced Study in Princeton (as one of the few originally appointed), and a key figure in the development of game theory and the concepts of cellular automata, the universal constructor, and the digital computer.

Von Neumann's mathematical analysis of the structure of self replication preceded the discovery of the structure of DNA. In a short list of facts about his life he submitted to the National Academy of Sciences, he stated "The part of my work I consider most essential is that on quantum mechanics, which developed in GÃ¶ttingen in 1926, and subsequently in Berlin in 1927 - 1929. Also, my work on various forms of operator theory, Berlin 1930 and Princeton 1935 â 1939; on the ergodic theorem, Princeton, 1931 â 1932". Along with theoretical physicist Edward Teller and mathematician Stanislaw Ulam, von Neumann worked out key steps in the nuclear physics involved in thermonuclear reactions and the hydrogen bomb.

Von Neumann wrote 150 published papers in his life; 60 in pure mathematics, 20 in physics, and 60 in applied mathematics. His last work, an unfinished manuscript written while in the hospital and later published in book form as The Computer and the Brain, gives an indication of the direction of his interests at the time of his death.
===

Von Neumann Bottleneck
The shared bus between the program memory and data memory leads to the Von Neumann bottleneck, the limited throughput (data transfer rate) between the CPU and memory compared to the amount of memory. Because program memory and data memory cannot be accessed at the same time, throughput is much smaller than the rate at which the CPU can work. This seriously limits the effective processing speed when the CPU is required to perform minimal processing on large amounts of data. The CPU is continually forced to wait for needed data to be transferred to or from memory. Since CPU speed and memory size have increased much faster than the throughput between them, the bottleneck has become more of a problem, a problem whose severity increases with every newer generation of CPU.

The von Neumann bottleneck was described by John Backus in his 1977 ACM Turing Award lecture. According to Backus:

"Surely there must be a less primitive way of making big changes in the store than by pushing vast numbers of words back and forth through the von Neumann bottleneck. Not only is this tube a literal bottleneck for the data traffic of a problem, but, more importantly, it is an intellectual bottleneck that has kept us tied to word-at-a-time thinking instead of encouraging us to think in terms of the larger conceptual units of the task at hand. Thus programming is basically planning and detailing the enormous traffic of words through the von Neumann bottleneck, and much of that traffic concerns not significant data itself, but where to find it."

The performance problem can be alleviated (to some extent) by several mechanisms. Providing a cache between the CPU and the main memory, providing separate caches or separate access paths for data and instructions (the so called [Modified Harvard architecture]), using branch predictor algorithms and logic, and providing a limited CPU stack or other on-chip scratchpad memory to reduce memory access are four of the ways performance is increased. The problem can also be sidestepped somewhat by using parallel computing, using for example the Non-Uniform Memory Access (NUMA) architecture this approach is commonly employed by supercomputers. It is less clear whether the intellectual bottleneck that Backus criticised has changed much since 1977. Backus's proposed solution has not had a major influence. Modern functional programming and object-oriented programming are much less geared towards "pushing vast numbers of words back and forth" than earlier languages like [Fortran] were, but internally, that is still what computers spend much of their time doing, even highly parallel supercomputers.
===

Harvard Architecture
The Harvard architecture is a computer architecture with physically separate storage and signal pathways for instructions and data. The term originated from the Harvard Mark I relay based computer, which stored instructions on punched tape (24 bits wide) and data in electro mechanical counters. These early machines had data storage entirely contained within the central processing unit, and provided no access to the instruction storage as data. Programs needed to be loaded by an operator; the processor could not initialise itself.

Today, most processors implement such separate signal pathways for performance reasons, but actually implement a modified Harvard architecture, so they can support tasks like loading a program from disk storage as data and then executing it.
===

Keyboard
In computing, a keyboard is a typewriter style device, which uses an arrangement of buttons or keys, to act as mechanical levers or electronic switches. Following the decline of punch cards and paper tape, interaction via teleprinter style keyboards became the main input device for computers.

A keyboard typically has characters engraved or printed on the keys and each press of a key typically corresponds to a single written symbol. However, to produce some symbols requires pressing and holding several keys simultaneously or in sequence. While most keyboard keys produce letters, numbers or signs (characters), other keys or simultaneous key presses can produce actions or execute computer commands.

Despite the development of alternative input devices, such as the [mouse], touchscreen, pen devices, character recognition and voice recognition, the keyboard remains the most commonly used device for direct (human) input of alphanumeric data into computers.

In normal usage, the keyboard is used as a text entry interface to type text and numbers into a [word processor], text editor or other programs. In a modern computer, the interpretation of key presses is generally left to the software. A computer keyboard distinguishes each physical key from every other and reports all key presses to the controlling software. Keyboards are also used for computer gaming, either with regular keyboards or by using keyboards with special gaming features, which can expedite frequently used keystroke combinations. A keyboard is also used to give commands to the operating system of a computer, such as [Windows] Control-Alt-Delete combination, which brings up a task window or shuts down the machine. A command-line interface is a type of user interface operated entirely through a keyboard, or another device doing the job of one.
===

Konami Code
The Konami Code is a cheat code that appears in many Konami video games, although the code also appears in some non Konami games.

During the title screen before the game demo begins, the player could press the following sequence of buttons on the game controller to enable the cheat:

ââââââââBA

The code has also found a place in popular culture as a reference to the third generation of video game consoles. The code is also present as an [Easter egg] on a number of websites.

The code was first used in the 1986 release of Gradius for the NES but was popularised among North American players in the NES version of Contra, for which it was also dubbed both the "Contra Code" and "30 Lives Code", because of its nearly necessary use in the game.

The Konami Code was created by Kazuhisa Hashimoto, who was developing the home port of the 1985 arcade game Gradius, a scrolling shooter released on the NES in 1986. Finding the game too difficult to play through during testing, he created a cheat code to give the player a full set of power-ups (normally attained gradually throughout the game). The code was still present in the released Gradius after Hashimoto forgot to remove it. Players discovered and shared the code.

The Konami Code was thus included in the series' other sequels and spin-offs, with some key differences:

- In the Super NES version of Gradius III, the original code destroys the player's ship. However, replacing â and â with the L and R triggers of the SNES controller powers up the ship.
- In the most recent iteration of the series Gradius Rebirth on the Wiiâthe Wii Remote's 1 and 2 buttons fill in for A and B, respectively.
- The code has been subsequently re-used in a large number of other games and is now used in the [Opera Browser] to activate hidden advanced settings.
===

Easter Egg 
An Easter egg is an intentional inside joke, hidden message, or feature in an interactive work such as a computer program, video game or DVD menu screen. The name has been said to evoke the idea of a traditional Easter egg hunt.

According to game designer Warren Robinett, this traditional term was coined into the context of media by [Atari] personnel who were alerted to the presence of a secret message which had been hidden by Robinett in his already widely distributed game, Adventure. Released in 1979, Atari's Adventure contains the first video game Easter egg to have been discovered by its players; the hidden item is the name of the game's programmer, Warren Robinett. Robinett inserted his Easter egg late in the game's development in an attempt to gain some recognition for his work, as Atari then kept its programmers' names secret. In 2004, an earlier Easter egg was found in Video Whizball, a 1978 game for the Fairchild Channel F system, displaying programmer Bradley Reid-Selth's surname.
===

Control-Alt-Delete
Control-Alt-Delete (often abbreviated to Ctrl+Alt+Del, also known as the "three-finger salute") is a computer keyboard command on [IBM PC compatible] computers, invoked by pressing the Delete key while holding the Control and Alt keys: Ctrl+Alt+Delete. The function of the key combination differs depending on the context but it generally interrupts or facilitates interrupting a function. For instance, in pre-boot environment (before an operating system starts) or in [DOS], [Windows 3.0] and earlier versions of [Windows] or [OS/2], the key combination reboots the computer. Starting with [Windows 3.1], the command invokes a task manager or security related component that facilitates ending a Windows session.
===

PDP-11
The PDP-11 is a series of [16-bit] minicomputers sold by Digital Equipment Corporation ([DEC]) from 1970 into the 1990s, one of a succession of products in the PDP series. The PDP-11 had several uniquely innovative features, and was easier to program than its predecessors through the additional general purpose registers. The PDP-11 replaced the PDP-8 in many real-time applications, although both product lines lived in parallel for more than 10 years. In total, around 600,000 PDP-11s of all models were sold, making it one of DEC's most successful product lines. Its successor in the mid-range minicomputer niche was the [32-bit] VAX-11, named as a nod to the PDP-11's popularity.

The PDP-11 is considered by some experts to be the most popular minicomputer ever. Design features of the PDP-11 influenced the design of most late 1970s computer systems including the [Intel x86] and the [Motorola 68000].

Design features of PDP-11 operating systems, as well as other operating systems from Digital Equipment, influenced the design of other operating systems such as [CP/M] and hence also [MS-DOS]. For a decade PDP-11 was the smallest system that could run [Unix]; the first officially named version ran on the PDP-11/20 in 1970. It is commonly stated that the [C] programming language took advantage of several low-level PDP-11âdependent programming features, albeit not originally by design.
===

Motherboard
A Motherboard (sometimes alternatively known as the mainboard, system board, planar board or logic board) is the main printed circuit board (PCB) found in computers and other expandable systems. It holds and allows communication between many of the crucial electronic components of a system, such as the central processing unit ([CPU]) and memory, and provides connectors for other peripherals. Unlike a backplane, a motherboard contains significant sub-systems such as the processor and other components.

Motherboard specifically refers to a PCB with expansion capability and as the name suggests, this board is often referred to as the "mother" of all components attached to it, which often include sound cards, video cards, network cards, hard drives, or other forms of persistent storage; TV tuner cards, cards providing extra [USB] or [FireWire] slots and a variety of other custom components (the term mainboard is applied to devices with a single board and no additional expansions or capability, such as controlling boards in televisions, washing machines and other embedded systems).
===

Chipset
In a computer system, a chipset is a set of electronic components in an integrated circuit that manages the data flow between the processor, memory and peripherals. It is usually found on the [motherboard]. Chipsets are usually designed to work with a specific family of microprocessors. Because it controls communications between the processor and external devices, the chipset plays a crucial role in determining system performance.
===

Computer Bus
In computer architecture, a bus (related to the Latin "omnibus", meaning "for all") is a communication system that transfers data between components inside a computer, or between computers. This expression covers all related hardware components (wire, optical fiber, etc.) and software, including communication protocols.

Early computer buses were parallel electrical wires with multiple connections, but the term is now used for any physical arrangement that provides the same logical functionality as a parallel electrical bus. Modern computer buses can use both parallel and bit serial connections, and can be wired in either a multidrop (electrical parallel) or daisy chain topology, or connected by switched hubs, as in the case of [USB].
===

Cray
Cray Inc is an American supercomputer manufacturer headquartered in Seattle, Washington. The company's predecessor, Cray Research Inc (CRI), was founded in 1972 by computer designer Seymour Cray. Seymour Cray went on to form the spin-off Cray Computer Corporation (CCC), in 1989, which went bankrupt in 1995, while Cray Research was bought by SGI the next year. Cray Inc was formed in 2000 when Tera Computer Company purchased the Cray Research Inc business from SGI and adopted the name of its acquisition.
===

eb Hypertext Application Technology Working Group (WHATWG)
The Web Hypertext Application Technology Working Group (WHATWG) is a community of people interested in evolving [HTML] and related technologies. The WHATWG was founded by individuals from [Apple], the [Mozilla Foundation] and [Opera Software] in 2004. Since then, the editor of the WHATWG specifications, Ian Hickson, has moved to [Google]. Chris Wilson of [Microsoft] was invited but did not join, citing the lack of a patent policy to ensure all specifications can be implemented on a royalty free basis.

The WHATWG has a small, invitation only oversight committee called "Members", which has the power to impeach the editor of the specifications. Anyone can participate as a Contributor by joining the WHATWG mailing list.
===

Web Worker
A web worker, as defined by the World Wide Web Consortium ([W3C]) and the Web Hypertext Application Technology Working Group ([WHATWG]), is a [JavaScript] script executed from an [HTML] page that runs in the background, independently of other user interface scripts that may also have been executed from the same HTML page. Web workers are able to utilize multi-core CPUs more effectively.

The W3C and WHATWG envision web workers as long running scripts that are not interrupted by user interface scripts (scripts that respond to clicks or other user interactions). Keeping such workers from being interrupted by user activities should allow Web pages to remain responsive at the same time as they are running long tasks in the background.

The simplest use of workers is for performing a computationally expensive task without interrupting the user interface.

The W3C and the WHATWG are currently in the process of developing a definition for an API for web workers.
===

WebSocket
WebSocket is a protocol providing full-duplex communication channels over a single [TCP] connection. The WebSocket protocol was standardised by the [IETF] as [RFC 6455] in 2011, and the WebSocket API in Web IDL is being standardised by the [W3C].

WebSocket is designed to be implemented in Web browsers and Web servers, but it can be used by any client or server application. The WebSocket Protocol is an independent TCP based protocol. Its only relationship to [HTTP] is that its handshake is interpreted by HTTP servers as an Upgrade request. The WebSocket protocol makes more interaction between a browser and a website possible, facilitating live content and the creation of real-time games. This is made possible by providing a standardised way for the server to send content to the browser without being solicited by the client, and allowing for messages to be passed back and forth while keeping the connection open. In this way a two-way (bi-directional) ongoing conversation can take place between a browser and the server. The communications are done over TCP port number 80, which is of benefit for those environments which block non-web Internet connections using a firewall. Similar two-way browser-server communications have been achieved in non-standardised ways using stop gap technologies such as Comet.

The WebSocket protocol is currently supported in most major browsers including [Google Chrome], [Internet Explorer], [Firefox], [Safari] and [Opera]. WebSocket also requires web applications on the server to support it.

Unlike HTTP, WebSocket provides full-duplex communication. Additionally, WebSocket enables streams of messages on top of TCP. TCP alone deals with streams of bytes with no inherent concept of a message. Before WebSocket, port 80 full-duplex communication was attainable using Comet channels; however, Comet implementation is nontrivial, and due to the TCP handshake and HTTP header overhead, it is inefficient for small messages. WebSocket protocol aims to solve these problems without compromising security assumptions of the web.

The WebSocket protocol specification defines two new URI schemes, ws: and wss:, for unencrypted and encrypted connections respectively. Apart from the scheme name and fragment (# is not supported), the rest of the URI components are defined to use URI generic syntax.

Using the Google Chrome Developer Tools, developers can inspect the WebSocket handshake as well as the WebSocket frames.
===

Mathematical Markup Language (MathML)
Mathematical Markup Language (MathML) is a mathematical markup language, an application of [XML] for describing mathematical notations and capturing both its structure and content. It aims at integrating mathematical formulae into [World Wide Web] pages and other documents. It is a recommendation of the [W3C] math working group and part of [HTML5].
===

Emacs
Emacs and its derivatives are a family of text editors that are characterised by their extensibility. The manual for the most widely used variant, GNU Emacs, describes it as "the extensible, customisable, self documenting, real-time display editor". Development of the first Emacs began in the mid 1970s and continues actively as of 2015. Emacs has over 2,000 built-in commands and allows the user to combine these commands into macros to automate work. Emacs Lisp provides a deep extension capability allowing users and developers to write new commands using a dialect of the [Lisp] programming language.

The original EMACS was written in 1976 by Richard Stallman and Guy L. Steele, Jr. as a set of Editor MACroS for the TECO editor. It was inspired by the ideas of the TECO macro editors TECMAC and TMACS.

The most popular, and most ported, version of Emacs is GNU Emacs, which was created by Stallman for the GNU Project. XEmacs is a variant that branched from GNU Emacs in 1991. Both GNU Emacs and XEmacs use Emacs Lisp and are for the most part compatible with each other.

Emacs is, along with [vi], one of the two main contenders in the traditional editor wars of [Unix] culture. Both are among the oldest application programs still in use.
===

AT&amp;T
AT&amp;T Inc is an American multinational telecommunications corporation, headquartered at Whitacre Tower in downtown Dallas, Texas. AT&amp;T is the second largest provider of mobile telephone and the largest provider of fixed telephone in the United States, and also provides broadband subscription television services. AT&amp;T is the third largest company in Texas (the largest non-oil company, behind only ExxonMobil and ConocoPhillips, and also the largest Dallas company). As of May 2014, AT&a,mp;T is the 23rd largest company in the world as measured by a composite of revenues, profits, assets and market value, and the 16th largest non-oil company. As of 2015, it is also the 20th largest mobile telecom operator in the world, with over 123.9 million mobile customers.

AT&amp;T Inc began its existence as Southwestern Bell Corporation, one of seven Regional Bell Operating Companies (RBOC's) created in 1983 in the divestiture of the American Telephone and Telegraph Company (founded 1885, later AT&amp;T Corp.) following the 1982 United States v. AT&amp;T antitrust lawsuit. Southwestern Bell changed its name to SBC Communications Inc in 1995. In 2005, SBC purchased former parent AT&a,p;T Corp and took on its branding, with the merged entity naming itself AT&amp;T Inc and using the iconic AT&amp;T Corp. logo and stock trading symbol.
===

Representational State Transfer (REST)
In computing, Representational State Transfer (REST) is a software architecture style for building scalable web services. REST gives a coordinated set of constraints to the design of components in a distributed hypermedia system that can lead to a more performant and maintainable architecture.

RESTful systems typically, but not always, communicate over the Hypertext Transfer Protocol with the same [HTTP] verbs (GET, POST, PUT, DELETE, etc.) which web browsers use to retrieve web pages and to send data to remote servers. REST interfaces usually involve collections of resources with identifiers, for example /people/mary, which can be operated upon using standard verbs, such as DELETE /people/mary.

The W3C Technical Architecture Group (TAG) developed the REST architectural style in parallel with HTTP 1.1 of 1996 - 1999, based on the existing design of HTTP 1.0 of 1996. The [World Wide Web] itself represents the largest implementation of a system conforming to the REST architectural style.
===

HTTP Status Codes
The following is a list of Hypertext Transfer Protocol (HTTP) response status codes. This includes codes from [IETF] internet standards as well as other IETF RFCs, other specifications and some additional commonly used codes. The first digit of the status code specifies one of five classes of response; the bare minimum for an [HTTP] client is that it recognises these five classes. The phrases used are the standard examples, but any human readable alternative can be provided. Unless otherwise stated, the status code is part of the HTTP/1.1 standard ([RFC 7231]).

The Internet Assigned Numbers Authority ([IANA]) maintains the official registry of HTTP status codes.

[Microsoft IIS] sometimes uses additional decimal sub-codes to provide more specific information.

1xx Informational
Request received, continuing process.

This class of status code indicates a provisional response, consisting only of the Status Line and optional headers, and is terminated by an empty line. Since HTTP/1.0 did not define any 1xx status codes, servers must not send a 1xx response to an HTTP/1.0 client except under experimental conditions.

100 Continue
This means that the server has received the request headers, and that the client should proceed to send the request body (in the case of a request for which a body needs to be sent; for example, a POST request). If the request body is large, sending it to a server when a request has already been rejected based upon inappropriate headers is inefficient. To have a server check if the request could be accepted based on the request's headers alone, a client must send Expect: 100 continue as a header in its initial request and check if a 100 Continue status code is received in response before continuing (or receive 417 Expectation Failed and not continue).
101 Switching Protocols
This means the requester has asked the server to switch protocols and the server is acknowledging that it will do so.
102 Processing (WebDAV; [RFC 2518])
As a [WebDAV] request may contain many sub-requests involving file operations, it may take a long time to complete the request. This code indicates that the server has received and is processing the request, but no response is available yet. This prevents the client from timing out and assuming the request was lost.

2xx Success
This class of status codes indicates the action requested by the client was received, understood, accepted and processed successfully.

200 OK
Standard response for successful HTTP requests. The actual response will depend on the request method used. In a GET request, the response will contain an entity corresponding to the requested resource. In a POST request, the response will contain an entity describing or containing the result of the action.

201 Created
The request has been fulfilled and resulted in a new resource being created.
202 Accepted
The request has been accepted for processing, but the processing has not been completed. The request might or might not eventually be acted upon, as it might be disallowed when processing actually takes place.
203 Non-Authoritative Information (since HTTP/1.1)
The server successfully processed the request, but is returning information that may be from another source.
204 No Content
The server successfully processed the request, but is not returning any content. Usually used as a response to a successful delete request.
205 Reset Content
The server successfully processed the request, but is not returning any content. Unlike a 204 response, this response requires that the requester reset the document view.
206 Partial Content ([RFC 7233])
The server is delivering only part of the resource (byte serving) due to a range header sent by the client. The range header is used by tools like wget to enable resuming of interrupted downloads, or split a download into multiple simultaneous streams.
207 Multi-Status (WebDAV; [RFC 4918])
The message body that follows is an [XML] message and can contain a number of separate response codes, depending on how many sub-requests were made.
208 Already Reported (WebDAV; [RFC 5842])
The members of a DAV binding have already been enumerated in a previous reply to this request, and are not being included again.
226 IM Used ([RFC 3229])
The server has fulfilled a request for the resource, and the response is a representation of the result of one or more instance manipulations applied to the current instance.

3xx Redirection
This class of status code indicates the client must take additional action to complete the request. Many of these status codes are used in [URL] redirection.

A user agent may carry out the additional action with no user interaction only if the method used in the second request is GET or HEAD. A user agent should not automatically redirect a request more than five times, since such redirections usually indicate an infinite loop.

300 Multiple Choices
Indicates multiple options for the resource that the client may follow. It, for instance, could be used to present different format options for video, list files with different extensions, or word sense disambiguation.
301 Moved Permanently
This and all future requests should be directed to the given URI.
302 Found
This is an example of industry practice contradicting the standard. The HTTP/1.0 specification ([RFC 1945]) required the client to perform a temporary redirect (the original describing phrase was "Moved Temporarily"), but popular browsers implemented 302 with the functionality of a 303 See Other. Therefore, HTTP/1.1 added status codes 303 and 307 to distinguish between the two behaviours. However, some Web applications and frameworks use the 302 status code as if it were the 303.
303 See Other (since HTTP/1.1)
The response to the request can be found under another URI using a GET method. When received in response to a POST (or PUT / DELETE), it should be assumed that the server has received the data and the redirect should be issued with a separate GET message.
304 Not Modified ([RFC 7232])
Indicates that the resource has not been modified since the version specified by the request headers If-Modified-Since or If-None-Match. This means that there is no need to retransmit the resource, since the client still has a previously downloaded copy.
305 Use Proxy (since HTTP/1.1)
The requested resource is only available through a proxy, whose address is provided in the response. Many HTTP clients (such as [Mozilla] and [Internet Explorer]) do not correctly handle responses with this status code, primarily for security reasons.
306 Switch Proxy
No longer used. Originally meant "Subsequent requests should use the specified proxy".
307 Temporary Redirect (since HTTP/1.1)
In this case, the request should be repeated with another URI; however, future requests should still use the original URI. In contrast to how 302 was historically implemented, the request method is not allowed to be changed when reissuing the original request. For instance, a POST request should be repeated using another POST request.
308 Permanent Redirect ([RFC 7538])
The request, and all future requests should be repeated using another URI. 307 and 308 (as proposed) parallel the behaviours of 302 and 301, but do not allow the HTTP method to change. So, for example, submitting a form to a permanently redirected resource may continue smoothly.
308 Resume Incomplete ([Google])
This code is used in the Resumable HTTP Requests Proposal to resume aborted PUT or POST requests.

4xx Client Error
The 4xx class of status code is intended for cases in which the client seems to have erred. Except when responding to a HEAD request, the server should include an entity containing an explanation of the error situation, and whether it is a temporary or permanent condition. These status codes are applicable to any request method. User agents should display any included entity to the user.

400 Bad Request
The server cannot or will not process the request due to something that is perceived to be a client error (e.g., malformed request syntax, invalid request message framing, or deceptive request routing).
401 Unauthorised ([RFC 7235])
Similar to 403 Forbidden, but specifically for use when authentication is required and has failed or has not yet been provided. The response must include a WWW-Authenticate header field containing a challenge applicable to the requested resource. See Basic access authentication and Digest access authentication.
402 Payment Required
Reserved for future use. The original intention was that this code might be used as part of some form of digital cash or micropayment scheme, but that has not happened, and this code is not usually used. [YouTube] uses this status if a particular IP address has made excessive requests, and requires the person to enter a [CAPTCHA].
403 Forbidden
The request was a valid request, but the server is refusing to respond to it. Unlike a 401 Unauthorised response, authenticating will make no difference.
404 Not Found
The requested resource could not be found but may be available again in the future. Subsequent requests by the client are permissible.
405 Method Not Allowed
A request was made of a resource using a request method not supported by that resource; for example, using GET on a form which requires data to be presented via POST, or using PUT on a read-only resource.
406 Not Acceptable
The requested resource is only capable of generating content not acceptable according to the Accept headers sent in the request.
407 Proxy Authentication Required ([RFC 7235])
The client must first authenticate itself with the proxy.
408 Request Timeout
The server timed out waiting for the request. According to HTTP specifications: "The client did not produce a request within the time that the server was prepared to wait. The client MAY repeat the request without modifications at any later time".
409 Conflict
Indicates that the request could not be processed because of conflict in the request, such as an edit conflict in the case of multiple updates.
410 Gone
Indicates that the resource requested is no longer available and will not be available again. This should be used when a resource has been intentionally removed and the resource should be purged. Upon receiving a 410 status code, the client should not request the resource again in the future. Clients such as search engines should remove the resource from their indices. Most use cases do not require clients and search engines to purge the resource, and a "404 Not Found" may be used instead.
411 Length Required
The request did not specify the length of its content, which is required by the requested resource.
412 Precondition Failed ([RFC 7232])
The server does not meet one of the preconditions that the requester put on the request.
413 Payload Too Large ([RFC 7231])
The request is larger than the server is willing or able to process. Called "Request Entity Too Large " previously.
414 Request-URI Too Long
The URI provided was too long for the server to process. Often the result of too much data being encoded as a query string of a GET request, in which case it should be converted to a POST request.
415 Unsupported Media Type
The request entity has a media type which the server or resource does not support. For example, the client uploads an image as image/svg+xml, but the server requires that images use a different format.
416 Requested Range Not Satisfiable ([RFC 7233])
The client has asked for a portion of the file (byte serving), but the server cannot supply that portion. For example, if the client asked for a part of the file that lies beyond the end of the file.
417 Expectation Failed
The server cannot meet the requirements of the Expect request header field.
418 I'm a teapot ([RFC 2324])
This code was defined in 1998 as one of the traditional [IETF] April Fools' jokes, in RFC 2324, Hyper Text Coffee Pot Control Protocol, and is not expected to be implemented by actual HTTP servers. The RFC specifies this code should be returned by tea pots requested to brew coffee.
419 Authentication Timeout (not in [RFC 2616])
Not a part of the HTTP standard, 419 Authentication Timeout denotes that previously valid authentication has expired. It is used as an alternative to 401 Unauthorised in order to differentiate from otherwise authenticated clients being denied access to specific server resources.
420 Method Failure (Spring Framework)
Not part of the HTTP standard, but defined by Spring in the HttpStatus class to be used when a method failed. This status code is deprecated by Spring.
420 Enhance Your Calm ([Twitter])
Not part of the HTTP standard, but returned by version 1 of the Twitter Search and Trends API when the client is being rate limited. Other services may wish to implement the 429 Too Many Requests response code instead.
421 Misdirected Request (HTTP/2)
The request was directed at a server that is not able to produce a response (for example because a connection reuse).
422 Unprocessable Entity (WebDAV; [RFC 4918])
The request was well formed but was unable to be followed due to semantic errors.
423 Locked (WebDAV; [RFC 4918])
The resource that is being accessed is locked.
424 Failed Dependency (WebDAV; [RFC 4918])
The request failed due to failure of a previous request (e.g., a PROPPATCH).
426 Upgrade Required
The client should switch to a different protocol such as TLS/1.0, given in the Upgrade header field.
428 Precondition Required ([RFC 6585])
The origin server requires the request to be conditional. Intended to prevent "the 'lost update' problem, where a client GETs a resource's state, modifies it, and PUTs it back to the server, when meanwhile a third party has modified the state on the server, leading to a conflict".
429 Too Many Requests ([RFC 6585])
The user has sent too many requests in a given amount of time. Intended for use with rate limiting schemes.
431 Request Header Fields Too Large ([RFC 6585])
The server is unwilling to process the request because either an individual header field, or all the header fields collectively, are too large.
440 Login Timeout ([Microsoft])
A Microsoft extension. Indicates that your session has expired.
444 No Response ([Nginx])
Used in Nginx logs to indicate that the server has returned no information to the client and closed the connection (useful as a deterrent for malware).
449 Retry With ([Microsoft])
A Microsoft extension. The request should be retried after performing the appropriate action.
450 Blocked by Windows Parental Controls ([Microsoft])
A Microsoft extension. This error is given when Windows Parental Controls are turned on and are blocking access to the given webpage.
451 Unavailable For Legal Reasons (Internet draft)
Defined in the internet draft "A New HTTP Status Code for Legally restricted Resources". Intended to be used when resource access is denied for legal reasons, e.g. censorship or government mandated blocked access. A reference to the 1953 dystopian novel Fahrenheit 451, where books are outlawed.
451 Redirect ([Microsoft])
Used in Exchange ActiveSync if there either is a more efficient server to use or the server cannot access the users' mailbox.
The client is supposed to re-run the HTTP Autodiscovery protocol to find a better suited server.
494 Request Header Too Large ([Nginx])
Nginx internal code similar to 431 but it was introduced earlier in version 0.9.4 (on 21 January 2011).
495 Cert Error ([Nginx])
Nginx internal code used when [SSL] client certificate error occurred to distinguish it from 4XX in a log and an error page redirection.
496 No Cert ([Nginx])
Nginx internal code used when client didn't provide certificate to distinguish it from 4XX in a log and an error page redirection.
497 HTTP to HTTPS ([Nginx])
Nginx internal code used for the plain HTTP requests that are sent to HTTPS port to distinguish it from 4XX in a log and an error page redirection.
498 Token expired/invalid (Esri)
Returned by ArcGIS for Server. A code of 498 indicates an expired or otherwise invalid token.
499 Client Closed Request ([Nginx])
Used in Nginx logs to indicate when the connection has been closed by client while the server is still processing its request, making server unable to send a status code back.
499 Token required (Esri)
Returned by ArcGIS for Server. A code of 499 indicates that a token is required (if no token was submitted).

5xx Server Error
The server failed to fulfil an apparently valid request.

Response status codes beginning with the digit "5" indicate cases in which the server is aware that it has encountered an error or is otherwise incapable of performing the request. Except when responding to a HEAD request, the server should include an entity containing an explanation of the error situation, and indicate whether it is a temporary or permanent condition. Likewise, user agents should display any included entity to the user. These response codes are applicable to any request method.

500 Internal Server Error
A generic error message, given when an unexpected condition was encountered and no more specific message is suitable.
501 Not Implemented
The server either does not recognise the request method, or it lacks the ability to fulfil the request. Usually this implies future availability.
502 Bad Gateway
The server was acting as a gateway or proxy and received an invalid response from the upstream server.
503 Service Unavailable
The server is currently unavailable (because it is overloaded or down for maintenance). Generally, this is a temporary state.
504 Gateway Timeout
The server was acting as a gateway or proxy and did not receive a timely response from the upstream server.
505 HTTP Version Not Supported
The server does not support the HTTP protocol version used in the request.
506 Variant Also Negotiates ([RFC 2295])
Transparent content negotiation for the request results in a circular reference.
507 Insufficient Storage (WebDAV; [RFC 4918])
The server is unable to store the representation needed to complete the request.
508 Loop Detected (WebDAV; [RFC 5842])
The server detected an infinite loop while processing the request (sent in lieu of 208 Already Reported).
509 Bandwidth Limit Exceeded ([Apache] bw/limited extension)
This status code is not specified in any RFCs. Its use is unknown.
510 Not Extended ([RFC 2774])
Further extensions to the request are required for the server to fulfil it.
511 Network Authentication Required ([RFC 6585])
The client needs to authenticate to gain network access. Intended for use by intercepting proxies used to control access to the network (e.g., "captive portals" used to require agreement to Terms of Service before granting full Internet access via a [Wi-Fi] hotspot).
520 Unknown Error
This status code is not specified in any RFC and is returned by certain services, for instance [Microsoft Azure] and [CloudFlare] servers: "The 520 error is essentially a âcatch-allâ response for when the origin server returns something unexpected or something that is not tolerated / interpreted (protocol violation or empty response)".
522 Origin Connection Time-out
This status code is not specified in any RFCs, but is used by [CloudFlare]'s reverse proxies to signal that a server connection timed out.
598 Network read timeout error (Unknown)
This status code is not specified in any RFCs, but is used by [Microsoft] HTTP proxies to signal a network read timeout behind the proxy to a client in front of the proxy.
599 Network connect timeout error (Unknown)
This status code is not specified in any RFCs, but is used by [Microsoft] HTTP proxies to signal a network connect timeout behind the proxy to a client in front of the proxy.
===

301 Moved Permanently
The [HTTP response status code] 301 Moved Permanently is used for permanent [URL] redirection, meaning current links or records using the URL that the response is received for should be updated. The new URL should be provided in the Location field included with the response. [RFC 2616] states that:

If a client has link editing capabilities, it should update all references to the Request URL.
The response is catchable.
Unless the request method was HEAD, the entity should contain a small hypertext note with a hyperlink to the new URL(s).
If the 301 status code is received in response to a request of any type other than GET or HEAD, the client must ask the user before redirecting.
===

302 Found
The [HTTP response status code] 302 Found is a common way of performing [URL] redirection.

An HTTP response with this status code will additionally provide a URL in the location header field. The user agent (e.g. a Web browser) is invited by a response with this code to make a second, otherwise identical, request to the new URL specified in the location field. The HTTP/1.0 specification ([RFC 1945]) initially defined this code, and gives it the description phrase "Moved Temporarily".

Many web browsers implemented this code in a manner that violated this standard, changing the request type of the new request to GET, regardless of the type employed in the original request (e.g. POST). For this reason, HTTP/1.1 ([RFC 2616]) added the new status codes 303 and 307 to disambiguate between the two behaviours, with 303 mandating the change of request type to GET, and 307 preserving the request type as originally sent. Despite the greater clarity provided by this disambiguation, the 302 code is still employed in web frameworks to preserve compatibility with browsers that do not implement the HTTP/1.1 specification.

As a consequence, the update of [RFC 2616] changes the definition to allow user agents to rewrite POST to GET.
===

303 See Other
The [HTTP response status code] 303 See Other is a way to redirect web applications to a new [URI], particularly after a HTTP POST has been performed, since [RFC 2616] (HTTP 1.1).

According to [RFC 7231], which obsoletes [RFC 2616], "A 303 response to a GET request indicates that the origin server does not have a representation of the target resource that can be transferred by the server over HTTP. However, the Location field value refers to a resource that is descriptive of the target resource, such that making a retrieval request on that other resource might result in a representation that is useful to recipients without implying that it represents the original target resource".

303 See Other has been proposed as one way of responding to a request for a URI that identifies a real world object according to Semantic Web theory (the other being the use of hash URIs). For example, if http://www.example.com/id/iain identifies a person, Iain, then it would be inappropriate for a server to respond to a GET request with 200 OK, as the server could not deliver Iain himself. Instead the server would issue a 303 See Other response which redirected to a separate URI providing a description of the person Iain.

303 See Other can be used for other purposes. For example, when building a [RESTful] web API that needs to return to the caller immediately but continue executing asynchronously (such as a long lived image conversion), the web API can provide a status check URI that allows the original client who requested the conversion to check on the conversion's status. This status check web API should return 303 See Other to the caller when the task is complete, along with a URI from which to retrieve the result in the Location HTTP header field.
===

403 Forbidden
A [Web server] may return a 403 Forbidden [HTTP status code] in response to a request from a client for a web page or resource to indicate that the server can be reached and understood the request, but refuses to take any further action. Status code 403 responses are the result of the web server being configured to deny access, for some reason, to the requested resource by the client.

A typical request that may receive a 403 Forbidden response is a GET for a web page, performed by a web browser to retrieve the page for display to a user in a browser window. The web server may return a 403 Forbidden status for other types of requests as well.

The [Apache] Web server returns 403 Forbidden in response to requests for URL paths that correspond to filesystem directories, when directory listings have been disabled in the server. Some administrators configure the Mod proxy extension to Apache to block such requests, and this will also return 403 Forbidden. [Microsoft IIS] responds in the same way when directory listings are denied in that server. In [WebDAV], the 403 Forbidden response will be returned by the server if the client issued a PROPFIND request but did not also issue the required Depth header, or issued a Depth header of infinity.
===

404 Not Found 
The 404 or Not Found error message is an [HTTP response status code] indicating that the client was able to communicate with a given server, but the server could not find what was requested.

The web site hosting server will typically generate a "404 Not Found" web page when a user attempts to follow a broken or dead link; hence the 404 error is one of the most recognisable errors users can find on the Web.

Custom Error Pages
[Web servers] can typically be configured to display a customised 404 error page, including a more natural description, the parent site's branding, and sometimes a site map, a search form or 404 page widget. The protocol level phrase, which is hidden from the user, is rarely customised.

[Internet Explorer], however, will not display custom pages unless they are larger than 512 bytes, opting instead to display a "friendly" error page. [Google Chrome] includes similar functionality, where the 404 is replaced with alternative suggestions generated by [Google] algorithms, if the page is under 512 bytes in size.

Another problem is that if the page does not provide a [favicon], and a separate custom 404 page exists, extra traffic and longer loading times will be generated on every page view.

Many organisations use 404 error pages as an opportunity to inject humor into what may otherwise be a serious website. For example, Metro UK shows a polar bear on a skateboard, and the web development agency Left Logic has a simple drawing program.

While many websites send additional information in a 404 error message such as a link to the homepage of a website or a search box some also endeavour to find the correct web page the user wanted. Extensions are available for some popular Content Management Systems ([CMS]) to do this.

In Europe, the NotFound project, created by multiple European organisations including Missing Children Europe and Child Focus, encourages site operators to add a snippet of code to serve customised 404 error pages which provide data about missing children.
===

418 I'm A Teapot
What is the [HTTP response status code] 418 I'm a teapot all about? Well, the group of people who make these codes and set the standards is the [IETF] or "Internet Engineering Task Force". To propose new standards, the members release [RFC]âs or "Requests for Comments" to the community. Every year since 1989, they release a few humorous RFCâs for Aprilâs Fool Day and on 1 April 1998, [RFC 2324] introduced the "Hyper Text Coffee Pot Control Protocol" or (HTCPCP/1.0). This was a brand new protocol for controlling, monitoring, and diagnosing coffee pots. Now, the RFC is pretty funny with lines like "Coffee pots heat water using electronic mechanisms, so there is no fire. Thus, no firewalls are necessary". If you have never read it, itâs definitely worth a read. Now, you may be asking, if this is a COFFEE protocol, why the "teapot" code? This is answered in Section 2.3.2. in that "Any attempt to brew coffee with a teapot should result in the HTTP error code 418 I'm a teapot and the resulting entity body MAY be short and stout". And just like that the "418 Iâm a teapot" code was born!
===

HTTP Header Fields
HTTP header fields are components of the header section of request and response messages in the Hypertext Transfer Protocol ([HTTP]). They define the operating parameters of an HTTP transaction.

The header fields are transmitted after the request or response line, which is the first line of a message. Header fields are colon separated name value pairs in clear text string format, terminated by a carriage return (CR) and line feed (LF) character sequence. The end of the header section is indicated by an empty field, resulting in the transmission of two consecutive CR-LF pairs. Historically, long lines could be folded into multiple lines; continuation lines are indicated by the presence of a space (SP) or horizontal tab (HT) as the first character on the next line. This folding is now deprecated.

Field Names
A core set of fields is standardised by the Internet Engineering Task Force ([IETF]) in RFCs [7230], [7231], [7232], [7233], [7234], and [7235]. The permanent registry of header fields and repository of provisional registrations are maintained by the [IANA]. Additional field names and permissible values may be defined by each application.

Non-standard header fields were conventionally marked by prefixing the field name with X- but this convention was deprecated in June 2012 because of the inconveniences it caused when non-standard fields became standard. An earlier restriction on use of Downgraded- was lifted in March 2013.

Field Values
A few fields can contain comments (i.e. in User-Agent, Server, Via fields), which can be ignored by software.

Many field values may contain a quality key value pair, specifying a weight to use in content negotiation.

Size Limits
The standard imposes no limits to the size of each header field name or value, or to the number of fields. However, most servers, clients, and proxy software impose some limits for practical and security reasons. For example, the [Apache] 2.3 server by default limits the size of each field to 8190 bytes, and there can be at most 100 header fields in a single request.
===

User Agent
In computing, a user agent is software (a software agent) that is acting on behalf of a user. For example, an email reader is a mail user agent, and in the Session Initiation Protocol ([SIP]), the term user agent refers to both end points of a communications session.

In many cases, a user agent acts as a client in a network protocol used in communications within a clientâserver distributed computing system. In particular, the Hypertext Transfer Protocol ([HTTP]) identifies the client software originating the request, using a "User-Agent" header, even when the client is not operated by a user. The SIP protocol (based on HTTP) followed this usage.
===

User Agent Identification
When a software agent operates in a network protocol, it often identifies itself, its application type, operating system, software vendor, or software revision, by submitting a characteristic identification string to its operating peer. In [HTTP], [SIP], and [SMTP] / NNTP protocols, this identification is transmitted in a header field User-Agent. Bots, such as Web crawlers, often also include a URL and / or e-mail address so that the Webmaster can contact the operator of the bot.

In HTTP, the User-Agent string is often used for content negotiation, where the origin server selects suitable content or operating parameters for the response. For example, the User-Agent string might be used by a web server to choose variants based on the known capabilities of a particular version of client software.

The User-Agent string is one of the criteria by which Web crawlers may be excluded from accessing certain parts of a Web site using the [Robots Exclusion Standard] (robots.txt file).

As with many other HTTP request headers, the information in the "User-Agent" string contributes to the information that the client sends to the server, since the string can vary considerably from user to user.

The User-Agent string format is currently specified by Section 5.5.3 of HTTP/1.1 Semantics and Content. The format of the User-Agent string in HTTP is a list of product tokens (keywords) with optional comments. For example if a user's product were called WikiBrowser, their user agent string might be WikiBrowser/1.0 Gecko/1.0. The "most important" product component is listed first. The parts of this string are as follows:

Product name and version (WikiBrowser/1.0)
Layout engine and version (Gecko/1.0)
During the first browser war, many web servers were configured to only send web pages that required advanced features, including frames, to clients that were identified as some version of [Mozilla]. Other browsers were considered to be older products such as [Mosaic], Cello or Samba and would be sent a bare bones HTML document.

For this reason, most Web browsers use a User-Agent value as follows: Mozilla/[version] ([system and browser information]) [platform] ([platform details]) [extensions]. For example, [Safari] on the [iPad] has used the following:

Mozilla/5.0 (iPad; U; CPU OS 3_2_1 like Mac OS X; en-us) AppleWebKit/531.21.10 (KHTML, like Gecko) Mobile/7B405

The components of this string are as follows:

Mozilla/5.0: Previously used to indicate compatibility with the Mozilla rendering engine
(iPad; U; CPU OS 3_2_1 like Mac OS X; en-us): Details of the system in which the browser is running
AppleWebKit/531.21.10: The platform the browser uses
(KHTML, like Gecko): Browser platform details
Mobile/7B405: This is used by the browser to indicate specific enhancements that are available directly in the browser or through third parties. An example of this is Microsoft Live Meeting which registers an extension so that the Live Meeting service knows if the software is already installed, which means it can provide a streamlined experience to joining meetings.
Before migrating to the [Chromium] code base, [Opera] was the most prolific web browser to not begin its User-Agent string with "Mozilla" (instead beginning it with "Opera"). As of 15 July 2013, Opera's User-Agent string begins with "Mozilla/5.0" and, to avoid encountering legacy server rules, no longer includes the word "Opera" (instead using the string "OPR" to denote the Opera version).

Automated web crawling tools can use a simplified form, where an important field is contact information in case of problems. By convention the word "bot" is included in the name of the agent. For example:

Googlebot/2.1 (+http://www.google.com/bot.html)
Automated agents are expected to follow rules in a special file called "robots.txt".

User Agent Spoofing
The popularity of various Web browser products has varied throughout the Web's history, and this has influenced the design of Web sites in such a way that Web sites are sometimes designed to work well only with particular browsers, rather than according to uniform standards by the World Wide Web Consortium ([W3C]) or the Internet Engineering Task Force ([IETF]). Web sites often include code to detect browser version to adjust the page design sent according to the user agent string received. This may mean that less popular browsers are not sent complex content (even though they might be able to deal with it correctly) or, in extreme cases, refused all content. Thus, various browsers have a feature to cloak or spoof their identification to force certain server-side content. For example, the [Android] browser identifies itself as [Safari] (among other things) in order to aid compatibility.

Other HTTP client programs, like download managers and offline browsers, often have the ability to change the user agent string.

Spam bots and Web scrapers often use fake user agents.

At times it has been popular among Web developers to initiate Viewable With Any Browser campaigns, encouraging developers to design Web pages that work equally well with any browser.

A result of user agent spoofing may be that collected statistics of Web browser usage are inaccurate.
==

Robots Exclusion Standard
The robots exclusion standard, also known as the robots exclusion protocol or robots.txt protocol, is a standard used by websites to communicate with web crawlers and other web robots. The standard specifies the instruction format to be used to inform the robot about which areas of the website should not be processed or scanned. Robots are often used by search engines to categorize and archive web sites, or by webmasters to proofread source code. Not all robots cooperate with the standard including email harvesters, spambots and malware robots that scan for security vulnerabilities. The standard is different from, but can be used in conjunction with Sitemaps, a robot inclusion standard for websites.

The standard was proposed by Martijn Koster, when working for Nexor in February 1994 on the www-talk mailing list, the main communication channel for WWW-related activities at the time. Charles Stross claims to have provoked Koster to suggest robots.txt, after he wrote a badly behaved web crawler that caused an inadvertent denial of service attack on Koster's server.

It quickly became a de facto standard that present and future web crawlers were expected to follow; most complied, including those operated by search engines such as [WebCrawler], [Lycos] and [AltaVista].
===

Etag
The ETag or entity tag is part of [HTTP], the protocol for the [World Wide Web]. It is one of several mechanisms that HTTP provides for web cache validation, and which allows a client to make conditional requests. This allows caches to be more efficient, and saves bandwidth, as a web server does not need to send a full response if the content has not changed. ETags can also be used for optimistic concurrency control, as a way to help prevent simultaneous updates of a resource from overwriting each other.

An ETag is an opaque identifier assigned by a web server to a specific version of a resource found at a [URL]. If the resource representation at that URL ever changes, a new and different ETag is assigned. Used in this manner ETags are similar to fingerprints, and they can be quickly compared to determine whether two representations of a resource are the same.
===

HTTP Cookie
An HTTP cookie (also called Web cookie, Internet cookie, browser cookie or simply cookie), is a small piece of data sent from a website and stored in a user's web browser while the user is browsing that website. Every time the user loads the website, the browser sends the cookie back to the server to notify the website of the user's previous activity. Cookies were designed to be a reliable mechanism for websites to remember stateful information (such as items in a shopping cart) or to record the user's browsing activity (including clicking particular buttons, logging in, or recording which pages were visited by the user as far back as months or years ago).

Although when everything is working correctly, cookies cannot carry viruses, and cannot install malware on the host computer, tracking cookies and especially third-party tracking cookies are commonly used as ways to compile long term records of individuals' browsing histories a potential privacy concern that prompted European and U.S. law makers to take action in 2011. Cookies can also store passwords and form content a user has previously entered, such as a credit card number or an address.

Other kinds of cookies perform essential functions in the modern web. Perhaps most importantly, authentication cookies are the most common method used by web servers to know whether the user is logged in or not, and which account they are logged in with. Without such a mechanism, the site would not know whether to send a page containing sensitive information, or require the user to authenticate themselves by logging in. The security of an authentication cookie generally depends on the security of the issuing website and the user's web browser, and on whether the cookie data is encrypted. Security vulnerabilities may allow a cookie's data to be read by a hacker, used to gain access to user data, or used to gain access (with the user's credentials) to the website to which the cookie belongs.

The term "cookie" was derived from the term "magic cookie", which is a packet of data a program receives and sends back unchanged. Magic cookies were already used in computing when computer programmer Lou Montulli had the idea of using them in web communications in June 1994. At the time, he was an employee of [Netscape Communications], which was developing an e-commerce application for MCI. Vint Cerf and John Klensin represented MCI in technical discussions with Netscape Communications. Not wanting the MCI servers to have to retain partial transaction states led to MCI's request to Netscape to find a way to store that state in each user's computer. Cookies provided a solution to the problem of reliably implementing a virtual shopping cart.

Together with John Giannandrea, Montulli wrote the initial Netscape cookie specification the same year. Version 0.9beta of [Mosaic Netscape], released on 13 October  1994, supported cookies. The first use of cookies (out of the labs) was checking whether visitors to the Netscape website had already visited the site. Montulli applied for a patent for the cookie technology in 1995, and US 5774670 was granted in 1998. Support for cookies was integrated in [Internet Explorer] in version 2, released in October 1995.

The introduction of cookies was not widely known to the public at the time. In particular, cookies were accepted by default, and users were not notified of their presence. The general public learned about cookies after the Financial Times published an article about them on 12 February 1996. In the same year, cookies received a lot of media attention, especially because of potential privacy implications. Cookies were discussed in two U.S. Federal Trade Commission hearings in 1996 and 1997.

The development of the formal cookie specifications was already ongoing. In particular, the first discussions about a formal specification started in April 1995 on the www-talk mailing list. A special working group within the IETF was formed. Two alternative proposals for introducing state in HTTP transactions had been proposed by Brian Behlendorf and David Kristol respectively, but the group, headed by Kristol himself and Aron Afatsuom, soon decided to use the Netscape specification as a starting point. In February 1996, the working group identified third-party cookies as a considerable privacy threat. The specification produced by the group was eventually published as [RFC 2109] in February 1997. It specifies that third-party cookies were either not allowed at all, or at least not enabled by default.

At this time, advertising companies were already using third-party cookies. The recommendation about third-party cookies of [RFC 2109] was not followed by [Netscape] and [Internet Explorer]. [RFC 2109] was superseded by [RFC 2965] in October 2000.

A definitive specification for cookies as used in the real world was published as [RFC 6265] in April 2011.
===

AltaVista
AltaVista was an early web search engine founded in 1995. It was once one of the most popular search engines, but it lost ground to [Google] and was purchased by [Yahoo!] in 2003, which retained the brand but based all AltaVista searches on its own search engine. On 8 July 2013, the service was shut down by Yahoo! and since then, the domain redirects to Yahoo!'s own search site.
===

CloudFlare
CloudFlare Inc is a U.S. company that provides a content delivery network and distributed domain name server services, sitting between the visitor and the CloudFlare user's hosting provider, acting as a reverse proxy for websites. Its network protects, speeds up, and improves availability for a website or mobile application with a change in [DNS]. CloudFlare is headquartered in San Francisco, California, with an additional office in London.

CloudFlare was created in 2009 by Matthew Prince, Lee Holloway, and Michelle Zatlyn, who had previously worked on Project Honey Pot. CloudFlare was launched at the September 2010 TechCrunch Disrupt conference. It received media attention in June 2011, after providing security to LulzSec's website.

The hacker group UGNazi attacked CloudFlare partially via flaws in [Google]'s authentication systems in June 2012, gaining administrative access to CloudFlare and using it to deface 4chan.

In February 2014, CloudFlare mitigated the largest ever recorded [DDoS] attack, which peaked at 400 Gbit/s.

CloudFlare uses a modified version of [Nginx] as a key technology. As of December 2014, it reportedly operated from within 30 partner data centers.

CloudFlare claims to protect, speed up, and improve availability for a website or mobile application by using a DNS change. The network optimizes web and mobile pages to improve page load times and performance. CloudFlare also attempts to block threats and limit abusive bots and crawlers. CloudFlare currently runs on an anycast network. CloudFlare aims to protect customers from DDoS attacks, they also provide other services like a web application firewall (WAF).

CloudFlare releases "Keyless SSL" technology that lets sites use CloudFlareâs Secure Socket Layer ([SSL]) service while retaining on premises custody of their private keys.

CloudFlare launched a free service for both its paying and free customers: automatic SSL encryption for any site without the need to pay for or configure an encryption certificate.
===

Distributed Denial of Service
A Distributed Denial of Service (DDoS) attack occurs when multiple systems flood the bandwidth or resources of a targeted system, usually one or more web servers. Such an attack is often the result of multiple compromised systems (for example a botnet) flooding the targeted system with traffic. When a server is overloaded with connections, new connections can no longer be accepted. The major advantages to an attacker of using a distributed denial of service attack are that multiple machines can generate more attack traffic than one machine, multiple attack machines are harder to turn off than one attack machine, and that the behaviour of each attack machine can be stealthier, making it harder to track and shut down. These attacker advantages cause challenges for defence mechanisms. For example, merely purchasing more incoming bandwidth than the current volume of the attack might not help, because the attacker might be able to simply add more attack machines. This after all will end up completely crashing a website for periods of time.

Malware can carry DDoS attack mechanisms; one of the better known examples of this was MyDoom. Its DoS mechanism was triggered on a specific date and time. This type of DDoS involved hardcoding the target IP address prior to release of the malware and no further interaction was necessary to launch the attack.

A system may also be compromised with a trojan, allowing the attacker to download a zombie agent, or the trojan may contain one. Attackers can also break into systems using automated tools that exploit flaws in programs that listen for connections from remote hosts. This scenario primarily concerns systems acting as servers on the web. Stacheldraht is a classic example of a DDoS tool. It utilizes a layered structure where the attacker uses a client program to connect to handlers, which are compromised systems that issue commands to the zombie agents, which in turn facilitate the DDoS attack. Agents are compromised via the handlers by the attacker, using automated routines to exploit vulnerabilities in programs that accept remote connections running on the targeted remote hosts. Each handler can control up to a thousand agents. In some cases a machine may become part of a DDoS attack with the owner's consent, for example, in Operation Payback, organised by the group Anonymous. These attacks can use different types of internet packets such as: [TCP], [UDP], [ICMP] etc.

These collections of systems compromisers are known as botnets. DDoS tools like Stacheldraht still use classic DoS attack methods centered on IP spoofing and amplification like smurf attacks and fraggle attacks (these are also known as bandwidth consumption attacks). SYN floods (also known as resource starvation attacks) may also be used. Newer tools can use DNS servers for DoS purposes. Unlike MyDoom's DDoS mechanism, botnets can be turned against any IP address. Script kiddies use them to deny the availability of well known websites to legitimate users. More sophisticated attackers use DDoS tools for the purposes of extortion - even against their business rivals.

Simple attacks such as SYN floods may appear with a wide range of source IP addresses, giving the appearance of a well distributed DoS. These flood attacks do not require completion of the TCP three way handshake and attempt to exhaust the destination SYN queue or the server bandwidth. Because the source IP addresses can be trivially spoofed, an attack could come from a limited set of sources, or may even originate from a single host. Stack enhancements such as syn cookies may be effective mitigation against SYN queue flooding, however complete bandwidth exhaustion may require involvement.

If an attacker mounts an attack from a single host it would be classified as a DoS attack. In fact, any attack against availability would be classed as a denial of service attack. On the other hand, if an attacker uses many systems to simultaneously launch attacks against a remote host, this would be classified as a DDoS attack.

UK's [GCHQ] has tools built for DDOS, named PREDATORS FACE and ROLLING THUNDER.
===

GCHQ - Government Communications Headquarters
The Government Communications Headquarters (GCHQ) is a British intelligence and security organisation responsible for providing signals intelligence (SIGINT) and information assurance to the British government and armed forces. Based in "The Doughnut", in the suburbs of Cheltenham, it operates under the formal direction of the Joint Intelligence Committee (JIC) alongside the Security Service (MI5), the Secret Intelligence Service (MI6) and Defence Intelligence (DI). GCHQ is the responsibility of the UK Secretary of State for Foreign and Commonwealth Affairs, but it is not a part of the Foreign Office and its Director ranks as a Permanent Secretary.

GCHQ was originally established after the First World War as the Government Code and Cypher School (GC&amp;CS) and was known under that name until 1946. During the Second World War it was located at [Bletchley Park], where it was famed for its role in the breaking of the German Enigma codes. Currently there are two main components of the GCHQ, the Composite Signals Organisation (CSO), which is responsible for gathering information, and the CESG, which is responsible for securing the UK's own communications. The Joint Technical Language Service (JTLS) is a small department and cross government resource responsible for mainly technical language support and translation and interpreting services across government departments. It is co-located with GCHQ for administrative purposes.

In 2013, GCHQ received considerable media attention when the former National Security Agency contractor Edward Snowden revealed that the agency was in the process of collecting all online and telephone data in the UK via the Tempora programme. Snowden's revelations began a spate of ongoing disclosures of global surveillance.
===

Advanced Gravis Computer Technology
Advanced Gravis Computer Technology Ltd. was a manufacturer of computer peripherals and hardware. The company was founded in 1982 in British Columbia, Canada.

Their most famous products were the [Gravis PC GamePad], at one time one of the most popular gaming controllers for the [PC], the once ubiquitous Gravis Joystick (black with red buttons), and the [Gravis Ultrasound] add-on card, competitor to the [Sound Blaster]. At its peak, the company had almost 300 employees, and was at the time the world's largest manufacturer of computer joysticks and gamepads.

The company was acquired by Kensington Computer Products Group in 1997 and has essentially disappeared.
===

Kensington Security Slot
A Kensington Security Slot (also called a K-Slot or Kensington lock) is part of an anti-theft system designed and patented by Kryptonite in 1999 - 2000, assigned to Schlage in 2002, and since 2005 owned and marketed by Kensington Computer Products Group, a division of ACCO Brands.

The system consists of a small, metal-reinforced hole found commonly on small or portable computers and electronics equipment such as laptops, computer monitors, desktop computers, gaming consoles, and video projectors, combined with a metal anchor attached to a rubberized metal cable secured with a key or combination lock. The end of the cable has a small loop that allows the cable to be looped around a permanent object, such as a heavy table or other similar equipment.[1]

The hole is found in most laptops, although a lock for it is typically not included. Occasionally, the slot is located so that installing a lock will also prevent the removal of a valuable subcomponent, such as a rechargeable battery or a memory module. The Kensington slot may be marked with a small icon that looks like a padlock with a capital "K", or the slot may be unlabeled.

Kensington locks are not designed to be an impervious protection measure.[2] Because most computer equipment cases are generally made of plastic or thin metal, the lock can be torn out, though not without doing significant visible damage to the case. The cable itself can be cut if an individual has a wire cutter or bolt cutter sufficiently strong to cut through the cable material, which will vary between different brands of cable.

The Kensington type locks are useful to prevent quick grab-and-run thefts of equipment from casually supervised locations such as coffee shops, but cannot prevent the removal of equipment secured in an unattended location.

The key is often a cylindrical type, but there are versions which use a traditional flat key. There are also versions of the lock that use a numeric combination instead of a key.[2]
===
The Gravis PC GamePad is a game port game controller produced by Advanced Gravis Computer Technology. It was the first gamepad for the IBM PC compatible in a market then dominated by joysticks.[citation needed] Included with the gamepad was a shareware Commander Keen game, episode 1, Marooned on Mars, which was later replaced with the shareware episode 4, Secret of the Oracle which supported all 4 buttons. The gamepad is no longer manufactured, as the Gravis company has ceased to exist.

The gamepad's design is similar to that of the stock SNES controller (more so the Japanese and European version with colored buttons), although it lacks the Start, Select and shoulder buttons, and the shape of the controller's chassis differs slightly, with an inverted curve on the left side. As originally found in some versions of the Sega Master System controller, the center of the Gravis GamePad's d-pad allows a small joystick to be inserted. The resulting lever action provides increased directional sensitivity, desirable in fighting games for example.

Both at the top and bottom of the gamepad are switches. One of them removes the normal functionality from 2 of the buttons, and turns them into autofire variants of the first 2. This gave all four buttons functionality even in PC games that only supported two buttons on joysticks or for scenarios when two gamepads are connected with a Y-splitter. The other allows for left-handed operation by turning the workings of the D-pad and buttons upside down. Both switches can be used at the same time.
===
Ad Lib, Inc. was a Canadian manufacturer of sound cards and other computer equipment founded by Martin Prevel, a former professor of music and vice-dean of the music department at the UniversitÃ© Laval.[1] The company's best known product, the AdLib Music Synthesizer Card (ALMSC), or simply the AdLib as it was called, was the first add-on sound card (on compatibles) to achieve widespread game-developer acceptance, becoming the first de facto standard for audio reproduction.[2]


Problems playing this file? See media help.
Today the AdLib's functionality can be recreated with emulators such as AdPlug and VDMSound (the latter is now deprecated but its source code has been incorporated into DOSBox). Emulating the AdLib Gold 1000 proves more of a challenge due to the surround sound module and the 2x oversampling effect.
===
Kingston Technology Corporation is an American, privately held, multinational computer technology corporation that develops, manufactures, sells and supports flash memory products and other computer-related memory products. Headquartered in Fountain Valley, California, United States, Kingston Technology employs more than 4,000 people worldwide as of Q1 2015. The company has manufacturing and logistics facilities in the United States, United Kingdom, Ireland, Taiwan, and Mainland China.

It is the largest independent producer of DRAM memory modules, currently owning 59% of the third-party worldwide DRAM module market share, according to IHS.[1] Kingston is arguably the second largest supplier of flash memory. Gartner ranks Kingston as the world's #2 supplier of USB drives, #2 in flash cards and #2 in PC based solid state drives.[citation needed]

In 2014, Kingston generated revenues of US $7.0 billion. Forbes lists Kingston as #69 on its list of "The 500 Largest Private Companies in the U.S." and #2 in the Technology Hardware & Equipment category.

Kingston serves an international network of distributors, resellers, retailers and OEM customers on six continents. The company also provides contract manufacturing and supply chain management services for semiconductor manufacturers and system OEMs.

Through its ownership of Kingston Technology Company Inc. and Advanced Validation Labs Inc. (AVL), Kingston Technology Corporation is one of the worldâs leading memory module manufacturing, module validation, semiconductor packaging and test companies[citation needed].
===
Dynamic random-access memory (DRAM) is a type of random-access memory that stores each bit of data in a separate capacitor within an integrated circuit. The capacitor can be either charged or discharged; these two states are taken to represent the two values of a bit, conventionally called 0 and 1. Since even "nonconducting" transistors always leak a small amount, the capacitors will slowly discharge, and the information eventually fades unless the capacitor charge is refreshed periodically. Because of this refresh requirement, it is a dynamic memory as opposed to static random access memory (SRAM) and other static types of memory.

The main memory (the "RAM") in personal computers is dynamic RAM (DRAM). It is the RAM in desktops, laptops and workstation computers as well as some of the RAM of video game consoles.

The advantage of DRAM is its structural simplicity: only one transistor and a capacitor are required per bit, compared to four or six transistors in SRAM. This allows DRAM to reach very high densities. Unlike flash memory, DRAM is volatile memory (vs. non-volatile memory), since it loses its data quickly when power is removed. The transistors and capacitors used are extremely small; billions can fit on a single memory chip.

Due to the nature of its memory cells, DRAM consumes relatively large amounts of power, with different ways for managing the power consumption.[1]
===
The Ricoh Company, Ltd. (æ ªå¼ä¼ç¤¾ãªã³ã¼ Kabushiki-gaisha RikÅ?) is a Japanese multinational imaging and electronics company. It was founded by the RIKEN zaibatsu on 6 February 1936 as Riken Sensitized Paper (çç æåç´ Riken KankÅshi?). Ricoh's headquarters are located in Ricoh Building in ChÅ«Å, Tokyo.[1]

Ricoh produces electronic products, primarily cameras and office equipment such as printers, photocopiers, fax machines, offers Software as a Service (SaaS) document management solutions such as DocumentMall, document solutions such as GlobalScan, Print&Share[2] and also offers Projectors. In the late 1990s through early 2000s, the company grew to become the largest copier manufacturer in the world. During this time, Ricoh acquired Savin, Gestetner, Lanier, Rex-Rotary, Monroe, Nashuatec, IKON and most recently IBM Printing Systems Division / Infoprint Solutions Company. Although the Monroe brand was discontinued, products continue to be marketed worldwide under the remaining brand names. In 2006, Ricoh acquired the European operations of Danka for $210 million. These operations continue as a stand-alone business unit, under the Infotec brand.
===
Lexmark International, Inc. is an American corporation that manufactures laser printers and provides enterprise software. The company is headquartered in Lexington, Kentucky, in the United States.

Lexmark was formed on March 27, 1991 when IBM divested a number of its hardware manufacturing operations, including printer and printer supply operations, to the investment firm Clayton & Dubilier & Rice, Inc. in a leveraged buyout.[2][3][4][5] Lexmark became a publicly traded company on the New York Stock Exchange on November 15, 1995.[6] The name Lexmark comes from a combination between "lexicon" and "Mark".
===
3Com Corporation was a digital electronics manufacturer best known for its computer network infrastructure products. The company was co-founded in 1979 by Robert Metcalfe, Howard Charney, Bruce Borden, and Greg Shaw and recruited Bill Krause from HP to be its President in February 1981 when it raised its first round of venture capital. Metcalfe has explained that he came up with the name 3Com as a contraction of "Computer Communication Compatibility",[2] with its focus on deploying the Ethernet technology that he had co-invented which enabled the networking of computers.

3Com provided network interface controllers and switches, routers, wireless access points and controllers, IP voice systems, and intrusion prevention systems. The company was based in Massachusetts, USA. From its 2007 acquisition of 100 percent ownership of H3C Technologies Co., Limited (H3C) âinitially a joint venture with China-based Huawei Technologiesâ3Com achieved a leading market presence in China, and a significant networking market share in Europe, Asia, and the Americas.[citation needed] 3Com products were sold under the brands 3Com, H3C, and TippingPoint.

On April 12, 2010, Hewlett-Packard completed the acquisition of 3Com.[3] Since the HP acquisition, 3Com has been fully absorbed by HP and no longer exists as a separate entity.
===
U.S. Robotics Corporation (often referred to as USR) is a company which produces USRobotics computer modems and related products. It sold high-speed modems in the 1980s, and had a reputation for high quality and compatibility with communication standards. With the reduced usage of analog or voiceband modems in North America in the early 21st century, USR is now one of the few modem companies left in that market. It now employs about 125 people worldwide.[1]

USR was founded in 1976 in Chicago, Illinois (and later moved to Skokie, Illinois), by a group of entrepreneurs, including Casey Cowell, who served as CEO for most of the company's history and Paul Collard who designed modems into the mid-1980s. The company name is a reference to the fiction of Isaac Asimov, who is credited with inventing the term robotics. Asimov's Robot stories featured a fictional company named U.S. Robots and Mechanical Men. Cowell stated at a popular BBS convention they named the company as an homage to Asimov and because in his science fiction works US Robotics eventually became "the biggest company in the universe".[citation needed] (The later 2004 movie I, Robot, which was loosely based on Asimov's works, and set in Chicago, used the name "U.S. Robotics" for the fictional robot manufacturer.) The movie's U.S. Robotics corporate logo resembles a former nonfictional USR logo. Following the release of the movie, the company officially changed its name to USR.

USR was one of many companies to offer dial-up modems for personal computers. Prior to the development of standards such as the V.32 family of protocols, USR introduced its own HST (High-Speed Transfer) protocol in 1986, which operated at 9600 bit/s (bits per second). In 1989 HST was expanded to 14.4 kbit/s, 16.8 kbit/s in 1992, and finally to 21 kbit/s and 24 kbit/s.

USR was not the only company making modems with proprietary protocols; Telebit's TrailBlazer series offered speeds up to 19.2 kbit/s in its first model, and Hayes also introduced a 9600 bit/s Express 96 (or "Ping-Pong") system. However, USR became the most successful of the three, due to a marketing scheme that offered large discounts to BBS sysops.


U.S. Robotics Sportster 14,400 Fax Modem (1994)
The proprietary nature of HST allowed USR to maintain its market predominance even when off-brand V.32-based modems began selling for less than equivalent HST modems. As the price differential decreased, however, V.32-based modems eventually became a cost-effective alternative to HST. Nevertheless, USR maintained its user base by creating slightly faster HST protocols (in particular, a 16.8 kbit/s mode) and by producing "dual-standard" modems which were able to communicate with both HST and V.32 modems at high speeds.

During this period, USR differentiated between its high and low-end product lines by supporting only the V.32 modes on its low-end Sportster models, while its high-end Courier models supported V.32, HST, or both in the Courier Dual Standard models. The Sportster used the same motherboard as the Couriers, and on certain 14.4 kbit/s models a sequence of AT commands could be issued to enable the faster 16.8 kbit/s HST mode.[2] The Courier modems remained a favorite in the BBS and emerging Internet service provider world, where they were known to run without problems for extended periods of time (although the initial large-scale deployment of Courier modems in the CompuServe network uncovered a serious bug which would cause the modems to crash and stop answering calls under high call volumes).


USR Sportster 56k 117102 ISA modem supporting X2 and V.90

Courier Dual Standard V34 Fax with V32 bis
Later, when 56 kbit/s modems were introduced, USR again went its own way with its X2 technology pitched against K56flex before the creation of a final formal 56K standard. After the V.90 industry standard became available, USR abandoned its proprietary protocols. In a further effort to reduce the retail price of its modems, USR also marketed a Winmodem that used software running on the host computer to perform some of the modem functions.

Some models of Courier modems were known for their long-term upgradeability, because they used an upgradeable DSP design. For example, when the Courier V.Everything modem was first released in 1994 under the product label "Courier V.34 Ready", it shipped with only V.FC support because V.34 had not been released. A free V.34 upgrade was made available later via FidoNet, as well as the Internet. USR then surprised many early Courier V.Everything modem owners with a limited-time free offer of an X2 firmware upgrade, which added 56K speed capability. Finally, USR released a V.90 upgrade that was compatible with X2-upgraded Courier V.Everything modems. Even the 1994 hardware released pre-V.34 was fully V.90-upgradeable without hardware modification. Many Courier V.Everything modems were still in use more than a decade later.[citation needed]

There was a licensing key needed for some Courier V.Everything V.90 flash upgrades. The firmware could be loaded onto the modem, but it would work in "degraded" V.34 mode. After paying a fee, and having the modem dial USR, a license key was installed that enabled the V.90 functions.
===

Cloud Computing
Cloud computing is a model for enabling ubiquitous network access to a shared pool of configurable computing resources.[1]

Cloud computing and storage solutions provide users and enterprises with various capabilities to store and process their data in third-party data centers.[2] It relies on sharing of resources to achieve coherence and economies of scale, similar to a utility (like the electricity grid) over a network.[3] At the foundation of cloud computing is the broader concept of converged infrastructure and shared services.

Cloud computing, or in simpler shorthand just "the cloud", also focuses on maximizing the effectiveness of the shared resources. Cloud resources are usually not only shared by multiple users but are also dynamically reallocated per demand. This can work for allocating resources to users. For example, a cloud computer facility that serves European users during European business hours with a specific application (e.g., email) may reallocate the same resources to serve North American users during North America's business hours with a different application (e.g., a web server). This approach should maximize the use of computing power thus reducing environmental damage as well since less power, air conditioning, rack space, etc. are required for a variety of functions. With cloud computing, multiple users can access a single server to retrieve and update their data without purchasing licenses for different applications.

The term "moving to cloud" also refers to an organization moving away from a traditional CAPEX model (buy the dedicated hardware and depreciate it over a period of time) to the OPEX model (use a shared cloud infrastructure and pay as one uses it).[dubious â discuss]

Proponents claim that cloud computing allows companies to avoid upfront infrastructure costs, and focus on projects that differentiate their businesses instead of on infrastructure.[4] Proponents also claim that cloud computing allows enterprises to get their applications up and running faster, with improved manageability and less maintenance, and enables IT to more rapidly adjust resources to meet fluctuating and unpredictable business demand.[4][5][6] Cloud providers typically use a "pay as you go" model. This can lead to unexpectedly high charges if administrators do not adapt to the cloud pricing model.[7]

The present availability of high-capacity networks, low-cost computers and storage devices as well as the widespread adoption of hardware virtualization, service-oriented architecture, and autonomic and utility computing have led to a growth in cloud computing.[8][9][10] Companies can scale up as computing needs increase and then scale down again as demands decrease.
===
DoS
ed
Gravis Ultrasound
Photoshop
Symantec
Peter Norton Computing


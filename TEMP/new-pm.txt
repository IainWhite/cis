V-model
<p>The <strong>V-model</strong> represents a software development process (also applicable to hardware development) which may be considered an extension of the [waterfall model]. Instead of moving down in a linear way, the process steps are bent upwards after the coding phase, to form the typical V shape. The V-Model demonstrates the relationships between each phase of the development life cycle and its associated phase of testing. The horizontal and vertical axes represents time or project completeness (left-to-right) and level of abstraction (coarsest-grain abstraction uppermost), respectively.</p>

<h2>Verification Phases<h2>

<h3>Requirements Analysis<h3>
<p>In the Requirements analysis phase, the first step in the verification process, the requirements of the system are collected by analyzing the needs of the user(s). This phase is concerned with establishing what the ideal system has to perform. However it does not determine how the software will be designed or built. Usually, the users are interviewed and a document called the user requirements document is generated.</p>
<p>The user requirements document will typically describe the system’s functional, interface, performance, data, security, etc. requirements as expected by the user. It is used by business analysts to communicate their understanding of the system to the users. The users carefully review this document as this document would serve as the guideline for the system designers in the system design phase. The user acceptance tests are designed in this phase. See also Functional requirements.</p>
<p>There are different methods for gathering requirements of both soft and hard methodologies including; interviews, questionnaires, document analysis, observation, throw-away prototypes, use cases and static and dynamic views with users.</p>

<h3>System Design<h3>
<p>Systems design is the phase where system engineers analyse and understand the business of the proposed system by studying the user requirements document. They figure out possibilities and techniques by which the user requirements can be implemented. If any of the requirements are not feasible, the user is informed of the issue. A resolution is found and the user requirement document is edited accordingly.</p>
<p>The software specification document which serves as a blueprint for the development phase is generated. This document contains the general system organisation, menu structures, data structures etc. It may also hold example business scenarios, sample windows, reports for the better understanding. Other technical documentation like entity diagrams, data dictionary will also be produced in this phase. The documents for system testing are prepared.</p>

<h3>Architecture Design</h3>
<p>The phase of the design of computer architecture and software architecture can also be referred to as high-level design. The baseline in selecting the architecture is that it should realize all which typically consists of the list of modules, brief functionality of each module, their interface relationships, dependencies, database tables, architecture diagrams, technology details etc. The integration testing design is carried out in the particular phase.</p>

<h3>Module Design</h3>
<p>The module design phase can also be referred to as low-level design. The designed system is broken up into smaller units or modules and each of them is explained so that the programmer can start coding directly. The low level design document or program specifications will contain a detailed functional logic of the module, in pseudocode:</p>
<ul>
	<li>database tables, with all elements, including their type and size</li>
	<li>all interface details with complete API references</li>
	<li>all dependency issues</li>
	<li>error message listings</li>
	<li>complete input and outputs for a module</li>
</ul>
<p>The unit test design is developed in this stage.</p>

<h2>Validation Phases</h2>
<p>In the V-model, each stage of verification phase has a corresponding stage in the validation phase. The following are the typical phases of validation in the V-Model, though they may be known by other names.</p>

<h3>Unit Testing</h3>
<p>In the V-Model, Unit Test Plans (UTPs) are developed during module design phase. These UTPs are executed to eliminate bugs at code level or unit level. A unit is the smallest entity which can independently exist, e.g. a program module. Unit testing verifies that the smallest entity can function correctly when isolated from the rest of the codes / units.</p>

<h3>Integration Testing</h3>
<p>Integration Test Plans are developed during the Architectural Design Phase. These tests verify that units created and tested independently can coexist and communicate among themselves. Test results are shared with customer's team.</p>

<h3>System Testing</h3>
<p>System Tests Plans are developed during System Design Phase. Unlike Unit and Integration Test Plans, System Test Plans are composed by client's business team. System Test ensures that expectations from application developed are met. The whole application is tested for its functionality, interdependency and communication. System Testing verifies that functional and non-functional requirements have been met. Load and performance testing, stress testing, regression testing, etc., are subsets of system testing.</p>

<h3>User Acceptance Testing</h3>
<p>User Acceptance Test (UAT) Plans are developed during the Requirements Analysis phase. Test Plans are composed by business users. UAT is performed in a user environment that resembles the production environment, using realistic data. UAT verifies that delivered system meets user's requirement and system is ready for use in real time.</p>

===

Dual Vee Model
<p>The <strong>Dual Vee Model</strong> builds on the [V-model] to cleanly depict the complexity associated with designing and developing systems. In systems engineering it defines a uniform procedure for product or project development. The model depicts concurrent development of a system's architecture as one Vee with each entity of that architecture as another Vee that intersects the architecture Vee. This clearly shows interactions and sequences in developing a complex system and a system of systems.</p>

===
Incremental Build Model
<p>The <strong>Incremental Build Model</strong> is a method of software development where the product is designed, implemented and tested incrementally (a little more is added each time) until the product is finished. It involves both development and maintenance. The product is defined as finished when it satisfies all of its requirements. This model combines the elements of the waterfall model with the iterative philosophy of prototyping.</p>
<p>The product is decomposed into a number of components, each of which is designed and built separately (termed as builds). Each component is delivered to the client when it is complete. This allows partial utilization of the product and avoids a long development time. It also avoids a large initial capital outlay and subsequent long waiting period. This model of development also helps ease the traumatic effect of introducing a completely new system all at once. There are, however, several problems with this model.</p>

===
Iterative and Incremental Development
<p><strong>Iterative and Incremental development</strong> is any combination of both <strong>iterative design</strong> or <strong>iterative method</strong> and [incremental build model] for software development. The combination is of long standing and has been widely suggested for large development efforts. For example, the 1985 DOD-STD-2167 mentions (in section 4.1.2): "During software development, more than one iteration of the software development cycle may be in progress at the same time." and "This process may be described as an 'evolutionary acquisition' or 'incremental build' approach." The relationship between iterations and increments is determined by the overall software development methodology and software development process. The exact number and nature of the particular incremental builds and what is iterated will be specific to each individual development effort.</p>
<p>Iterative and incremental development are essential parts of the modified [waterfall models], [Rational Unified Process], [Extreme Programming] and generally the various [Agile software development] frameworks.</p>
<p>It follows a similar process to the [plan-do-check-act cycle] of [business process improvement].</p>

===
Business Process Improvement (BPI)
<p><strong>Business Process Improvement (BPI)</strong> is a systematic approach to help an organisation optimize its underlying processes to achieve more efficient results. The methodology was first documented in H. James Harrington’s 1991 book Business Process Improvement. It is the methodology that both Process Redesign and Business Process Reengineering are based upon. BPI has allegedly been responsible for reducing cost and cycle time by as much as 90% while improving quality by over 60%.</p>
<p>Process improvement is an aspect of organisational development (OD) in which a series of actions are taken by a process owner to identify, analyse and improve existing business processes within an organisation to meet new goals and objectives, such as increasing profits and performance, reducing costs and accelerating schedules. These actions often follow a specific methodology or strategy to increase the likelihood of successful results. Process improvement may include the restructuring of company training programs to increase their effectiveness.</p>
<p>Process improvement is also a method to introduce process changes to improve the quality of a product or service, to better match customer and consumer needs.</p>

===
Plan–Do–Check–Act - PDCA
<p><strong>PDCA (plan–do–check–act or plan–do–check–adjust)</strong> is an iterative four-step management method used in business for the control and continuous improvement of processes and products. It is also known as the Deming circle / cycle / wheel, Shewhart cycle, control circle/cycle, or plan–do–study–act (PDSA). Another version of this PDCA cycle is OPDCA. The added "O" stands for observation or as some versions say "Grasp the current condition." This emphasis on observation and current condition has currency with [Lean manufacturing] / Toyota Production System] literature.</p>

<h2>PLAN</h2>
<p>Establish the objectives and processes necessary to deliver results in accordance with the expected output (the target or goals). By establishing output expectations, the completeness and accuracy of the spec is also a part of the targeted improvement. When possible start on a small scale to test possible effects.</p>

<h2>DO</h2>
<p>Implement the plan, execute the process, make the product. Collect data for charting and analysis in the following "CHECK" and "ACT" steps.</p>

<h2>CHECK</h2>
<p>Study the actual results (measured and collected in "DO" above) and compare against the expected results (targets or goals from the "PLAN") to ascertain any differences. Look for deviation in implementation from the plan and also look for the appropriateness and completeness of the plan to enable the execution, i.e., "Do". Charting data can make this much easier to see trends over several PDCA cycles and in order to convert the collected data into information. Information is what you need for the next step "ACT".</p>

<h2>ACT</h2>
<p>If the CHECK shows that the PLAN that was implemented in DO is an improvement to the prior standard (baseline), then that becomes the new standard (baseline) for how the organisation should ACT going forward (new standards are enACTed). If the CHECK shows that the PLAN that was implemented in DO is not an improvement, then the existing standard (baseline) will remain in place. In either case, if the CHECK showed something different than expected (whether better or worse), then there is some more learning to be done... and that will suggest potential future PDCA cycles. Note that some who teach PDCA assert that the ACT involves making adjustments or corrective actions... but generally it would be counter to PDCA thinking to propose and decide upon alternative changes without using a proper PLAN phase, or to make them the new standard (baseline) without going through DO and CHECK steps.</p>
===

Capability Maturity Model Integration (CMMI)
<p><strong>Capability Maturity Model Integration (CMMI)</strong> is a process improvement training and appraisal program and service administered and marketed by Carnegie Mellon University and required by many DoD and U.S. Government contracts, especially in software development. Carnegie Mellon University claims CMMI can be used to guide process improvement across a project, division, or an entire organisation. CMMI defines the following maturity levels for processes: Initial, Managed, Defined, Quantitatively Managed, Optimising. Currently supported is CMMI Version 1.3. CMMI is registered in the U.S. Patent and Trademark Office by Carnegie Mellon University.</p>
===

Acceptance Test-Driven Development (ATDD)
<p><strong>Acceptance Test-Driven Development (ATDD)</strong> is a development methodology based on communication between the business customers, the developers, and the testers. ATDD encompasses many of the same practices as Specification by Example, [Behavior Driven Development] (BDD), [Example-Driven Development] (EDD), and Story Test-Driven Development (SDD). All these processes aid developers and testers in understanding the customer’s needs prior to implementation and allow customers to be able to converse in their own domain language.</p>
<p>ATDD is closely related to [Test-Driven Development] (TDD). It differs by the emphasis on developer-tester-business customer collaboration. ATDD encompasses acceptance testing, but highlights writing acceptance tests before developers begin coding.</p>
===

Code Refactoring
<p><strong>Code refactoring</strong> is the process of restructuring existing computer code – changing the factoring – without changing its external behaviour. Refactoring improves nonfunctional attributes of the software. Advantages include improved code readability and reduced complexity to improve source code maintainability, and create a more expressive internal architecture or object model to improve extensibility. Typically, refactoring applies a series of standardised basic micro-refactorings, each of which is (usually) a tiny change in a computer program's source code that either preserves the behaviour of the software, or at least does not modify its conformance to functional requirements. Many development environments provide automated support for performing the mechanical aspects of these basic refactorings. If done extremely well, code refactoring may also resolve hidden, dormant, or undiscovered computer bugs or vulnerabilities in the system by simplifying the underlying logic and eliminating unnecessary levels of complexity. If done poorly it may fail the requirement that external functionality not be changed, and/or introduce new bugs.</p>
<div>
	<p><em>By continuously improving the design of code, we make it easier and easier to work with. This is in sharp contrast to what typically happens: little refactoring and a great deal of attention paid to expediently adding new features. If you get into the hygienic habit of refactoring continuously, you'll find that it is easier to extend and maintain code.</em></p>
	<p>- Joshua Kerievsky, Refactoring to Patterns
</div>
===

Use Case
<p>In software and systems engineering, a <strong>use case</strong> is a list of steps, typically defining interactions between a role (known in [Unified Modeling Language] (UML) as an "actor") and a system, to achieve a goal. The actor can be a human, an external system, or time.</p>
<p>In systems engineering, use cases are used at a higher level than within software engineering, often representing missions or stakeholder goals. The detailed requirements may then be captured in [Systems Modeling Language] (SysML) or as contractual statements.</p>
<p>Use Cases are an important requirement technique that have been widely used in modern software engineering since their formal introduction by Ivar Jacobson in 1992. Use case driven development is a key characteristic of process models and frameworks such as the [Unified Process] (UP), [Rational Unified Process] (RUP), and [Oracle Unified Method] (OUM). With its iterative and evolutionary nature, the use case is also a good fit for agile development.</p>
===

Systems Modeling Language (SysML)
<p>The <strong>Systems Modeling Language (SysML)</strong> is a general-purpose modeling language for systems engineering applications. It supports the specification, analysis, design, verification and validation of a broad range of systems and systems-of-systems.</p>
<p>SysML was originally developed by an open source specification project, and includes an open source license for distribution and use. SysML is defined as an extension of a subset of the [Unified Modeling Language] (UML) using UML's profile mechanism.</p>

===

User Story
<p>In software development and product management, a <strong>user story</strong> is a description consisting of one or more sentences in the everyday or business language of the end user or user of a system that captures what a user does or needs to do as part of his or her job function. User stories are used with agile software development methodologies as the basis for defining the functions a business system must provide, and to facilitate requirements management. It captures the 'who', 'what' and 'why' of a requirement in a simple, concise way, often limited in detail by what can be hand-written on a small paper notecard.</p>
<p>User stories originated with [Extreme Programming] (XP), whose first written description in 1998 only claimed that customers defined project scope "with user stories, which are like use cases". Rather than offered as a distinct practice, they were described as one of the "game pieces" used in the planning game. However, most of the further literature thrust around all the ways arguing that user stories are "unlike" use cases, in trying to answer in a more practical manner "how requirements are handled" in XP and more generally [Agile] projects. This drives the emergence, over the years, of a more sophisticated account of user stories.</p>
<p>In 2001, Ron Jeffries proposed the well-known <strong>Three C's formula</strong>, i.e. Card, Conversation, Confirmation, to capture the components of a user story:</p>
<ul>
	<li>A Card (or often a Post-it note) is a physical token giving tangible and durable form to what would otherwise only be an abstraction;</li>
	<li>A Conversation is taking place at different time and places during a project between the various stakeholders concerned by the given feature (customers, users, developers, testers, etc.), which is largely verbal but most often supplemented by documentation;</li>
	<li>The Confirmation, the more formal the better, ensures that the objectives the conversation revolved around have been reached finally.</li>
</ul>
===

Story-Driven Modeling
<p><strong>Story-Driven Modeling</strong> is an object-oriented modeling technique. Other forms of object-oriented modeling focus on class diagrams. Class diagrams describe the static structure of a program, i.e. the building blocks of a program and how they relate to each other. Class diagrams also model data structures, but with an emphasis on rather abstract concepts like types and type features.</p>
<p>Instead of abstract static structures, story-driven modeling focuses on concrete example scenarios and on how the steps of the example scenarios may be represented as object diagrams and how these object diagrams evolve during scenario execution.</p>
===
